from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate
import os
from dotenv import load_dotenv

load_dotenv()

# OpenAI LLM ê°ì²´ ìƒì„±
llm = OpenAI(
    model="gpt-4o-mini",
    temperature=0,
    max_tokens=100,
    openai_api_key=os.getenv("OPENAI_API_KEY"),
)

# PromptTemplate ìƒì„±
prompt_template = PromptTemplate(
    input_variables=["job"], template="ë‹¹ì‹ ì€ {job}ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ í•  ì¼ì€?"
)

# ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸
input_data = {"job": "ê°œë°œì"}
formatted_prompt = prompt_template.format(**input_data)

print("ğŸ” í”„ë¡¬í”„íŠ¸ ë¶„ì„")
print(f"í…œí”Œë¦¿: {prompt_template.template}")
print(f"ë³€ìˆ˜: {prompt_template.input_variables}")
print(f"ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸: '{formatted_prompt}'")

# íŒŒì´í”„ë¼ì¸ ë°©ì‹ìœ¼ë¡œ ì²´ì¸ ìƒì„±
chain = prompt_template | llm

# ì‹¤í–‰
output = chain.invoke(input_data)

print("í˜„ëŒ€ì ì¸ ì²´ì¸ ì‹¤í–‰ ì™„ë£Œ!")
print(f"ìƒì„±ëœ ì‘ë‹µ: {output}")
