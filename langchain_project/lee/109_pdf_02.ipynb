{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c145dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dff7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'더존비즈온'이 포함된 PDF 파일 검색 중...\n",
      "발견: .\\20250630_더존비즈온.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def find_pdf_files(search_name=\"더존비즈온\"):\n",
    "    \"\"\"PDF 파일 검색\"\"\"\n",
    "    print(f\"'{search_name}'이 포함된 PDF 파일 검색 중...\")\n",
    "\n",
    "    # 현재 디렉토리와 하위 디렉토리에서 검색\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\") and search_name in file:\n",
    "                full_path = os.path.join(root, file)\n",
    "                print(f\"발견: {full_path}\")\n",
    "                return full_path\n",
    "\n",
    "    print(\"해당 파일을 찾을 수 없습니다.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# 파일 검색 및 처리\n",
    "found_file = find_pdf_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fc2386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 추출 중...\n",
      "텍스트 지식 구조 생성 중...\n",
      "표 추출 및 Q&A 생성 중...\n",
      "처리 중 오류 발생: 'utf-8' codec can't decode byte 0xba in position 211: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "\n",
    "class PDFToKnowledgeConverter:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = []\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"PDF에서 텍스트 추출\"\"\"\n",
    "        text = \"\"\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    def extract_tables_from_pdf(self, pdf_path: str) -> List[pd.DataFrame]:\n",
    "        \"\"\"PDF에서 표 추출 (tabula-py 사용)\"\"\"\n",
    "        try:\n",
    "            import tabula\n",
    "\n",
    "            tables = tabula.read_pdf(pdf_path, pages=\"all\", multiple_tables=True)\n",
    "            return tables\n",
    "        except ImportError:\n",
    "            print(\"tabula-py가 설치되지 않았습니다. pip install tabula-py\")\n",
    "            return []\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"텍스트 정제\"\"\"\n",
    "        # 불필요한 공백, 특수문자 제거\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        text = re.sub(r\"[^\\w\\s가-힣.,?!]\", \" \", text)\n",
    "        return text.strip()\n",
    "\n",
    "    def split_into_chunks(self, text: str, chunk_size: int = 500) -> List[str]:\n",
    "        \"\"\"텍스트를 청크로 분할\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = \" \".join(words[i : i + chunk_size])\n",
    "            chunks.append(chunk)\n",
    "        return chunks\n",
    "\n",
    "    def table_to_qa_pairs(self, table: pd.DataFrame) -> List[Dict]:\n",
    "        \"\"\"표를 Q&A 쌍으로 변환\"\"\"\n",
    "        qa_pairs = []\n",
    "\n",
    "        # 각 행을 질문-답변으로 변환\n",
    "        for index, row in table.iterrows():\n",
    "            for col in table.columns:\n",
    "                if pd.notna(row[col]):\n",
    "                    question = f\"{col}에 대해 알려주세요.\"\n",
    "                    answer = f\"{col}은(는) {row[col]}입니다.\"\n",
    "\n",
    "                    qa_pairs.append(\n",
    "                        {\n",
    "                            \"question\": question,\n",
    "                            \"answer\": answer,\n",
    "                            \"source\": \"table\",\n",
    "                            \"metadata\": {\"table_row\": index, \"column\": col},\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        return qa_pairs\n",
    "\n",
    "    def text_to_knowledge_structure(self, text_chunks: List[str]) -> List[Dict]:\n",
    "        \"\"\"텍스트 청크를 지식 구조로 변환\"\"\"\n",
    "        knowledge_items = []\n",
    "\n",
    "        for i, chunk in enumerate(text_chunks):\n",
    "            # 간단한 제목 추출 (첫 문장을 제목으로 사용)\n",
    "            sentences = chunk.split(\".\")\n",
    "            title = (\n",
    "                sentences[0][:50] + \"...\" if len(sentences[0]) > 50 else sentences[0]\n",
    "            )\n",
    "\n",
    "            knowledge_item = {\n",
    "                \"id\": f\"doc_chunk_{i}\",\n",
    "                \"title\": title,\n",
    "                \"content\": chunk,\n",
    "                \"type\": \"document\",\n",
    "                \"metadata\": {\"chunk_index\": i, \"word_count\": len(chunk.split())},\n",
    "            }\n",
    "            knowledge_items.append(knowledge_item)\n",
    "\n",
    "        return knowledge_items\n",
    "\n",
    "    def process_pdf(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"PDF 전체 처리 파이프라인\"\"\"\n",
    "        result = {\"document_knowledge\": [], \"table_qa_pairs\": [], \"summary\": {}}\n",
    "\n",
    "        # 1. 텍스트 추출 및 처리\n",
    "        print(\"텍스트 추출 중...\")\n",
    "        raw_text = self.extract_text_from_pdf(pdf_path)\n",
    "        cleaned_text = self.clean_text(raw_text)\n",
    "        text_chunks = self.split_into_chunks(cleaned_text)\n",
    "\n",
    "        # 2. 텍스트를 지식 구조로 변환\n",
    "        print(\"텍스트 지식 구조 생성 중...\")\n",
    "        result[\"document_knowledge\"] = self.text_to_knowledge_structure(text_chunks)\n",
    "\n",
    "        # 3. 표 추출 및 Q&A 쌍 생성\n",
    "        print(\"표 추출 및 Q&A 생성 중...\")\n",
    "        tables = self.extract_tables_from_pdf(pdf_path)\n",
    "\n",
    "        for table_idx, table in enumerate(tables):\n",
    "            if not table.empty:\n",
    "                qa_pairs = self.table_to_qa_pairs(table)\n",
    "                for qa in qa_pairs:\n",
    "                    qa[\"metadata\"][\"table_index\"] = table_idx\n",
    "                result[\"table_qa_pairs\"].extend(qa_pairs)\n",
    "\n",
    "        # 4. 요약 정보\n",
    "        result[\"summary\"] = {\n",
    "            \"total_text_chunks\": len(text_chunks),\n",
    "            \"total_tables\": len(tables),\n",
    "            \"total_qa_pairs\": len(result[\"table_qa_pairs\"]),\n",
    "            \"total_knowledge_items\": len(result[\"document_knowledge\"]),\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def save_knowledge_base(self, knowledge_data: Dict, output_path: str):\n",
    "        \"\"\"지식 베이스를 JSON 파일로 저장\"\"\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(knowledge_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"지식 베이스가 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 필요한 패키지 설치\n",
    "    # pip install PyPDF2 pandas tabula-py\n",
    "\n",
    "    converter = PDFToKnowledgeConverter()\n",
    "\n",
    "    # PDF 파일 경로\n",
    "    pdf_file = \".\\\\20250630_더존비즈온.pdf\"\n",
    "\n",
    "    try:\n",
    "        # PDF 처리\n",
    "        knowledge_data = converter.process_pdf(pdf_file)\n",
    "\n",
    "        # 결과 출력\n",
    "        print(\"\\n=== 처리 결과 요약 ===\")\n",
    "        print(f\"텍스트 청크 수: {knowledge_data['summary']['total_text_chunks']}\")\n",
    "        print(f\"추출된 표 수: {knowledge_data['summary']['total_tables']}\")\n",
    "        print(f\"생성된 Q&A 쌍 수: {knowledge_data['summary']['total_qa_pairs']}\")\n",
    "\n",
    "        # 지식 베이스 저장\n",
    "        converter.save_knowledge_base(knowledge_data, \"knowledge_base.json\")\n",
    "\n",
    "        # 샘플 출력\n",
    "        if knowledge_data[\"document_knowledge\"]:\n",
    "            print(\"\\n=== 문서 지식 샘플 ===\")\n",
    "            print(knowledge_data[\"document_knowledge\"][0])\n",
    "\n",
    "        if knowledge_data[\"table_qa_pairs\"]:\n",
    "            print(\"\\n=== 표 Q&A 샘플 ===\")\n",
    "            print(knowledge_data[\"table_qa_pairs\"][0])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ad56f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PDF 처리 시작 ===\n",
      "처리 중 오류 발생: 'PDFToKnowledgeConverter' object has no attribute 'process_pdf'\n",
      "가능한 해결방법:\n",
      "1. JPype1 설치: pip install jpype1\n",
      "2. tabula-py 재설치: pip install --upgrade tabula-py\n",
      "3. PDF 파일 인코딩 확인\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "\n",
    "class PDFToKnowledgeConverter:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = []\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"PDF에서 텍스트 추출 (인코딩 문제 해결)\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # 바이너리 모드로 파일 열기\n",
    "            with open(pdf_path, \"rb\") as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page in pdf_reader.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"PDF 텍스트 추출 오류: {e}\")\n",
    "        return text\n",
    "\n",
    "    def extract_tables_from_pdf(self, pdf_path: str) -> List[pd.DataFrame]:\n",
    "        \"\"\"PDF에서 표 추출 (인코딩 옵션 추가)\"\"\"\n",
    "        try:\n",
    "            import tabula\n",
    "\n",
    "            # 인코딩 옵션을 여러 개 시도\n",
    "            encodings = [\"utf-8\", \"cp949\", \"euc-kr\", \"cp1252\", \"iso-8859-1\"]\n",
    "\n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    print(f\"인코딩 {encoding} 시도 중...\")\n",
    "                    tables = tabula.read_pdf(\n",
    "                        pdf_path, pages=\"all\", multiple_tables=True, encoding=encoding\n",
    "                    )\n",
    "                    print(f\"성공: {encoding} 인코딩으로 표 추출 완료\")\n",
    "                    return tables\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "\n",
    "            print(\"모든 인코딩 방식 실패, 빈 리스트 반환\")\n",
    "            return []\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"tabula-py가 설치되지 않았습니다.\")\n",
    "            print(\"다음 명령어로 설치하세요:\")\n",
    "            print(\"pip install tabula-py\")\n",
    "            print(\"pip install jpype1\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"표 추출 오류: {e}\")\n",
    "            return []\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"텍스트 정제 (한글 지원)\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # 불필요한 공백 정리\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        # 특수문자 제거하되 한글, 영문, 숫자, 기본 문장부호 유지\n",
    "        text = re.sub(r\"[^\\w\\s가-힣.,?!():\\-]\", \" \", text)\n",
    "        return text.strip()\n",
    "\n",
    "    # ... 나머지 메서드들은 동일 ...\n",
    "\n",
    "\n",
    "# 안전한 실행 함수\n",
    "def safe_process_pdf(pdf_path: str):\n",
    "    \"\"\"안전한 PDF 처리 함수\"\"\"\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"파일을 찾을 수 없습니다: {pdf_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        converter = PDFToKnowledgeConverter()\n",
    "\n",
    "        print(\"=== PDF 처리 시작 ===\")\n",
    "        knowledge_data = converter.process_pdf(pdf_path)\n",
    "\n",
    "        print(\"\\n=== 처리 결과 ===\")\n",
    "        print(f\"텍스트 청크: {knowledge_data['summary']['total_text_chunks']}개\")\n",
    "        print(f\"추출된 표: {knowledge_data['summary']['total_tables']}개\")\n",
    "        print(f\"Q&A 쌍: {knowledge_data['summary']['total_qa_pairs']}개\")\n",
    "\n",
    "        # 결과 저장\n",
    "        output_file = \"buzzon_knowledge_base.json\"\n",
    "        converter.save_knowledge_base(knowledge_data, output_file)\n",
    "\n",
    "        return knowledge_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")\n",
    "        print(\"가능한 해결방법:\")\n",
    "        print(\"1. JPype1 설치: pip install jpype1\")\n",
    "        print(\"2. tabula-py 재설치: pip install --upgrade tabula-py\")\n",
    "        print(\"3. PDF 파일 인코딩 확인\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \".\\\\20250630_더존비즈온.pdf\"\n",
    "    result = safe_process_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953a7310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 PDF to 챗봇 지식 구조 변환기\n",
      "==================================================\n",
      "🔍 파일 경로 확인: 20250630_더존비즈온.pdf\n",
      "📁 절대 경로: c:\\workdir\\github-space-cap\\GPT-study-blog\\langchain_project\\lee\\20250630_더존비즈온.pdf\n",
      "📊 파일 크기: 1,741,038 bytes (1.66 MB)\n",
      "\n",
      "==================================================\n",
      "🚀 PDF 지식 구조 변환 시작\n",
      "==================================================\n",
      "📄 PDF 처리 시작: 20250630_더존비즈온.pdf\n",
      "📝 텍스트 추출 중...\n",
      "✅ 7개의 텍스트 청크 생성\n",
      "🔄 텍스트 지식 구조 생성 중...\n",
      "📊 표 추출 및 Q&A 생성 중...\n",
      "tabula-py를 사용하여 표 추출 시도...\n",
      "인코딩 utf-8 시도 중...\n",
      "utf-8 인코딩 실패: 'utf-8' codec can't decode byte 0xb8 in position 3153: invalid start byte\n",
      "인코딩 cp949 시도 중...\n",
      "✅ cp949 인코딩으로 36개 표 추출 성공\n",
      "📋 표 2 처리 중... (크기: (1, 1))\n",
      "📋 표 5 처리 중... (크기: (1, 1))\n",
      "📋 표 10 처리 중... (크기: (9, 24))\n",
      "📋 표 20 처리 중... (크기: (26, 3))\n",
      "📋 표 25 처리 중... (크기: (10, 13))\n",
      "📋 표 26 처리 중... (크기: (1, 2))\n",
      "📋 표 27 처리 중... (크기: (2, 3))\n",
      "📋 표 29 처리 중... (크기: (1, 2))\n",
      "📋 표 30 처리 중... (크기: (1, 2))\n",
      "📋 표 31 처리 중... (크기: (1, 3))\n",
      "📋 표 32 처리 중... (크기: (2, 3))\n",
      "📋 표 34 처리 중... (크기: (1, 1))\n",
      "📋 표 35 처리 중... (크기: (1, 2))\n",
      "✅ PDF 처리 완료!\n",
      "\n",
      "==================================================\n",
      "📊 처리 결과 요약\n",
      "==================================================\n",
      "📝 텍스트 청크: 7개\n",
      "📊 추출된 표: 36개\n",
      "❓ 생성된 Q&A 쌍: 32개\n",
      "📚 총 지식 아이템: 7개\n",
      "📄 원본 텍스트 길이: 10,129 문자\n",
      "💾 지식 베이스가 20250630_더존비즈온_knowledge_base.json에 저장되었습니다.\n",
      "\n",
      "==================================================\n",
      "📋 샘플 결과 미리보기\n",
      "==================================================\n",
      "\n",
      "📝 문서 지식 샘플:\n",
      "제목: --- 페이지 1 --- 2025\n",
      "내용: --- 페이지 1 --- 2025.06. 30 더존비즈온 (012510) 내 안에 디지털뱅킹이 있다(ft. 정부정책 수혜) Company Brief 제주은행에 디지털 관련 서비스 등이 접목됨에 따라 전국구 디지털뱅크로 전환되면서 성장성 가속화 동사 제주은행 2대주주로서 최대 수혜 지난 2021년 동사의 방대한 기업 데이터를 활용해 신한은행이 차별화된 금융 ...\n",
      "키워드: ['별도의', '동사와', '바탕으로', '데이터를', '활용해']\n",
      "\n",
      "📊 표 Q&A 샘플:\n",
      "질문: 표 2의 구조를 알려주세요.\n",
      "답변: 표 2은 1개 열, 1개 행으로 구성되어 있습니다. 열 이름은 Unnamed: 0입니다....\n",
      "\n",
      "🎉 처리가 성공적으로 완료되었습니다!\n",
      "생성된 지식 베이스를 챗봇 학습에 활용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class PDFToKnowledgeConverter:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = []\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"PDF에서 텍스트 추출 (인코딩 문제 해결)\"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # 바이너리 모드로 파일 열기\n",
    "            with open(pdf_path, \"rb\") as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    try:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += f\"\\n--- 페이지 {page_num + 1} ---\\n\"\n",
    "                            text += page_text + \"\\n\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"페이지 {page_num + 1} 텍스트 추출 실패: {e}\")\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            print(f\"PDF 텍스트 추출 오류: {e}\")\n",
    "        return text\n",
    "\n",
    "    def extract_tables_from_pdf(self, pdf_path: str) -> List[pd.DataFrame]:\n",
    "        \"\"\"PDF에서 표 추출 (인코딩 옵션 추가)\"\"\"\n",
    "        try:\n",
    "            import tabula\n",
    "\n",
    "            print(\"tabula-py를 사용하여 표 추출 시도...\")\n",
    "\n",
    "            # 인코딩 옵션을 여러 개 시도\n",
    "            encodings = [\"utf-8\", \"cp949\", \"euc-kr\", \"cp1252\", \"iso-8859-1\"]\n",
    "\n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    print(f\"인코딩 {encoding} 시도 중...\")\n",
    "                    tables = tabula.read_pdf(\n",
    "                        pdf_path,\n",
    "                        pages=\"all\",\n",
    "                        multiple_tables=True,\n",
    "                        encoding=encoding,\n",
    "                        lattice=True,  # 격자 기반 테이블 추출\n",
    "                        stream=True,  # 스트림 기반 테이블 추출도 시도\n",
    "                    )\n",
    "                    if tables:\n",
    "                        print(f\"✅ {encoding} 인코딩으로 {len(tables)}개 표 추출 성공\")\n",
    "                        return tables\n",
    "                except Exception as e:\n",
    "                    print(f\"{encoding} 인코딩 실패: {e}\")\n",
    "                    continue\n",
    "\n",
    "            print(\"⚠️ 모든 인코딩 방식 실패, 빈 리스트 반환\")\n",
    "            return []\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"❌ tabula-py가 설치되지 않았습니다.\")\n",
    "            print(\"다음 명령어로 설치하세요:\")\n",
    "            print(\"pip install tabula-py\")\n",
    "            print(\"pip install jpype1\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"표 추출 오류: {e}\")\n",
    "            return []\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"텍스트 정제 (한글 지원)\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        # 불필요한 공백 정리\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        # 특수문자 제거하되 한글, 영문, 숫자, 기본 문장부호 유지\n",
    "        text = re.sub(r\"[^\\w\\s가-힣.,?!():\\-]\", \" \", text)\n",
    "\n",
    "        # 연속된 공백을 하나로\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    def split_into_chunks(self, text: str, chunk_size: int = 500) -> List[str]:\n",
    "        \"\"\"텍스트를 청크로 분할\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "\n",
    "        # 문장 단위로 먼저 분할\n",
    "        sentences = re.split(r\"[.!?]\\s+\", text)\n",
    "\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        current_size = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            words = sentence.split()\n",
    "            sentence_size = len(words)\n",
    "\n",
    "            if current_size + sentence_size <= chunk_size:\n",
    "                current_chunk += sentence + \". \"\n",
    "                current_size += sentence_size\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \". \"\n",
    "                current_size = sentence_size\n",
    "\n",
    "        # 마지막 청크 추가\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def table_to_qa_pairs(self, table: pd.DataFrame, table_index: int) -> List[Dict]:\n",
    "        \"\"\"표를 Q&A 쌍으로 변환\"\"\"\n",
    "        qa_pairs = []\n",
    "\n",
    "        if table.empty:\n",
    "            return qa_pairs\n",
    "\n",
    "        try:\n",
    "            # 표의 기본 정보 Q&A\n",
    "            qa_pairs.append(\n",
    "                {\n",
    "                    \"question\": f\"표 {table_index + 1}의 구조를 알려주세요.\",\n",
    "                    \"answer\": f\"표 {table_index + 1}은 {len(table.columns)}개 열, {len(table)}개 행으로 구성되어 있습니다. 열 이름은 {', '.join(str(col) for col in table.columns)}입니다.\",\n",
    "                    \"source\": \"table_structure\",\n",
    "                    \"metadata\": {\n",
    "                        \"table_index\": table_index,\n",
    "                        \"columns\": len(table.columns),\n",
    "                        \"rows\": len(table),\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # 각 행의 데이터를 Q&A로 변환\n",
    "            for row_idx, row in table.iterrows():\n",
    "                if row_idx >= 10:  # 너무 많은 Q&A 생성 방지\n",
    "                    break\n",
    "\n",
    "                # 첫 번째 열을 기준으로 질문 생성\n",
    "                first_col = str(table.columns[0])\n",
    "                first_value = str(row.iloc[0]) if pd.notna(row.iloc[0]) else \"정보 없음\"\n",
    "\n",
    "                # 해당 행의 모든 정보를 포함한 답변 생성\n",
    "                answer_parts = []\n",
    "                for col, value in row.items():\n",
    "                    if pd.notna(value) and str(value).strip():\n",
    "                        answer_parts.append(f\"{col}: {value}\")\n",
    "\n",
    "                if answer_parts:\n",
    "                    question = f\"{first_col} '{first_value}'에 대한 정보를 알려주세요.\"\n",
    "                    answer = (\n",
    "                        f\"{first_col} '{first_value}'의 정보는 다음과 같습니다. \"\n",
    "                        + \", \".join(answer_parts)\n",
    "                        + \".\"\n",
    "                    )\n",
    "\n",
    "                    qa_pairs.append(\n",
    "                        {\n",
    "                            \"question\": question,\n",
    "                            \"answer\": answer,\n",
    "                            \"source\": \"table_row\",\n",
    "                            \"metadata\": {\n",
    "                                \"table_index\": table_index,\n",
    "                                \"row_index\": row_idx,\n",
    "                                \"primary_key\": first_value,\n",
    "                            },\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"표 {table_index} Q&A 변환 중 오류: {e}\")\n",
    "\n",
    "        return qa_pairs\n",
    "\n",
    "    def text_to_knowledge_structure(self, text_chunks: List[str]) -> List[Dict]:\n",
    "        \"\"\"텍스트 청크를 지식 구조로 변환\"\"\"\n",
    "        knowledge_items = []\n",
    "\n",
    "        for i, chunk in enumerate(text_chunks):\n",
    "            if not chunk.strip():\n",
    "                continue\n",
    "\n",
    "            # 첫 문장을 제목으로 추출\n",
    "            sentences = chunk.split(\".\")\n",
    "            title = sentences[0].strip()[:100]  # 제목 길이 제한\n",
    "            if not title:\n",
    "                title = f\"문서 섹션 {i + 1}\"\n",
    "\n",
    "            # 키워드 추출 (간단한 방법)\n",
    "            words = chunk.split()\n",
    "            keywords = []\n",
    "            for word in words:\n",
    "                if len(word) > 2 and word.isalpha():\n",
    "                    keywords.append(word)\n",
    "            keywords = list(set(keywords))[:10]  # 중복 제거 및 상위 10개\n",
    "\n",
    "            knowledge_item = {\n",
    "                \"id\": f\"doc_chunk_{i}\",\n",
    "                \"title\": title,\n",
    "                \"content\": chunk,\n",
    "                \"type\": \"document\",\n",
    "                \"keywords\": keywords,\n",
    "                \"metadata\": {\n",
    "                    \"chunk_index\": i,\n",
    "                    \"word_count\": len(chunk.split()),\n",
    "                    \"character_count\": len(chunk),\n",
    "                },\n",
    "            }\n",
    "            knowledge_items.append(knowledge_item)\n",
    "\n",
    "        return knowledge_items\n",
    "\n",
    "    def process_pdf(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"PDF 전체 처리 파이프라인\"\"\"\n",
    "        result = {\n",
    "            \"document_knowledge\": [],\n",
    "            \"table_qa_pairs\": [],\n",
    "            \"summary\": {},\n",
    "            \"metadata\": {\n",
    "                \"source_file\": pdf_path,\n",
    "                \"processing_timestamp\": pd.Timestamp.now().isoformat(),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        print(f\"📄 PDF 처리 시작: {pdf_path}\")\n",
    "\n",
    "        # 1. 텍스트 추출 및 처리\n",
    "        print(\"📝 텍스트 추출 중...\")\n",
    "        raw_text = self.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        if raw_text:\n",
    "            cleaned_text = self.clean_text(raw_text)\n",
    "            text_chunks = self.split_into_chunks(cleaned_text, chunk_size=300)\n",
    "            print(f\"✅ {len(text_chunks)}개의 텍스트 청크 생성\")\n",
    "\n",
    "            # 2. 텍스트를 지식 구조로 변환\n",
    "            print(\"🔄 텍스트 지식 구조 생성 중...\")\n",
    "            result[\"document_knowledge\"] = self.text_to_knowledge_structure(text_chunks)\n",
    "        else:\n",
    "            print(\"⚠️ 추출된 텍스트가 없습니다.\")\n",
    "\n",
    "        # 3. 표 추출 및 Q&A 쌍 생성\n",
    "        print(\"📊 표 추출 및 Q&A 생성 중...\")\n",
    "        tables = self.extract_tables_from_pdf(pdf_path)\n",
    "\n",
    "        for table_idx, table in enumerate(tables):\n",
    "            if not table.empty:\n",
    "                print(f\"📋 표 {table_idx + 1} 처리 중... (크기: {table.shape})\")\n",
    "                qa_pairs = self.table_to_qa_pairs(table, table_idx)\n",
    "                result[\"table_qa_pairs\"].extend(qa_pairs)\n",
    "\n",
    "        # 4. 요약 정보\n",
    "        result[\"summary\"] = {\n",
    "            \"total_text_chunks\": len(result[\"document_knowledge\"]),\n",
    "            \"total_tables\": len(tables),\n",
    "            \"total_qa_pairs\": len(result[\"table_qa_pairs\"]),\n",
    "            \"total_knowledge_items\": len(result[\"document_knowledge\"]),\n",
    "            \"original_text_length\": len(raw_text) if raw_text else 0,\n",
    "        }\n",
    "\n",
    "        print(\"✅ PDF 처리 완료!\")\n",
    "        return result\n",
    "\n",
    "    def save_knowledge_base(self, knowledge_data: Dict, output_path: str):\n",
    "        \"\"\"지식 베이스를 JSON 파일로 저장\"\"\"\n",
    "        try:\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(knowledge_data, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"💾 지식 베이스가 {output_path}에 저장되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 저장 실패: {e}\")\n",
    "\n",
    "\n",
    "def safe_process_pdf(pdf_path: str):\n",
    "    \"\"\"안전한 PDF 처리 함수\"\"\"\n",
    "\n",
    "    # Path 객체로 경로 처리\n",
    "    path = Path(pdf_path)\n",
    "\n",
    "    print(f\"🔍 파일 경로 확인: {path}\")\n",
    "    print(f\"📁 절대 경로: {path.absolute()}\")\n",
    "\n",
    "    if not path.exists():\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {pdf_path}\")\n",
    "\n",
    "        # 현재 디렉토리에서 PDF 파일 검색\n",
    "        print(\"\\n🔎 현재 디렉토리에서 PDF 파일 검색:\")\n",
    "        for pdf_file in Path(\".\").rglob(\"*.pdf\"):\n",
    "            print(f\"📄 발견: {pdf_file}\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # 파일 크기 확인\n",
    "        file_size = path.stat().st_size\n",
    "        print(f\"📊 파일 크기: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)\")\n",
    "\n",
    "        converter = PDFToKnowledgeConverter()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"🚀 PDF 지식 구조 변환 시작\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        knowledge_data = converter.process_pdf(str(path))\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"📊 처리 결과 요약\")\n",
    "        print(\"=\" * 50)\n",
    "        summary = knowledge_data[\"summary\"]\n",
    "        print(f\"📝 텍스트 청크: {summary['total_text_chunks']:,}개\")\n",
    "        print(f\"📊 추출된 표: {summary['total_tables']:,}개\")\n",
    "        print(f\"❓ 생성된 Q&A 쌍: {summary['total_qa_pairs']:,}개\")\n",
    "        print(f\"📚 총 지식 아이템: {summary['total_knowledge_items']:,}개\")\n",
    "        print(f\"📄 원본 텍스트 길이: {summary['original_text_length']:,} 문자\")\n",
    "\n",
    "        # 결과 저장\n",
    "        output_file = path.stem + \"_knowledge_base.json\"\n",
    "        converter.save_knowledge_base(knowledge_data, output_file)\n",
    "\n",
    "        # 샘플 출력\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"📋 샘플 결과 미리보기\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if knowledge_data[\"document_knowledge\"]:\n",
    "            print(\"\\n📝 문서 지식 샘플:\")\n",
    "            sample = knowledge_data[\"document_knowledge\"][0]\n",
    "            print(f\"제목: {sample['title']}\")\n",
    "            print(f\"내용: {sample['content'][:200]}...\")\n",
    "            print(f\"키워드: {sample['keywords'][:5]}\")\n",
    "\n",
    "        if knowledge_data[\"table_qa_pairs\"]:\n",
    "            print(\"\\n📊 표 Q&A 샘플:\")\n",
    "            sample = knowledge_data[\"table_qa_pairs\"][0]\n",
    "            print(f\"질문: {sample['question']}\")\n",
    "            print(f\"답변: {sample['answer'][:200]}...\")\n",
    "\n",
    "        return knowledge_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 처리 중 오류 발생: {e}\")\n",
    "        print(\"\\n🔧 해결 방법:\")\n",
    "        print(\"1. 필수 패키지 설치:\")\n",
    "        print(\"   pip install jpype1\")\n",
    "        print(\"   pip install tabula-py\")\n",
    "        print(\"   pip install PyPDF2\")\n",
    "        print(\"   pip install pandas\")\n",
    "        print(\"2. PDF 파일 인코딩 및 권한 확인\")\n",
    "        print(\"3. Java 설치 확인 (tabula-py 필요)\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 메인 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    # 더존비즈온 PDF 파일 처리\n",
    "    pdf_file = \".\\\\20250630_더존비즈온.pdf\"\n",
    "\n",
    "    print(\"🤖 PDF to 챗봇 지식 구조 변환기\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    result = safe_process_pdf(pdf_file)\n",
    "\n",
    "    if result:\n",
    "        print(\"\\n🎉 처리가 성공적으로 완료되었습니다!\")\n",
    "        print(\"생성된 지식 베이스를 챗봇 학습에 활용할 수 있습니다.\")\n",
    "    else:\n",
    "        print(\"\\n😞 처리에 실패했습니다. 오류 메시지를 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e4c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
