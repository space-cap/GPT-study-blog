import PyPDF2
import pandas as pd
import re
from typing import List, Dict
import json
import os
from pathlib import Path

class PDFToKnowledgeConverter:
    def __init__(self, output_dir: str = "knowledge_output"):
        self.knowledge_base = []
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.images_dir = self.output_dir / "images"
        self.images_dir.mkdir(exist_ok=True)
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì¸ì½”ë”© ë¬¸ì œ í•´ê²°)"""
        text = ""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            text += f"\n--- í˜ì´ì§€ {page_num + 1} ---\n"
                            text += page_text + "\n"
                    except Exception as e:
                        print(f"í˜ì´ì§€ {page_num + 1} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                        continue
        except Exception as e:
            print(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return text
    
    def extract_tables_from_pdf(self, pdf_path: str) -> List[pd.DataFrame]:
        """PDFì—ì„œ í‘œ ì¶”ì¶œ (ì¸ì½”ë”© ì˜µì…˜ ì¶”ê°€)"""
        try:
            import tabula
            print("tabula-pyë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œ ì¶”ì¶œ ì‹œë„...")
            
            encodings = ['utf-8', 'cp949', 'euc-kr', 'cp1252', 'iso-8859-1']
            
            for encoding in encodings:
                try:
                    print(f"ì¸ì½”ë”© {encoding} ì‹œë„ ì¤‘...")
                    tables = tabula.read_pdf(
                        pdf_path, 
                        pages='all', 
                        multiple_tables=True,
                        encoding=encoding,
                        lattice=True,
                        stream=True
                    )
                    if tables:
                        print(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ {len(tables)}ê°œ í‘œ ì¶”ì¶œ ì„±ê³µ")
                        return tables
                except Exception as e:
                    print(f"{encoding} ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
                    continue
                    
            print("âš ï¸ ëª¨ë“  ì¸ì½”ë”© ë°©ì‹ ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
            return []
            
        except ImportError:
            print("âŒ tabula-pyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        except Exception as e:
            print(f"í‘œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_images_from_pdf(self, pdf_path: str) -> List[Dict]:
        """PDFì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì €ì¥"""
        images_info = []
        
        try:
            import fitz  # PyMuPDF
            pdf_document = fitz.open(pdf_path)
            
            for page_num in range(len(pdf_document)):
                page = pdf_document.load_page(page_num)
                image_list = page.get_images(full=True)
                
                for img_index, img in enumerate(image_list):
                    xref = img[0]
                    pix = fitz.Pixmap(pdf_document, xref)
                    
                    if pix.n - pix.alpha < 4:
                        img_filename = f"page_{page_num+1}_img_{img_index+1}.png"
                        img_path = self.images_dir / img_filename
                        
                        pix.save(str(img_path))
                        
                        images_info.append({
                            "filename": img_filename,
                            "path": str(img_path),
                            "page": page_num + 1,
                            "index": img_index + 1,
                            "width": pix.width,
                            "height": pix.height,
                            "description": f"í˜ì´ì§€ {page_num+1}ì˜ ì´ë¯¸ì§€ {img_index+1}",
                            "tags": ["document_image", f"page_{page_num+1}"]
                        })
                    
                    pix = None
            
            pdf_document.close()
            print(f"âœ… {len(images_info)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
            
        except ImportError:
            print("âš ï¸ PyMuPDFê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return images_info
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ (í•œê¸€ ì§€ì›)"""
        if not text:
            return ""
        
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\sê°€-í£.,?!():\-]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def split_into_chunks(self, text: str, chunk_size: int = 500) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        if not text:
            return []
        
        sentences = re.split(r'[.!?]\s+', text)
        
        chunks = []
        current_chunk = ""
        current_size = 0
        
        for sentence in sentences:
            words = sentence.split()
            sentence_size = len(words)
            
            if current_size + sentence_size <= chunk_size:
                current_chunk += sentence + ". "
                current_size += sentence_size
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
                current_size = sentence_size
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def table_to_qa_pairs(self, table: pd.DataFrame, table_index: int) -> List[Dict]:
        """í‘œë¥¼ Q&A ìŒìœ¼ë¡œ ë³€í™˜"""
        qa_pairs = []
        
        if table.empty:
            return qa_pairs
        
        try:
            qa_pairs.append({
                "question": f"í‘œ {table_index + 1}ì˜ êµ¬ì¡°ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
                "answer": f"í‘œ {table_index + 1}ì€ {len(table.columns)}ê°œ ì—´, {len(table)}ê°œ í–‰ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—´ ì´ë¦„ì€ {', '.join(str(col) for col in table.columns)}ì…ë‹ˆë‹¤.",
                "source": "table_structure",
                "metadata": {
                    "table_index": table_index,
                    "columns": len(table.columns),
                    "rows": len(table)
                }
            })
            
            for row_idx, row in table.iterrows():
                if row_idx >= 10:
                    break
                    
                first_col = str(table.columns[0])
                first_value = str(row.iloc[0]) if pd.notna(row.iloc[0]) else "ì •ë³´ ì—†ìŒ"
                
                answer_parts = []
                for col, value in row.items():
                    if pd.notna(value) and str(value).strip():
                        answer_parts.append(f"{col}: {value}")
                
                if answer_parts:
                    question = f"{first_col} '{first_value}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
                    answer = f"{first_col} '{first_value}'ì˜ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. " + ", ".join(answer_parts) + "."
                    
                    qa_pairs.append({
                        "question": question,
                        "answer": answer,
                        "source": "table_row",
                        "metadata": {
                            "table_index": table_index,
                            "row_index": row_idx,
                            "primary_key": first_value
                        }
                    })
                    
        except Exception as e:
            print(f"í‘œ {table_index} Q&A ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return qa_pairs
    
    def text_to_knowledge_structure(self, text_chunks: List[str]) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ì§€ì‹ êµ¬ì¡°ë¡œ ë³€í™˜"""
        knowledge_items = []
        
        for i, chunk in enumerate(text_chunks):
            if not chunk.strip():
                continue
                
            sentences = chunk.split('.')
            title = sentences[0].strip()[:100]
            if not title:
                title = f"ë¬¸ì„œ ì„¹ì…˜ {i + 1}"
            
            words = chunk.split()
            keywords = []
            for word in words:
                if len(word) > 2 and word.isalpha():
                    keywords.append(word)
            keywords = list(set(keywords))[:10]
            
            knowledge_item = {
                "id": f"doc_chunk_{i}",
                "title": title,
                "content": chunk,
                "type": "document",
                "keywords": keywords,
                "metadata": {
                    "chunk_index": i,
                    "word_count": len(chunk.split()),
                    "character_count": len(chunk)
                }
            }
            knowledge_items.append(knowledge_item)
        
        return knowledge_items
    
    def process_pdf(self, pdf_path: str) -> Dict:
        """PDF ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        result = {
            "document_knowledge": [],
            "table_qa_pairs": [],
            "images": [],
            "summary": {},
            "metadata": {
                "source_file": pdf_path,
                "processing_timestamp": pd.Timestamp.now().isoformat()
            }
        }
        
        print(f"ğŸ“„ PDF ì²˜ë¦¬ ì‹œì‘: {pdf_path}")
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        print("ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
        raw_text = self.extract_text_from_pdf(pdf_path)
        
        if raw_text:
            cleaned_text = self.clean_text(raw_text)
            text_chunks = self.split_into_chunks(cleaned_text, chunk_size=300)
            print(f"âœ… {len(text_chunks)}ê°œì˜ í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„±")
            result["document_knowledge"] = self.text_to_knowledge_structure(text_chunks)
        else:
            print("âš ï¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # í‘œ ì¶”ì¶œ
        print("ğŸ“Š í‘œ ì¶”ì¶œ ë° Q&A ìƒì„± ì¤‘...")
        tables = self.extract_tables_from_pdf(pdf_path)
        
        for table_idx, table in enumerate(tables):
            if not table.empty:
                print(f"ğŸ“‹ í‘œ {table_idx + 1} ì²˜ë¦¬ ì¤‘... (í¬ê¸°: {table.shape})")
                qa_pairs = self.table_to_qa_pairs(table, table_idx)
                result["table_qa_pairs"].extend(qa_pairs)
        
        # ì´ë¯¸ì§€ ì¶”ì¶œ
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘...")
        images_info = self.extract_images_from_pdf(pdf_path)
        result['images'] = images_info
        
        # ìš”ì•½
        result["summary"] = {
            "total_text_chunks": len(result["document_knowledge"]),
            "total_tables": len(tables),
            "total_qa_pairs": len(result["table_qa_pairs"]),
            "total_images": len(images_info),
            "total_knowledge_items": len(result["document_knowledge"]),
            "original_text_length": len(raw_text) if raw_text else 0
        }
        
        print("âœ… PDF ì²˜ë¦¬ ì™„ë£Œ!")
        return result
    
    def save_readable_results(self, knowledge_data: Dict, output_name: str):
        """ê°€ë…ì„± ì¢‹ì€ í˜•íƒœë¡œ ê²°ê³¼ ì €ì¥"""
        
        # HTML ë³´ê³ ì„œ ìƒì„±
        html_path = self.output_dir / f"{output_name}_report.html"
        self.create_html_report(knowledge_data, html_path)
        
        # í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼
        txt_path = self.output_dir / f"{output_name}_summary.txt"
        self.create_text_summary(knowledge_data, txt_path)
        
        # Excel íŒŒì¼
        excel_path = self.output_dir / f"{output_name}_tables.xlsx"
        self.create_excel_tables(knowledge_data, excel_path)
        
        # CSV íŒŒì¼
        csv_path = self.output_dir / f"{output_name}_qa_pairs.csv"
        self.create_qa_csv(knowledge_data, csv_path)
        
        # JSON íŒŒì¼
        json_path = self.output_dir / f"{output_name}_knowledge.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ ê²°ê³¼ë¬¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"ğŸ“„ HTML ë³´ê³ ì„œ: {html_path}")
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ìš”ì•½: {txt_path}")
        print(f"ğŸ“Š Excel í‘œ: {excel_path}")
        print(f"â“ Q&A CSV: {csv_path}")
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í´ë”: {self.images_dir}")
        print(f"ğŸ’¾ JSON ë°ì´í„°: {json_path}")
    
    def create_html_report(self, knowledge_data: Dict, output_path: Path):
        """HTML ë³´ê³ ì„œ ìƒì„±"""
        html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PDF ì§€ì‹ êµ¬ì¡° ë³€í™˜ ë³´ê³ ì„œ</title>
    <style>
        body {{ font-family: 'Malgun Gothic', sans-serif; margin: 40px; line-height: 1.6; }}
        .header {{ background: #f8f9fa; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}
        .summary-box {{ background: #e3f2fd; padding: 15px; border-left: 4px solid #2196F3; margin: 20px 0; }}
        .section {{ margin: 30px 0; }}
        .knowledge-item {{ border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px; }}
        .qa-pair {{ background: #f5f5f5; padding: 10px; margin: 8px 0; border-radius: 5px; }}
        .question {{ font-weight: bold; color: #1976D2; }}
        .answer {{ margin-top: 5px; }}
        .image-gallery {{ display: flex; flex-wrap: wrap; gap: 10px; }}
        .image-item {{ border: 1px solid #ddd; padding: 10px; border-radius: 5px; text-align: center; }}
        .image-item img {{ max-width: 200px; max-height: 200px; }}
        .metadata {{ font-size: 0.9em; color: #666; margin-top: 10px; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“„ PDF ì§€ì‹ êµ¬ì¡° ë³€í™˜ ë³´ê³ ì„œ</h1>
        <p><strong>ì›ë³¸ íŒŒì¼:</strong> {knowledge_data.get('metadata', {}).get('source_file', 'Unknown')}</p>
        <p><strong>ì²˜ë¦¬ ì‹œê°„:</strong> {knowledge_data.get('metadata', {}).get('processing_timestamp', 'Unknown')}</p>
    </div>

    <div class="summary-box">
        <h2>ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½</h2>
        <ul>
            <li>ğŸ“ í…ìŠ¤íŠ¸ ì²­í¬: <strong>{knowledge_data['summary']['total_text_chunks']:,}ê°œ</strong></li>
            <li>ğŸ“Š ì¶”ì¶œëœ í‘œ: <strong>{knowledge_data['summary']['total_tables']:,}ê°œ</strong></li>
            <li>â“ Q&A ìŒ: <strong>{knowledge_data['summary']['total_qa_pairs']:,}ê°œ</strong></li>
            <li>ğŸ–¼ï¸ ì¶”ì¶œëœ ì´ë¯¸ì§€: <strong>{knowledge_data['summary']['total_images']:,}ê°œ</strong></li>
            <li>ğŸ“„ ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: <strong>{knowledge_data['summary']['original_text_length']:,} ë¬¸ì</strong></li>
        </ul>
    </div>
"""
        
        # ì´ë¯¸ì§€ ê°¤ëŸ¬ë¦¬
        if knowledge_data.get('images'):
            html_content += """
    <div class="section">
        <h2>ğŸ–¼ï¸ ì¶”ì¶œëœ ì´ë¯¸ì§€</h2>
        <div class="image-gallery">
"""
            for img in knowledge_data['images']:
                html_content += f"""
            <div class="image-item">
                <img src="images/{img['filename']}" alt="{img['description']}">
                <div class="metadata">
                    <strong>{img['description']}</strong><br>
                    í¬ê¸°: {img['width']} x {img['height']}<br>
                    íƒœê·¸: {', '.join(img['tags'])}
                </div>
            </div>
"""
            html_content += """
        </div>
    </div>
"""
        
        # ë¬¸ì„œ ì§€ì‹
        html_content += """
    <div class="section">
        <h2>ğŸ“š ë¬¸ì„œ ì§€ì‹ êµ¬ì¡°</h2>
"""
        for item in knowledge_data['document_knowledge'][:5]:
            html_content += f"""
        <div class="knowledge-item">
            <h3>{item['title']}</h3>
            <p>{item['content'][:500]}...</p>
            <div class="metadata">
                <strong>í‚¤ì›Œë“œ:</strong> {', '.join(item.get('keywords', [])[:8])}<br>
                <strong>ë‹¨ì–´ ìˆ˜:</strong> {item['metadata']['word_count']}<br>
                <strong>ë¬¸ì ìˆ˜:</strong> {item['metadata']['character_count']}
            </div>
        </div>
"""
        
        # Q&A
        if knowledge_data['table_qa_pairs']:
            html_content += """
    </div>
    
    <div class="section">
        <h2>â“ í‘œ ê¸°ë°˜ Q&A</h2>
"""
            for qa in knowledge_data['table_qa_pairs'][:10]:
                html_content += f"""
        <div class="qa-pair">
            <div class="question">Q: {qa['question']}</div>
            <div class="answer">A: {qa['answer']}</div>
        </div>
"""
        
        html_content += """
    </div>
</body>
</html>
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def create_text_summary(self, knowledge_data: Dict, output_path: Path):
        """í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ìƒì„±"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("ğŸ“„ PDF ì§€ì‹ êµ¬ì¡° ë³€í™˜ ìš”ì•½ ë³´ê³ ì„œ\n")
            f.write("="*60 + "\n\n")
            
            f.write(f"ì›ë³¸ íŒŒì¼: {knowledge_data.get('metadata', {}).get('source_file', 'Unknown')}\n")
            f.write(f"ì²˜ë¦¬ ì‹œê°„: {knowledge_data.get('metadata', {}).get('processing_timestamp', 'Unknown')}\n\n")
            
            f.write("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:\n")
            f.write(f"- í…ìŠ¤íŠ¸ ì²­í¬: {knowledge_data['summary']['total_text_chunks']:,}ê°œ\n")
            f.write(f"- ì¶”ì¶œëœ í‘œ: {knowledge_data['summary']['total_tables']:,}ê°œ\n")
            f.write(f"- Q&A ìŒ: {knowledge_data['summary']['total_qa_pairs']:,}ê°œ\n")
            f.write(f"- ì¶”ì¶œëœ ì´ë¯¸ì§€: {knowledge_data['summary']['total_images']:,}ê°œ\n")
            f.write(f"- ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {knowledge_data['summary']['original_text_length']:,} ë¬¸ì\n\n")
    
    def create_excel_tables(self, knowledge_data: Dict, output_path: Path):
        """Excel íŒŒì¼ ìƒì„±"""
        try:
            with pd.ExcelWriter(str(output_path), engine='openpyxl') as writer:
                summary_data = {
                    'í•­ëª©': ['í…ìŠ¤íŠ¸ ì²­í¬', 'ì¶”ì¶œëœ í‘œ', 'Q&A ìŒ', 'ì¶”ì¶œëœ ì´ë¯¸ì§€', 'ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´'],
                    'ê°œìˆ˜': [
                        knowledge_data['summary']['total_text_chunks'],
                        knowledge_data['summary']['total_tables'],
                        knowledge_data['summary']['total_qa_pairs'],
                        knowledge_data['summary']['total_images'],
                        knowledge_data['summary']['original_text_length']
                    ]
                }
                pd.DataFrame(summary_data).to_excel(writer, sheet_name='ìš”ì•½', index=False)
        except Exception as e:
            print(f"Excel íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def create_qa_csv(self, knowledge_data: Dict, output_path: Path):
        """Q&A CSV ìƒì„±"""
        try:
            qa_data = []
            for qa in knowledge_data['table_qa_pairs']:
                qa_data.append({
                    'ì§ˆë¬¸': qa['question'],
                    'ë‹µë³€': qa['answer'],
                    'ì¶œì²˜': qa['source'],
                    'í…Œì´ë¸”_ì¸ë±ìŠ¤': qa['metadata'].get('table_index', ''),
                    'í–‰_ì¸ë±ìŠ¤': qa['metadata'].get('row_index', ''),
                    'ì£¼ìš”í‚¤': qa['metadata'].get('primary_key', '')
                })
            
            if qa_data:
                pd.DataFrame(qa_data).to_csv(str(output_path), index=False, encoding='utf-8-sig')
        except Exception as e:
            print(f"CSV íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")

# ì‹¤í–‰ í•¨ìˆ˜
def process_pdf_with_enhanced_output(pdf_path: str):
    """í–¥ìƒëœ ì¶œë ¥ ê¸°ëŠ¥ì´ í¬í•¨ëœ PDF ì²˜ë¦¬"""
    
    path = Path(pdf_path)
    if not path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return None
    
    try:
        output_name = path.stem
        converter = PDFToKnowledgeConverter(output_dir=f"{output_name}_results")
        
        print("ğŸš€ PDF ì²˜ë¦¬ ì‹œì‘ (ì´ë¯¸ì§€ í¬í•¨)")
        knowledge_data = converter.process_pdf(str(path))
        
        converter.save_readable_results(knowledge_data, output_name)
        
        print("\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
        return knowledge_data
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None

# ì‹¤í–‰
if __name__ == "__main__":
    pdf_file = ".\\20250630_ë”ì¡´ë¹„ì¦ˆì˜¨.pdf"
    process_pdf_with_enhanced_output(pdf_file)
