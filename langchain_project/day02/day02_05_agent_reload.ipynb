{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a334c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `PopulationLookup` with `ì„œìš¸`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m9,733,509ëª… (2025ë…„ ê¸°ì¤€)\u001b[0m\u001b[32;1m\u001b[1;3mì„œìš¸ì˜ ì¸êµ¬ëŠ” 9,733,509ëª…ì…ë‹ˆë‹¤ (2025ë…„ ê¸°ì¤€).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ì„œìš¸ì˜ ì¸êµ¬ëŠ” 9,733,509ëª…ì…ë‹ˆë‹¤ (2025ë…„ ê¸°ì¤€).\n",
      "\n",
      "=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ (LLM Fallback) ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `PopulationLookup` with `ëŒ€êµ¬`\n",
      "\n",
      "\n",
      "\u001b[0mğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\n",
      "ëŒ€êµ¬ì˜ ì¸êµ¬ëŠ” 2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ì•½ 240ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸êµ¬ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë³€ë™í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ëŒ€êµ¬ì˜ ì¸êµ¬ì— ëŒ€í•œ ì •í™•í•œ ìˆ˜ì¹˜ëŠ” ëŒ€êµ¬ê´‘ì—­ì‹œì²­ì´ë‚˜ í†µê³„ì²­ì˜ ê³µì‹ ìë£Œë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool, AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜\n",
    "load_dotenv()\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# ê¸°ì¡´ ë„êµ¬ í•¨ìˆ˜ë“¤\n",
    "def add_two(x: str) -> str:\n",
    "    try:\n",
    "        return str(float(x) + 2)\n",
    "    except Exception:\n",
    "        raise ValueError(\"ìˆ«ìë§Œ ì…ë ¥í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "def population_lookup(city: str) -> str:\n",
    "    data = {\n",
    "        \"ì„œìš¸\": \"9,733,509ëª… (2025ë…„ ê¸°ì¤€)\",\n",
    "        \"ë¶€ì‚°\": \"3,400,000ëª… (2025ë…„ ê¸°ì¤€)\",\n",
    "    }\n",
    "    result = data.get(city.strip().lower())\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        raise ValueError(f\"{city}ì˜ ì¸êµ¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ë„êµ¬ ë° LLM ì„¤ì •\n",
    "tools = [\n",
    "    Tool(name=\"AddTwo\", func=add_two, description=\"ìˆ«ì ì…ë ¥ ì‹œ 2ë¥¼ ë”í•©ë‹ˆë‹¤.\"),\n",
    "    Tool(\n",
    "        name=\"PopulationLookup\",\n",
    "        func=population_lookup,\n",
    "        description=\"ë„ì‹œ ì´ë¦„ ì…ë ¥ ì‹œ ì¸êµ¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPEN_API_KEY, verbose=True)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Agent ìƒì„±\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Fallback í•¨ìˆ˜\n",
    "def llm_fallback(inputs):\n",
    "    user_input = inputs.get(\"input\", \"\")\n",
    "    response = llm.invoke(f\"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”: {user_input}\")\n",
    "    return {\n",
    "        \"output\": f\"ğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\\n{response.content}\",\n",
    "        \"intermediate_steps\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "# Fallbackì´ ì ìš©ëœ Agent\n",
    "smart_agent = agent_executor.with_fallbacks([RunnableLambda(llm_fallback)])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if __name__ == \"__main__\":\n",
    "    # ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´\n",
    "    print(\"=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ ===\")\n",
    "    result1 = smart_agent.invoke({\"input\": \"ì„œìš¸ì˜ ì¸êµ¬ëŠ”?\"})\n",
    "    print(result1[\"output\"])\n",
    "\n",
    "    print(\"\\n=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ (LLM Fallback) ===\")\n",
    "    result2 = smart_agent.invoke({\"input\": \"ëŒ€êµ¬ì˜ ì¸êµ¬ëŠ”?\"})\n",
    "    print(result2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ed96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
