{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e53f335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac6fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 도구에서 찾을 수 있는 정보 ===\n",
      "🤖 도구에서 정보를 찾지 못해 일반 지식으로 답변합니다:\n",
      "2023년 기준으로 서울의 인구는 약 9백만 명 정도입니다. 하지만 인구는 지속적으로 변동할 수 있으므로, 최신 통계 자료를 확인하는 것이 좋습니다. 서울특별시청이나 통계청의 공식 웹사이트에서 최신 정보를 확인할 수 있습니다.\n",
      "\n",
      "========================================\n",
      "\n",
      "=== 도구에서 찾을 수 없는 정보 (LLM Fallback) ===\n",
      "🤖 도구에서 정보를 찾지 못해 일반 지식으로 답변합니다:\n",
      "대구의 인구는 2023년 기준으로 약 240만 명 정도입니다. 하지만 인구는 시간이 지남에 따라 변동할 수 있으므로, 최신 정보를 확인하는 것이 좋습니다. 대구의 인구에 대한 정확한 수치는 대구광역시청이나 통계청의 공식 자료를 참고하시기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.agents import (\n",
    "    create_react_agent as create_react_agent_runnable,\n",
    ")  # 변경: 함수 이름 충돌 방지\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# --- 환경 변수 설정 ---\n",
    "load_dotenv()\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# --- 기존 도구 함수들 (변경 없음) ---\n",
    "def add_two(x: str) -> str:\n",
    "    \"\"\"숫자 입력 시 2를 더합니다.\"\"\"\n",
    "    try:\n",
    "        return str(float(x) + 2)\n",
    "    except Exception:\n",
    "        raise ValueError(\"숫자만 입력해 주세요.\")\n",
    "\n",
    "\n",
    "def population_lookup(city: str) -> str:\n",
    "    \"\"\"도시 이름 입력 시 인구 정보를 반환합니다.\"\"\"\n",
    "    data = {\n",
    "        \"서울\": \"9,733,509명 (2025년 기준)\",\n",
    "        \"부산\": \"3,400,000명 (2025년 기준)\",\n",
    "    }\n",
    "    result = data.get(city.strip().lower())\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        # 이 ValueError가 fallback을 트리거하는 핵심입니다.\n",
    "        raise ValueError(f\"{city}의 인구 정보를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "# --- 도구 및 LLM 설정 (변경 없음) ---\n",
    "tools = [\n",
    "    Tool(name=\"AddTwo\", func=add_two, description=\"숫자 입력 시 2를 더합니다.\"),\n",
    "    Tool(\n",
    "        name=\"PopulationLookup\",\n",
    "        func=population_lookup,\n",
    "        description=\"도시 이름 입력 시 인구 정보를 반환합니다. 도시 이름은 '서울', '부산'만 가능합니다.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPEN_API_KEY)\n",
    "\n",
    "\n",
    "# --- LangGraph 상태 정의 (변경 없음) ---\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "# --- ReAct 프롬프트 가져오기 ---\n",
    "# LangGraph의 create_react_agent가 내부적으로 사용하는 것과 동일한 프롬프트를 사용합니다.\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "\n",
    "# --- 노드 정의: Agent와 Action 분리 ---\n",
    "\n",
    "# 1. Agent Node: LLM을 사용하여 다음 단계를 결정 (추론)\n",
    "# 이 노드는 도구를 직접 실행하지 않고, 어떤 도구를 사용할지에 대한 결정만 내립니다.\n",
    "agent_runnable = create_react_agent_runnable(llm, tools, prompt)\n",
    "\n",
    "\n",
    "def run_agent(state: AgentState):\n",
    "    \"\"\"Agent Runnable을 실행하여 추론하고, 그 결과를 state에 추가합니다.\"\"\"\n",
    "    agent_output = agent_runnable.invoke(state)\n",
    "    return {\"messages\": [agent_output]}\n",
    "\n",
    "\n",
    "# 2. Action Node: Agent가 결정한 도구를 실행\n",
    "# ToolNode는 도구 실행 시 발생하는 오류를 잡지 않고 상위로 전달합니다.\n",
    "# 이로 인해 ValueError가 발생하면 그래프 실행이 중단되고 fallback이 트리거됩니다.\n",
    "action_node = ToolNode(tools)\n",
    "\n",
    "\n",
    "# --- Fallback 함수 정의 (변경 없음) ---\n",
    "def create_llm_fallback():\n",
    "    def llm_fallback(state: AgentState) -> dict:\n",
    "        user_input = state[\"messages\"][0].content\n",
    "        prompt = f\"다음 질문에 답해주세요: {user_input}\"\n",
    "        response = llm.invoke(prompt)\n",
    "        fallback_message = f\"🤖 도구에서 정보를 찾지 못해 일반 지식으로 답변합니다:\\n{response.content}\"\n",
    "        return {\"messages\": [AIMessage(content=fallback_message)]}\n",
    "\n",
    "    return llm_fallback\n",
    "\n",
    "\n",
    "# --- 라우팅 함수 정의 ---\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Agent의 마지막 메시지를 보고 다음 경로를 결정합니다.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # AIMessage에 tool_calls가 있으면 'action' 노드로 이동\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"action\"\n",
    "    # tool_calls가 없으면(최종 답변이면) 그래프 종료\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "# --- Graph 생성 및 컴파일 (수정된 로직) ---\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# 추론 노드와 실행 노드를 각각 추가\n",
    "graph.add_node(\"agent\", run_agent)\n",
    "graph.add_node(\"action\", action_node)\n",
    "\n",
    "# 시작점을 'agent' 노드로 설정\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "# 조건부 엣지: 'agent' 노드 실행 후 'should_continue' 함수 결과에 따라 분기\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"action\": \"action\",  # 'action'을 반환하면 'action' 노드로 이동\n",
    "        END: END,  # END를 반환하면 종료\n",
    "    },\n",
    ")\n",
    "\n",
    "# 'action' 노드 실행 후에는 항상 다시 'agent' 노드로 돌아가서 결과를 보고 다음 행동 결정\n",
    "graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Fallback 함수 생성\n",
    "llm_fallback_runnable = RunnableLambda(create_llm_fallback())\n",
    "\n",
    "# 그래프 컴파일 및 fallback 연결\n",
    "smart_agent = graph.compile().with_fallbacks(fallbacks=[llm_fallback_runnable])\n",
    "\n",
    "\n",
    "# --- 테스트 (변경 없음) ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 도구에서 찾을 수 있는 정보 ===\")\n",
    "    inputs1 = {\"messages\": [HumanMessage(content=\"서울의 인구는?\")]}\n",
    "    result1 = smart_agent.invoke(inputs1)\n",
    "    print(result1[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "\n",
    "    print(\"=== 도구에서 찾을 수 없는 정보 (LLM Fallback) ===\")\n",
    "    inputs2 = {\"messages\": [HumanMessage(content=\"대구의 인구는?\")]}\n",
    "    result2 = smart_agent.invoke(inputs2)\n",
    "    print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c84154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
