{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e53f335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac6fea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ ===\n",
      "ğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\n",
      "2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 9ë°±ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸êµ¬ëŠ” ì§€ì†ì ìœ¼ë¡œ ë³€ë™í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì‹  í†µê³„ ìë£Œë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì„œìš¸íŠ¹ë³„ì‹œì²­ì´ë‚˜ í†µê³„ì²­ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "========================================\n",
      "\n",
      "=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ (LLM Fallback) ===\n",
      "ğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\n",
      "ëŒ€êµ¬ì˜ ì¸êµ¬ëŠ” 2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ì•½ 240ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸êµ¬ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë³€ë™í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ëŒ€êµ¬ì˜ ì¸êµ¬ì— ëŒ€í•œ ì •í™•í•œ ìˆ˜ì¹˜ëŠ” ëŒ€êµ¬ê´‘ì—­ì‹œì²­ì´ë‚˜ í†µê³„ì²­ì˜ ê³µì‹ ìë£Œë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.agents import (\n",
    "    create_react_agent as create_react_agent_runnable,\n",
    ")  # ë³€ê²½: í•¨ìˆ˜ ì´ë¦„ ì¶©ëŒ ë°©ì§€\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# --- í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ---\n",
    "load_dotenv()\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# --- ê¸°ì¡´ ë„êµ¬ í•¨ìˆ˜ë“¤ (ë³€ê²½ ì—†ìŒ) ---\n",
    "def add_two(x: str) -> str:\n",
    "    \"\"\"ìˆ«ì ì…ë ¥ ì‹œ 2ë¥¼ ë”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        return str(float(x) + 2)\n",
    "    except Exception:\n",
    "        raise ValueError(\"ìˆ«ìë§Œ ì…ë ¥í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "def population_lookup(city: str) -> str:\n",
    "    \"\"\"ë„ì‹œ ì´ë¦„ ì…ë ¥ ì‹œ ì¸êµ¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    data = {\n",
    "        \"ì„œìš¸\": \"9,733,509ëª… (2025ë…„ ê¸°ì¤€)\",\n",
    "        \"ë¶€ì‚°\": \"3,400,000ëª… (2025ë…„ ê¸°ì¤€)\",\n",
    "    }\n",
    "    result = data.get(city.strip().lower())\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        # ì´ ValueErrorê°€ fallbackì„ íŠ¸ë¦¬ê±°í•˜ëŠ” í•µì‹¬ì…ë‹ˆë‹¤.\n",
    "        raise ValueError(f\"{city}ì˜ ì¸êµ¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# --- ë„êµ¬ ë° LLM ì„¤ì • (ë³€ê²½ ì—†ìŒ) ---\n",
    "tools = [\n",
    "    Tool(name=\"AddTwo\", func=add_two, description=\"ìˆ«ì ì…ë ¥ ì‹œ 2ë¥¼ ë”í•©ë‹ˆë‹¤.\"),\n",
    "    Tool(\n",
    "        name=\"PopulationLookup\",\n",
    "        func=population_lookup,\n",
    "        description=\"ë„ì‹œ ì´ë¦„ ì…ë ¥ ì‹œ ì¸êµ¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ë„ì‹œ ì´ë¦„ì€ 'ì„œìš¸', 'ë¶€ì‚°'ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPEN_API_KEY)\n",
    "\n",
    "\n",
    "# --- LangGraph ìƒíƒœ ì •ì˜ (ë³€ê²½ ì—†ìŒ) ---\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "# --- ReAct í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° ---\n",
    "# LangGraphì˜ create_react_agentê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "\n",
    "# --- ë…¸ë“œ ì •ì˜: Agentì™€ Action ë¶„ë¦¬ ---\n",
    "\n",
    "# 1. Agent Node: LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì • (ì¶”ë¡ )\n",
    "# ì´ ë…¸ë“œëŠ” ë„êµ¬ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì§€ ì•Šê³ , ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ì— ëŒ€í•œ ê²°ì •ë§Œ ë‚´ë¦½ë‹ˆë‹¤.\n",
    "agent_runnable = create_react_agent_runnable(llm, tools, prompt)\n",
    "\n",
    "\n",
    "def run_agent(state: AgentState):\n",
    "    \"\"\"Agent Runnableì„ ì‹¤í–‰í•˜ì—¬ ì¶”ë¡ í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ stateì— ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
    "    agent_output = agent_runnable.invoke(state)\n",
    "    return {\"messages\": [agent_output]}\n",
    "\n",
    "\n",
    "# 2. Action Node: Agentê°€ ê²°ì •í•œ ë„êµ¬ë¥¼ ì‹¤í–‰\n",
    "# ToolNodeëŠ” ë„êµ¬ ì‹¤í–‰ ì‹œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ì¡ì§€ ì•Šê³  ìƒìœ„ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "# ì´ë¡œ ì¸í•´ ValueErrorê°€ ë°œìƒí•˜ë©´ ê·¸ë˜í”„ ì‹¤í–‰ì´ ì¤‘ë‹¨ë˜ê³  fallbackì´ íŠ¸ë¦¬ê±°ë©ë‹ˆë‹¤.\n",
    "action_node = ToolNode(tools)\n",
    "\n",
    "\n",
    "# --- Fallback í•¨ìˆ˜ ì •ì˜ (ë³€ê²½ ì—†ìŒ) ---\n",
    "def create_llm_fallback():\n",
    "    def llm_fallback(state: AgentState) -> dict:\n",
    "        user_input = state[\"messages\"][0].content\n",
    "        prompt = f\"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”: {user_input}\"\n",
    "        response = llm.invoke(prompt)\n",
    "        fallback_message = f\"ğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\\n{response.content}\"\n",
    "        return {\"messages\": [AIMessage(content=fallback_message)]}\n",
    "\n",
    "    return llm_fallback\n",
    "\n",
    "\n",
    "# --- ë¼ìš°íŒ… í•¨ìˆ˜ ì •ì˜ ---\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Agentì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ë³´ê³  ë‹¤ìŒ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # AIMessageì— tool_callsê°€ ìˆìœ¼ë©´ 'action' ë…¸ë“œë¡œ ì´ë™\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"action\"\n",
    "    # tool_callsê°€ ì—†ìœ¼ë©´(ìµœì¢… ë‹µë³€ì´ë©´) ê·¸ë˜í”„ ì¢…ë£Œ\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "# --- Graph ìƒì„± ë° ì»´íŒŒì¼ (ìˆ˜ì •ëœ ë¡œì§) ---\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# ì¶”ë¡  ë…¸ë“œì™€ ì‹¤í–‰ ë…¸ë“œë¥¼ ê°ê° ì¶”ê°€\n",
    "graph.add_node(\"agent\", run_agent)\n",
    "graph.add_node(\"action\", action_node)\n",
    "\n",
    "# ì‹œì‘ì ì„ 'agent' ë…¸ë“œë¡œ ì„¤ì •\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: 'agent' ë…¸ë“œ ì‹¤í–‰ í›„ 'should_continue' í•¨ìˆ˜ ê²°ê³¼ì— ë”°ë¼ ë¶„ê¸°\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"action\": \"action\",  # 'action'ì„ ë°˜í™˜í•˜ë©´ 'action' ë…¸ë“œë¡œ ì´ë™\n",
    "        END: END,  # ENDë¥¼ ë°˜í™˜í•˜ë©´ ì¢…ë£Œ\n",
    "    },\n",
    ")\n",
    "\n",
    "# 'action' ë…¸ë“œ ì‹¤í–‰ í›„ì—ëŠ” í•­ìƒ ë‹¤ì‹œ 'agent' ë…¸ë“œë¡œ ëŒì•„ê°€ì„œ ê²°ê³¼ë¥¼ ë³´ê³  ë‹¤ìŒ í–‰ë™ ê²°ì •\n",
    "graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Fallback í•¨ìˆ˜ ìƒì„±\n",
    "llm_fallback_runnable = RunnableLambda(create_llm_fallback())\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼ ë° fallback ì—°ê²°\n",
    "smart_agent = graph.compile().with_fallbacks(fallbacks=[llm_fallback_runnable])\n",
    "\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ (ë³€ê²½ ì—†ìŒ) ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ ===\")\n",
    "    inputs1 = {\"messages\": [HumanMessage(content=\"ì„œìš¸ì˜ ì¸êµ¬ëŠ”?\")]}\n",
    "    result1 = smart_agent.invoke(inputs1)\n",
    "    print(result1[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")\n",
    "\n",
    "    print(\"=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ (LLM Fallback) ===\")\n",
    "    inputs2 = {\"messages\": [HumanMessage(content=\"ëŒ€êµ¬ì˜ ì¸êµ¬ëŠ”?\")]}\n",
    "    result2 = smart_agent.invoke(inputs2)\n",
    "    print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c84154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
