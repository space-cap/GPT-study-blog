{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38168b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e982845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mì„œìš¸ì˜ ì¸êµ¬ ì •ë³´ë¥¼ ì•Œì•„ë³´ì•„ì•¼ í•©ë‹ˆë‹¤. \n",
      "Action: PopulationLookup \n",
      "Action Input: \"ì„œìš¸\" \u001b[0m\u001b[33;1m\u001b[1;3m9,733,509ëª… (2025ë…„ ê¸°ì¤€)\u001b[0m\u001b[32;1m\u001b[1;3mThought: ì„œìš¸ì˜ ì¸êµ¬ëŠ” 9,733,509ëª…ì…ë‹ˆë‹¤. ì´ì œ ìµœì¢… ë‹µë³€ì„ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "Final Answer: ì„œìš¸ì˜ ì¸êµ¬ëŠ” 9,733,509ëª…ì…ë‹ˆë‹¤.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ì„œìš¸ì˜ ì¸êµ¬ëŠ” 9,733,509ëª…ì…ë‹ˆë‹¤.\n",
      "\n",
      "=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ (LLM Fallback) ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mëŒ€êµ¬ì˜ ì¸êµ¬ ì •ë³´ë¥¼ ì•Œì•„ë³´ì•„ì•¼ í•©ë‹ˆë‹¤. \n",
      "Action: PopulationLookup \n",
      "Action Input: \"ëŒ€êµ¬\" \u001b[0mğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\n",
      "ëŒ€êµ¬ì˜ ì¸êµ¬ëŠ” 2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ì•½ 240ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸êµ¬ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë³€ë™í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ëŒ€êµ¬ì— ëŒ€í•œ ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain import hub\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜\n",
    "load_dotenv()\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# ê¸°ì¡´ ë„êµ¬ í•¨ìˆ˜ë“¤\n",
    "def add_two(x: str) -> str:\n",
    "    try:\n",
    "        return str(float(x) + 2)\n",
    "    except Exception:\n",
    "        raise ValueError(\"ìˆ«ìë§Œ ì…ë ¥í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "def population_lookup(city: str) -> str:\n",
    "    data = {\n",
    "        \"ì„œìš¸\": \"9,733,509ëª… (2025ë…„ ê¸°ì¤€)\",\n",
    "        \"ë¶€ì‚°\": \"3,400,000ëª… (2025ë…„ ê¸°ì¤€)\",\n",
    "    }\n",
    "    result = data.get(city.strip().lower())\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        raise ValueError(f\"{city}ì˜ ì¸êµ¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ë„êµ¬ ë° LLM ì„¤ì •\n",
    "tools = [\n",
    "    Tool(name=\"AddTwo\", func=add_two, description=\"ìˆ«ì ì…ë ¥ ì‹œ 2ë¥¼ ë”í•©ë‹ˆë‹¤.\"),\n",
    "    Tool(\n",
    "        name=\"PopulationLookup\",\n",
    "        func=population_lookup,\n",
    "        description=\"ë„ì‹œ ì´ë¦„ ì…ë ¥ ì‹œ ì¸êµ¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPEN_API_KEY, verbose=True\n",
    ")\n",
    "\n",
    "# ReAct í”„ë¡¬í”„íŠ¸ ì„¤ì • (ë°©ë²• 1: ì§ì ‘ ì •ì˜)\n",
    "react_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "{tools}\n",
    "\n",
    "ë„êµ¬ ì´ë¦„: {tool_names}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:\n",
    "\n",
    "Question: ë‹µë³€í•´ì•¼ í•  ì…ë ¥ ì§ˆë¬¸\n",
    "Thought: ë¬´ì—‡ì„ í•´ì•¼ í• ì§€ ìƒê°í•´ë³´ì„¸ìš”\n",
    "Action: ìˆ˜í–‰í•  ì•¡ì…˜, [{tool_names}] ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤\n",
    "Action Input: ì•¡ì…˜ì— ëŒ€í•œ ì…ë ¥\n",
    "Observation: ì•¡ì…˜ì˜ ê²°ê³¼\n",
    "... (ì´ Thought/Action/Action Input/Observationì„ í•„ìš”í•œ ë§Œí¼ ë°˜ë³µ)\n",
    "Thought: ì´ì œ ìµœì¢… ë‹µë³€ì„ ì•Œì•˜ìŠµë‹ˆë‹¤\n",
    "Final Answer: ì›ë˜ ì…ë ¥ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€\n",
    "\n",
    "ì‹œì‘í•˜ì„¸ìš”!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ë˜ëŠ” ë°©ë²• 2: LangChain Hubì—ì„œ ê¸°ë³¸ ReAct í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "# react_prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Agent ìƒì„±\n",
    "# agent = create_react_agent(llm, tools, react_prompt, debug=True)\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=react_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "# Fallback í•¨ìˆ˜\n",
    "def llm_fallback(inputs):\n",
    "    user_input = inputs.get(\"input\", \"\")\n",
    "    response = llm.invoke(f\"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”: {user_input}\")\n",
    "    return {\n",
    "        \"output\": f\"ğŸ¤– ë„êµ¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:\\n{response.content}\",\n",
    "        \"intermediate_steps\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "# Fallbackì´ ì ìš©ëœ Agent\n",
    "smart_agent = agent_executor.with_fallbacks([RunnableLambda(llm_fallback)])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if __name__ == \"__main__\":\n",
    "    # ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´\n",
    "    print(\"=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ ===\")\n",
    "    result1 = smart_agent.invoke({\"input\": \"ì„œìš¸ì˜ ì¸êµ¬ëŠ”?\"})\n",
    "    print(result1[\"output\"])\n",
    "\n",
    "    print(\"\\n=== ë„êµ¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ (LLM Fallback) ===\")\n",
    "    result2 = smart_agent.invoke({\"input\": \"ëŒ€êµ¬ì˜ ì¸êµ¬ëŠ”?\"})\n",
    "    print(result2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc4e6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
