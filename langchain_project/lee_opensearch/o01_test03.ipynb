{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ï≤≠ÎÖÑÏ†ïÏ±Ö Í≤ÄÏÉâ ÏãúÏä§ÌÖú - OpenSearch + LangChain + ChatOpenAI\n",
        "\n",
        "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏùÄ Î°úÏª¨ OpenSearch 3.1.0Í≥º LangChain, ChatOpenAIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ \n",
        "youth_policies Ïù∏Îç±Ïä§ÏóêÏÑú ÏßàÎ¨∏ Í∏∞Î∞ò Í≤ÄÏÉâÏùÑ Íµ¨ÌòÑÌïòÎäî Îã®Í≥ÑÎ≥Ñ Í∞ÄÏù¥ÎìúÏûÖÎãàÎã§.\n",
        "\n",
        "## ÏãúÏä§ÌÖú Íµ¨ÏÑ±\n",
        "- **Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•ÏÜå**: OpenSearch 3.1.0\n",
        "- **AI Î™®Îç∏**: OpenAI GPT-4o-mini\n",
        "- **ÏûÑÎ≤†Îî©**: OpenAI text-embedding-3-small\n",
        "- **ÌîÑÎ†àÏûÑÏõåÌÅ¨**: LangChain\n",
        "- **Ïù∏Îç±Ïä§**: youth_policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Îã®Í≥Ñ: ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò (ÌÑ∞ÎØ∏ÎÑêÏóêÏÑú Ïã§Ìñâ)\n",
        "# !pip install langchain langchain-openai langchain-community opensearch-py python-dotenv\n",
        "\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# LangChain Í¥ÄÎ†® ÏûÑÌè¨Ìä∏\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏\n",
        "from opensearchpy import OpenSearch\n",
        "\n",
        "# ÌôòÍ≤Ω Î≥ÄÏàò Í¥ÄÎ¶¨\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "print(\"‚úÖ ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ ÏôÑÎ£å\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Îã®Í≥Ñ: ÌôòÍ≤Ω ÏÑ§Ï†ï"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .env ÌååÏùº Î°úÎìú (.env ÌååÏùºÏù¥ ÏûàÎäî Í≤ΩÏö∞)\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI API ÌÇ§ ÏÑ§Ï†ï (Ïã§Ï†ú ÌÇ§Î°ú Î≥ÄÍ≤Ω ÌïÑÏöî)\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")\n",
        "\n",
        "# OpenSearch Ïó∞Í≤∞ ÏÑ§Ï†ï\n",
        "OPENSEARCH_HOST = \"localhost\"\n",
        "OPENSEARCH_PORT = 9200\n",
        "OPENSEARCH_INDEX = \"youth_policies\"\n",
        "\n",
        "# OpenSearch Ïó∞Í≤∞ Ï†ïÎ≥¥\n",
        "OPENSEARCH_CONFIG = {\n",
        "    \"hosts\": [{\"host\": OPENSEARCH_HOST, \"port\": OPENSEARCH_PORT}],\n",
        "    \"http_compress\": True,\n",
        "    \"use_ssl\": False,\n",
        "    \"verify_certs\": False,\n",
        "    \"timeout\": 30\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ ÌôòÍ≤Ω ÏÑ§Ï†ï ÏôÑÎ£å\")\n",
        "print(f\"OpenSearch Ïó∞Í≤∞: {OPENSEARCH_HOST}:{OPENSEARCH_PORT}\")\n",
        "print(f\"Ïù∏Îç±Ïä§: {OPENSEARCH_INDEX}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Îã®Í≥Ñ: OpenSearch Ïó∞Í≤∞ ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±\n",
        "client = OpenSearch(**OPENSEARCH_CONFIG)\n",
        "\n",
        "try:\n",
        "    # ÌÅ¥Îü¨Ïä§ÌÑ∞ ÏÉÅÌÉú ÌôïÏù∏\n",
        "    cluster_info = client.info()\n",
        "    print(\"‚úÖ OpenSearch Ïó∞Í≤∞ ÏÑ±Í≥µ!\")\n",
        "    print(f\"ÌÅ¥Îü¨Ïä§ÌÑ∞ Ïù¥Î¶Ñ: {cluster_info['cluster_name']}\")\n",
        "    print(f\"Î≤ÑÏ†Ñ: {cluster_info['version']['number']}\")\n",
        "    \n",
        "    # Ïù∏Îç±Ïä§ Ï°¥Ïû¨ ÌôïÏù∏\n",
        "    if client.indices.exists(index=OPENSEARCH_INDEX):\n",
        "        print(f\"‚úÖ Ïù∏Îç±Ïä§ '{OPENSEARCH_INDEX}' Ï°¥Ïû¨ ÌôïÏù∏\")\n",
        "        \n",
        "        # Ïù∏Îç±Ïä§ ÌÜµÍ≥Ñ Ï°∞Ìöå\n",
        "        stats = client.indices.stats(index=OPENSEARCH_INDEX)\n",
        "        doc_count = stats['indices'][OPENSEARCH_INDEX]['total']['docs']['count']\n",
        "        print(f\"Î¨∏ÏÑú Ïàò: {doc_count}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Ïù∏Îç±Ïä§ '{OPENSEARCH_INDEX}'Í∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå OpenSearch Ïó∞Í≤∞ Ïã§Ìå®: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Îã®Í≥Ñ: ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ïù∏Îç±Ïä§ÏóêÏÑú ÏÉòÌîå Î¨∏ÏÑú Ï°∞Ìöå\n",
        "try:\n",
        "    sample_query = {\n",
        "        \"size\": 2,\n",
        "        \"query\": {\n",
        "            \"match_all\": {}\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    response = client.search(index=OPENSEARCH_INDEX, body=sample_query)\n",
        "    \n",
        "    print(f\"‚úÖ ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå ÏÑ±Í≥µ\")\n",
        "    print(f\"Ï¥ù Î¨∏ÏÑú Ïàò: {response['hits']['total']['value']}\")\n",
        "    \n",
        "    # Ï≤´ Î≤àÏß∏ Î¨∏ÏÑú Ï∂úÎ†•\n",
        "    if response['hits']['hits']:\n",
        "        first_doc = response['hits']['hits'][0]['_source']\n",
        "        print(f\"\\nüìÑ Ï≤´ Î≤àÏß∏ Î¨∏ÏÑú:\")\n",
        "        print(f\"Ï†ïÏ±ÖÎ™Ö: {first_doc.get('plcyNm', 'N/A')}\")\n",
        "        print(f\"Ï†ïÏ±ÖÏÑ§Î™Ö: {first_doc.get('plcyExplnCn', 'N/A')[:100]}...\")\n",
        "        print(f\"Ï£ºÍ¥ÄÍ∏∞Í¥Ä: {first_doc.get('sprvsnInstCdNm', 'N/A')}\")\n",
        "        print(f\"ÎåÄÏÉÅÏó∞Î†π: {first_doc.get('sprtTrgtMinAge', 'N/A')}ÏÑ∏ ~ {first_doc.get('sprtTrgtMaxAge', 'N/A')}ÏÑ∏\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå Ïã§Ìå®: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Îã®Í≥Ñ: OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÌÅ¥ÎûòÏä§ Ï†ïÏùò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OpenSearchClient:\n",
        "    def __init__(self, config: Dict, index_name: str):\n",
        "        \"\"\"OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî\"\"\"\n",
        "        self.client = OpenSearch(**config)\n",
        "        self.index_name = index_name\n",
        "    \n",
        "    def search_documents(self, query: str, size: int = 5) -> Dict:\n",
        "        \"\"\"ÌÇ§ÏõåÎìú Í∏∞Î∞ò Î¨∏ÏÑú Í≤ÄÏÉâ\"\"\"\n",
        "        search_body = {\n",
        "            \"size\": size,\n",
        "            \"query\": {\n",
        "                \"bool\": {\n",
        "                    \"should\": [\n",
        "                        {\n",
        "                            \"multi_match\": {\n",
        "                                \"query\": query,\n",
        "                                \"fields\": [\n",
        "                                    \"plcyNm^3\",           # Ï†ïÏ±ÖÎ™ÖÏóê Í∞ÄÏ§ëÏπò 3Î∞∞\n",
        "                                    \"plcyKywdNm^2\",       # ÌÇ§ÏõåÎìúÏóê Í∞ÄÏ§ëÏπò 2Î∞∞\n",
        "                                    \"plcyExplnCn^2\",      # ÏÑ§Î™ÖÏóê Í∞ÄÏ§ëÏπò 2Î∞∞\n",
        "                                    \"plcySprtCn^1.5\",     # ÏßÄÏõêÎÇ¥Ïö©Ïóê Í∞ÄÏ§ëÏπò 1.5Î∞∞\n",
        "                                    \"lclsfNm\",            # ÎåÄÎ∂ÑÎ•ò\n",
        "                                    \"mclsfNm\"             # Ï§ëÎ∂ÑÎ•ò\n",
        "                                ],\n",
        "                                \"type\": \"best_fields\",\n",
        "                                \"fuzziness\": \"AUTO\"\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"match_phrase\": {\n",
        "                                \"plcyNm\": {\n",
        "                                    \"query\": query,\n",
        "                                    \"boost\": 2.0\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"highlight\": {\n",
        "                \"fields\": {\n",
        "                    \"plcyNm\": {\"pre_tags\": [\"<mark>\"], \"post_tags\": [\"</mark>\"]},\n",
        "                    \"plcyExplnCn\": {\"pre_tags\": [\"<mark>\"], \"post_tags\": [\"</mark>\"]},\n",
        "                    \"plcySprtCn\": {\"pre_tags\": [\"<mark>\"], \"post_tags\": [\"</mark>\"]}\n",
        "                }\n",
        "            },\n",
        "            \"_source\": {\n",
        "                \"excludes\": [\"zipCodes\", \"majorCodes\", \"jobCodes\", \"schoolCodes\"]\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.client.search(index=self.index_name, body=search_body)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Í≤ÄÏÉâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "            return {\"hits\": {\"hits\": []}}\n",
        "    \n",
        "    def search_by_filters(self, age: Optional[int] = None, \n",
        "                         region: Optional[str] = None, \n",
        "                         category: Optional[str] = None, \n",
        "                         size: int = 10) -> Dict:\n",
        "        \"\"\"ÌïÑÌÑ∞ Í∏∞Î∞ò Í≤ÄÏÉâ\"\"\"\n",
        "        filters = []\n",
        "        \n",
        "        # ÎÇòÏù¥ ÌïÑÌÑ∞\n",
        "        if age:\n",
        "            filters.append({\n",
        "                \"range\": {\n",
        "                    \"sprtTrgtMinAge\": {\"lte\": age}\n",
        "                }\n",
        "            })\n",
        "            filters.append({\n",
        "                \"range\": {\n",
        "                    \"sprtTrgtMaxAge\": {\"gte\": age}\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        # ÏßÄÏó≠ ÌïÑÌÑ∞ (Ïö∞Ìé∏Î≤àÌò∏ Í∏∞Î∞ò)\n",
        "        if region:\n",
        "            filters.append({\n",
        "                \"wildcard\": {\n",
        "                    \"zipCd\": f\"*{region}*\"\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        # Ïπ¥ÌÖåÍ≥†Î¶¨ ÌïÑÌÑ∞\n",
        "        if category:\n",
        "            filters.append({\n",
        "                \"multi_match\": {\n",
        "                    \"query\": category,\n",
        "                    \"fields\": [\"lclsfNm\", \"mclsfNm\"],\n",
        "                    \"fuzziness\": \"AUTO\"\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        search_body = {\n",
        "            \"size\": size,\n",
        "            \"query\": {\n",
        "                \"bool\": {\n",
        "                    \"filter\": filters\n",
        "                }\n",
        "            } if filters else {\"match_all\": {}}\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.client.search(index=self.index_name, body=search_body)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ÌïÑÌÑ∞ Í≤ÄÏÉâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "            return {\"hits\": {\"hits\": []}}\n",
        "    \n",
        "    def get_policy_statistics(self) -> Dict:\n",
        "        \"\"\"Ï†ïÏ±Ö ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï°∞Ìöå\"\"\"\n",
        "        stats_query = {\n",
        "            \"size\": 0,\n",
        "            \"aggs\": {\n",
        "                \"by_category\": {\n",
        "                    \"terms\": {\n",
        "                        \"field\": \"lclsfNm\",\n",
        "                        \"size\": 10\n",
        "                    }\n",
        "                },\n",
        "                \"by_region\": {\n",
        "                    \"terms\": {\n",
        "                        \"field\": \"sprvsnInstCdNm\",\n",
        "                        \"size\": 10\n",
        "                    }\n",
        "                },\n",
        "                \"age_stats\": {\n",
        "                    \"stats\": {\n",
        "                        \"field\": \"sprtTrgtMinAge\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.client.search(index=self.index_name, body=stats_query)\n",
        "            return response.get(\"aggregations\", {})\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ÌÜµÍ≥Ñ Ï°∞Ìöå Ï§ë Ïò§Î•ò: {e}\")\n",
        "            return {}\n",
        "\n",
        "# OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
        "search_client = OpenSearchClient(OPENSEARCH_CONFIG, OPENSEARCH_INDEX)\n",
        "print(\"‚úÖ OpenSearch ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÌÅ¥ÎûòÏä§ ÏÉùÏÑ± ÏôÑÎ£å\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Îã®Í≥Ñ: OpenSearch Í≤ÄÏÉâ Í∏∞Îä• ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌÇ§ÏõåÎìú Í≤ÄÏÉâ ÌÖåÏä§Ìä∏\n",
        "print(\"üîç ÌÇ§ÏõåÎìú Í≤ÄÏÉâ ÌÖåÏä§Ìä∏\")\n",
        "test_queries = [\"SW ÍµêÏú°\", \"Ï∑®ÏóÖ ÏßÄÏõê\", \"Ï∞ΩÏóÖ\"]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nÍ≤ÄÏÉâÏñ¥: '{query}'\")\n",
        "    results = search_client.search_documents(query, size=3)\n",
        "    \n",
        "    hits = results.get(\"hits\", {}).get(\"hits\", [])\n",
        "    print(f\"Í≤ÄÏÉâ Í≤∞Í≥º: {len(hits)}Í∞ú\")\n",
        "    \n",
        "    for i, hit in enumerate(hits, 1):\n",
        "        source = hit[\"_source\"]\n",
        "        score = hit[\"_score\"]\n",
        "        print(f\"  {i}. {source.get('plcyNm', 'N/A')} (Ï†êÏàò: {score:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Îã®Í≥Ñ: ÌïÑÌÑ∞ Í≤ÄÏÉâ ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç ÌïÑÌÑ∞ Í≤ÄÏÉâ ÌÖåÏä§Ìä∏\")\n",
        "\n",
        "# ÎÇòÏù¥ ÌïÑÌÑ∞ ÌÖåÏä§Ìä∏\n",
        "print(\"\\n1. ÎÇòÏù¥ ÌïÑÌÑ∞ ÌÖåÏä§Ìä∏ (25ÏÑ∏)\")\n",
        "age_results = search_client.search_by_filters(age=25, size=3)\n",
        "age_hits = age_results.get(\"hits\", {}).get(\"hits\", [])\n",
        "print(f\"25ÏÑ∏ ÎåÄÏÉÅ Ï†ïÏ±Ö: {len(age_hits)}Í∞ú\")\n",
        "\n",
        "for i, hit in enumerate(age_hits, 1):\n",
        "    source = hit[\"_source\"]\n",
        "    print(f\"  {i}. {source.get('plcyNm', 'N/A')} \"\n",
        "          f\"(ÎåÄÏÉÅ: {source.get('sprtTrgtMinAge', 'N/A')}ÏÑ∏ ~ {source.get('sprtTrgtMaxAge', 'N/A')}ÏÑ∏)\")\n",
        "\n",
        "# Ïπ¥ÌÖåÍ≥†Î¶¨ ÌïÑÌÑ∞ ÌÖåÏä§Ìä∏\n",
        "print(\"\\n2. Ïπ¥ÌÖåÍ≥†Î¶¨ ÌïÑÌÑ∞ ÌÖåÏä§Ìä∏ ('ÍµêÏú°')\")\n",
        "category_results = search_client.search_by_filters(category=\"ÍµêÏú°\", size=3)\n",
        "category_hits = category_results.get(\"hits\", {}).get(\"hits\", [])\n",
        "print(f\"ÍµêÏú° Í¥ÄÎ†® Ï†ïÏ±Ö: {len(category_hits)}Í∞ú\")\n",
        "\n",
        "for i, hit in enumerate(category_hits, 1):\n",
        "    source = hit[\"_source\"]\n",
        "    print(f\"  {i}. {source.get('plcyNm', 'N/A')} \"\n",
        "          f\"(Î∂ÑÎ•ò: {source.get('lclsfNm', 'N/A')} > {source.get('mclsfNm', 'N/A')})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Îã®Í≥Ñ: ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï°∞Ìöå ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä Ï†ïÏ±Ö ÌÜµÍ≥Ñ Ï†ïÎ≥¥\")\n",
        "stats = search_client.get_policy_statistics()\n",
        "\n",
        "if stats:\n",
        "    # Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌÜµÍ≥Ñ\n",
        "    if \"by_category\" in stats:\n",
        "        print(\"\\nüìà Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Ï†ïÏ±Ö Ïàò:\")\n",
        "        for bucket in stats[\"by_category\"][\"buckets\"]:\n",
        "            print(f\"  - {bucket['key']}: {bucket['doc_count']}Í∞ú\")\n",
        "    \n",
        "    # ÏßÄÏó≠Î≥Ñ ÌÜµÍ≥Ñ (ÏÉÅÏúÑ 5Í∞ú)\n",
        "    if \"by_region\" in stats:\n",
        "        print(\"\\nüåç ÏßÄÏó≠Î≥Ñ Ï†ïÏ±Ö Ïàò (ÏÉÅÏúÑ 5Í∞ú):\")\n",
        "        for bucket in stats[\"by_region\"][\"buckets\"][:5]:\n",
        "            print(f\"  - {bucket['key']}: {bucket['doc_count']}Í∞ú\")\n",
        "    \n",
        "    # ÎÇòÏù¥ ÌÜµÍ≥Ñ\n",
        "    if \"age_stats\" in stats:\n",
        "        age_stats = stats[\"age_stats\"]\n",
        "        print(f\"\\nüë• ÎåÄÏÉÅ Ïó∞Î†π ÌÜµÍ≥Ñ:\")\n",
        "        print(f\"  - ÏµúÏÜå Ïó∞Î†π: {age_stats.get('min', 'N/A')}ÏÑ∏\")\n",
        "        print(f\"  - ÏµúÎåÄ Ïó∞Î†π: {age_stats.get('max', 'N/A')}ÏÑ∏\")\n",
        "        print(f\"  - ÌèâÍ∑† Ïó∞Î†π: {age_stats.get('avg', 'N/A'):.1f}ÏÑ∏\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Îã®Í≥Ñ: LangChainÍ≥º OpenAI Ï¥àÍ∏∞Ìôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenAI API ÌÇ§ ÌôïÏù∏\n",
        "if not OPENAI_API_KEY or OPENAI_API_KEY == \"your_openai_api_key_here\":\n",
        "    print(\"‚ö†Ô∏è OpenAI API ÌÇ§Î•º ÏÑ§Ï†ïÌï¥Ï£ºÏÑ∏Ïöî!\")\n",
        "    print(\"OPENAI_API_KEY Î≥ÄÏàòÏóê Ïã§Ï†ú API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî.\")\n",
        "else:\n",
        "    try:\n",
        "        # OpenAI ÏûÑÎ≤†Îî© Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
        "        embeddings = OpenAIEmbeddings(\n",
        "            openai_api_key=OPENAI_API_KEY,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        \n",
        "        # ChatOpenAI Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
        "        llm = ChatOpenAI(\n",
        "            openai_api_key=OPENAI_API_KEY,\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.1\n",
        "        )\n",
        "        \n",
        "        print(\"‚úÖ LangChain Î∞è OpenAI Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
        "        print(f\"ÏûÑÎ≤†Îî© Î™®Îç∏: text-embedding-3-small\")\n",
        "        print(f\"LLM Î™®Îç∏: gpt-4o-mini\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå OpenAI Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10Îã®Í≥Ñ: Í≤ÄÏÉâ ÏùòÎèÑ Ï∂îÏ∂ú ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_search_intent(user_query: str) -> Dict:\n",
        "    \"\"\"ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏóêÏÑú Í≤ÄÏÉâ ÏùòÎèÑ Ï∂îÏ∂ú\"\"\"\n",
        "    intent_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"\"\"\n",
        "        Îã§Ïùå ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Í≤ÄÏÉâÏóê ÌïÑÏöîÌïú Ï†ïÎ≥¥Î•º JSON ÌòïÌÉúÎ°ú Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî:\n",
        "        \n",
        "        ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: {query}\n",
        "        \n",
        "        Ï∂îÏ∂úÌï† Ï†ïÎ≥¥:\n",
        "        - keywords: Í≤ÄÏÉâ ÌÇ§ÏõåÎìúÎì§ (Î¶¨Ïä§Ìä∏)\n",
        "        - age: ÎÇòÏù¥ (Ïà´Ïûê, Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ null)\n",
        "        - region: ÏßÄÏó≠ (Î¨∏ÏûêÏó¥, Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ null)\n",
        "        - category: Ï†ïÏ±Ö Î∂ÑÏïº (ÍµêÏú°, Ï∑®ÏóÖ, Ï∞ΩÏóÖ, Ï£ºÍ±∞, Î≥µÏßÄ Îì±, Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ null)\n",
        "        \n",
        "        ÏùëÎãµÏùÄ Î∞òÎìúÏãú JSON ÌòïÌÉúÎ°úÎßå Ìï¥Ï£ºÏÑ∏Ïöî.\n",
        "        ÏòàÏãú: {{\"keywords\": [\"Ï∑®ÏóÖ\", \"ÏßÄÏõê\"], \"age\": 25, \"region\": \"ÏÑúÏö∏\", \"category\": \"Ï∑®ÏóÖ\"}}\n",
        "        \"\"\"\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        response = llm.invoke([\n",
        "            HumanMessage(content=intent_prompt.format(query=user_query))\n",
        "        ])\n",
        "        \n",
        "        # JSON ÌååÏã± ÏãúÎèÑ\n",
        "        intent_data = json.loads(response.content)\n",
        "        return intent_data\n",
        "        \n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON ÌååÏã± Ïã§Ìå®, Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©\")\n",
        "        return {\n",
        "            \"keywords\": [user_query],\n",
        "            \"age\": None,\n",
        "            \"region\": None,\n",
        "            \"category\": None\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ÏùòÎèÑ Ï∂îÏ∂ú Ïã§Ìå®: {e}\")\n",
        "        return {\n",
        "            \"keywords\": [user_query],\n",
        "            \"age\": None,\n",
        "            \"region\": None,\n",
        "            \"category\": None\n",
        "        }\n",
        "\n",
        "# ÏùòÎèÑ Ï∂îÏ∂ú ÌÖåÏä§Ìä∏\n",
        "if 'llm' in locals():\n",
        "    print(\"üß† Í≤ÄÏÉâ ÏùòÎèÑ Ï∂îÏ∂ú ÌÖåÏä§Ìä∏\")\n",
        "    \n",
        "    test_queries = [\n",
        "        \"25ÏÑ∏ Ï≤≠ÎÖÑÏùÑ ÏúÑÌïú SW ÍµêÏú° Ï†ïÏ±ÖÏù¥ ÏûàÎÇòÏöî?\",\n",
        "        \"ÏÑúÏö∏ÏóêÏÑú Ï∞ΩÏóÖ ÏßÄÏõê Î∞õÏùÑ Ïàò ÏûàÎäî Ï†ïÏ±Ö ÏïåÎ†§Ï£ºÏÑ∏Ïöî\",\n",
        "        \"Ï∑®ÏóÖ Ï§ÄÎπÑÏÉùÏùÑ ÏúÑÌïú ÏßÄÏõê Ï†ïÏ±ÖÏùÑ Ï∞æÍ≥† ÏûàÏäµÎãàÎã§\"\n",
        "    ]\n",
        "    \n",
        "    for query in test_queries:\n",
        "        print(f\"\\nÏßàÎ¨∏: {query}\")\n",
        "        intent = extract_search_intent(query)\n",
        "        print(f\"Ï∂îÏ∂úÎêú ÏùòÎèÑ: {intent}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è OpenAI Î™®Îç∏Ïù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. API ÌÇ§Î•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11Îã®Í≥Ñ: Î©îÏù∏ Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ ÌÅ¥ÎûòÏä§ Ï†ïÏùò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YouthPolicySearchAgent:\n",
        "    def __init__(self, search_client: OpenSearchClient, llm, embeddings):\n",
        "        \"\"\"Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ Ï¥àÍ∏∞Ìôî\"\"\"\n",
        "        self.search_client = search_client\n",
        "        self.llm = llm\n",
        "        self.embeddings = embeddings\n",
        "        \n",
        "        # ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï\n",
        "        self.system_prompt = \"\"\"\n",
        "        ÎãπÏã†ÏùÄ Ï≤≠ÎÖÑÏ†ïÏ±Ö Ï†ÑÎ¨∏ ÏÉÅÎã¥ÏÇ¨ÏûÖÎãàÎã§. \n",
        "        ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Í¥ÄÎ†®Îêú Ï≤≠ÎÖÑÏ†ïÏ±ÖÏùÑ Ï∞æÏïÑÏÑú ÏπúÏ†àÌïòÍ≥† Ï†ïÌôïÌïòÍ≤å ÏïàÎÇ¥Ìï¥Ï£ºÏÑ∏Ïöî.\n",
        "        \n",
        "        Îã§Ïùå Ï†ïÎ≥¥Î•º Ìè¨Ìï®ÌïòÏó¨ ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî:\n",
        "        1. Ï†ïÏ±ÖÎ™ÖÍ≥º Í∞ÑÎã®Ìïú ÏÑ§Î™Ö\n",
        "        2. Ï£ºÏöî ÏßÄÏõê ÎÇ¥Ïö©\n",
        "        3. ÏßÄÏõê ÎåÄÏÉÅ (Ïó∞Î†π, Ï°∞Í±¥ Îì±)\n",
        "        4. Ïã†Ï≤≠ Î∞©Î≤ï Î∞è Ï†àÏ∞®\n",
        "        5. Í¥ÄÎ†® Í∏∞Í¥Ä Ï†ïÎ≥¥\n",
        "        6. Ïã†Ï≤≠ URL (ÏûàÎäî Í≤ΩÏö∞)\n",
        "        \n",
        "        ÎãµÎ≥ÄÏùÄ ÌïúÍµ≠Ïñ¥Î°ú ÌïòÏãúÍ≥†, Íµ¨Ï≤¥Ï†ÅÏù¥Í≥† Ïã§Ïö©Ï†ÅÏù∏ Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî.\n",
        "        Ï†ïÏ±ÖÏù¥ Ïó¨Îü¨ Í∞úÏù∏ Í≤ΩÏö∞ Í∞ÅÍ∞ÅÏùÑ Î™ÖÌôïÌûà Íµ¨Î∂ÑÌïòÏó¨ ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî.\n",
        "        \"\"\"\n",
        "    \n",
        "    def extract_search_intent(self, user_query: str) -> Dict:\n",
        "        \"\"\"ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏóêÏÑú Í≤ÄÏÉâ ÏùòÎèÑ Ï∂îÏ∂ú\"\"\"\n",
        "        intent_prompt = PromptTemplate(\n",
        "            input_variables=[\"query\"],\n",
        "            template=\"\"\"\n",
        "            Îã§Ïùå ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Í≤ÄÏÉâÏóê ÌïÑÏöîÌïú Ï†ïÎ≥¥Î•º JSON ÌòïÌÉúÎ°ú Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî:\n",
        "            \n",
        "            ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: {query}\n",
        "            \n",
        "            Ï∂îÏ∂úÌï† Ï†ïÎ≥¥:\n",
        "            - keywords: Í≤ÄÏÉâ ÌÇ§ÏõåÎìúÎì§ (Î¶¨Ïä§Ìä∏)\n",
        "            - age: ÎÇòÏù¥ (Ïà´Ïûê, Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ null)\n",
        "            - region: ÏßÄÏó≠ (Î¨∏ÏûêÏó¥, Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ null)\n",
        "            - category: Ï†ïÏ±Ö Î∂ÑÏïº (ÍµêÏú°, Ï∑®ÏóÖ, Ï∞ΩÏóÖ, Ï£ºÍ±∞, Î≥µÏßÄ Îì±, Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ null)\n",
        "            \n",
        "            ÏùëÎãµÏùÄ Î∞òÎìúÏãú JSON ÌòïÌÉúÎ°úÎßå Ìï¥Ï£ºÏÑ∏Ïöî.\n",
        "            \"\"\"\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            response = self.llm.invoke([\n",
        "                HumanMessage(content=intent_prompt.format(query=user_query))\n",
        "            ])\n",
        "            \n",
        "            intent_data = json.loads(response.content)\n",
        "            return intent_data\n",
        "            \n",
        "        except json.JSONDecodeError:\n",
        "            return {\n",
        "                \"keywords\": [user_query],\n",
        "                \"age\": None,\n",
        "                \"region\": None,\n",
        "                \"category\": None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ÏùòÎèÑ Ï∂îÏ∂ú Ïã§Ìå®: {e}\")\n",
        "            return {\n",
        "                \"keywords\": [user_query],\n",
        "                \"age\": None,\n",
        "                \"region\": None,\n",
        "                \"category\": None\n",
        "            }\n",
        "    \n",
        "    def search_policies(self, user_query: str, max_results: int = 3) -> List[Dict]:\n",
        "        \"\"\"Ï†ïÏ±Ö Í≤ÄÏÉâ ÏàòÌñâ\"\"\"\n",
        "        # 1. Í≤ÄÏÉâ ÏùòÎèÑ Ï∂îÏ∂ú\n",
        "        intent = self.extract_search_intent(user_query)\n",
        "        \n",
        "        # 2. ÌÇ§ÏõåÎìú Í∏∞Î∞ò Í≤ÄÏÉâ\n",
        "        search_results = []\n",
        "        \n",
        "        if intent.get(\"keywords\"):\n",
        "            keyword_query = \" \".join(intent[\"keywords\"])\n",
        "            keyword_results = self.search_client.search_documents(\n",
        "                query=keyword_query, \n",
        "                size=max_results\n",
        "            )\n",
        "            if keyword_results:\n",
        "                search_results.extend(keyword_results.get(\"hits\", {}).get(\"hits\", []))\n",
        "        \n",
        "        # 3. ÌïÑÌÑ∞ Í∏∞Î∞ò Í≤ÄÏÉâ (Ï∂îÍ∞Ä)\n",
        "        filter_results = self.search_client.search_by_filters(\n",
        "            age=intent.get(\"age\"),\n",
        "            region=intent.get(\"region\"),\n",
        "            category=intent.get(\"category\"),\n",
        "            size=max_results\n",
        "        )\n",
        "        \n",
        "        if filter_results:\n",
        "            filter_hits = filter_results.get(\"hits\", {}).get(\"hits\", [])\n",
        "            # Ï§ëÎ≥µ Ï†úÍ±∞ÌïòÎ©∞ Í≤∞Í≥º Ï∂îÍ∞Ä\n",
        "            existing_ids = {hit[\"_id\"] for hit in search_results}\n",
        "            for hit in filter_hits:\n",
        "                if hit[\"_id\"] not in existing_ids:\n",
        "                    search_results.append(hit)\n",
        "        \n",
        "        # 4. Í≤∞Í≥º Ï†úÌïú Î∞è Ï†êÏàò Ïàú Ï†ïÎ†¨\n",
        "        search_results.sort(key=lambda x: x.get(\"_score\", 0), reverse=True)\n",
        "        return search_results[:max_results]\n",
        "    \n",
        "    def format_policy_info(self, policy_doc: Dict) -> str:\n",
        "        \"\"\"Ï†ïÏ±Ö Ï†ïÎ≥¥Î•º Ìè¨Îß∑ÌåÖ\"\"\"\n",
        "        source = policy_doc.get(\"_source\", {})\n",
        "        \n",
        "        # Í∏∞Î≥∏ Ï†ïÎ≥¥\n",
        "        policy_name = source.get('plcyNm', 'N/A')\n",
        "        policy_desc = source.get('plcyExplnCn', 'N/A')\n",
        "        support_content = source.get('plcySprtCn', 'N/A')\n",
        "        \n",
        "        # ÎåÄÏÉÅ Ï†ïÎ≥¥\n",
        "        min_age = source.get('sprtTrgtMinAge', 'N/A')\n",
        "        max_age = source.get('sprtTrgtMaxAge', 'N/A')\n",
        "        \n",
        "        # Í∏∞Í¥Ä Ï†ïÎ≥¥\n",
        "        supervising_org = source.get('sprvsnInstCdNm', 'N/A')\n",
        "        operating_org = source.get('operInstCdNm', 'N/A')\n",
        "        \n",
        "        # Ïã†Ï≤≠ Ï†ïÎ≥¥\n",
        "        apply_url = source.get('aplyUrlAddr', 'N/A')\n",
        "        apply_method = source.get('plcyAplyMthdCn', 'N/A')\n",
        "        \n",
        "        # Îã¥ÎãπÏûê Ï†ïÎ≥¥\n",
        "        contact_person = source.get('sprvsnInstPicNm', 'N/A')\n",
        "        \n",
        "        formatted_info = f\"\"\"\n",
        "        üìã **Ï†ïÏ±ÖÎ™Ö**: {policy_name}\n",
        "        \n",
        "        üìù **Ï†ïÏ±Ö ÏÑ§Î™Ö**: {policy_desc}\n",
        "        \n",
        "        üí∞ **ÏßÄÏõê ÎÇ¥Ïö©**: \n",
        "        {support_content}\n",
        "        \n",
        "        üéØ **ÏßÄÏõê ÎåÄÏÉÅ**: {min_age}ÏÑ∏ ~ {max_age}ÏÑ∏\n",
        "        \n",
        "        üè¢ **Ï£ºÍ¥Ä Í∏∞Í¥Ä**: {supervising_org}\n",
        "        üèõÔ∏è **Ïö¥ÏòÅ Í∏∞Í¥Ä**: {operating_org}\n",
        "        üë§ **Îã¥ÎãπÏûê**: {contact_person}\n",
        "        \n",
        "        üìã **Ïã†Ï≤≠ Î∞©Î≤ï**: \n",
        "        {apply_method}\n",
        "        \n",
        "        üåê **Ïã†Ï≤≠ URL**: {apply_url}\n",
        "        \"\"\"\n",
        "        \n",
        "        return formatted_info.strip()\n",
        "    \n",
        "    def generate_response(self, user_query: str, search_results: List[Dict]) -> str:\n",
        "        \"\"\"ÏµúÏ¢Ö ÏùëÎãµ ÏÉùÏÑ±\"\"\"\n",
        "        if not search_results:\n",
        "            return \"Ï£ÑÏÜ°Ìï©ÎãàÎã§. Í¥ÄÎ†®Îêú Ï≤≠ÎÖÑÏ†ïÏ±ÖÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Îã§Î•∏ ÌÇ§ÏõåÎìúÎ°ú Í≤ÄÏÉâÌï¥Î≥¥ÏãúÍ±∞ÎÇò Îçî Íµ¨Ï≤¥Ï†ÅÏù∏ Ï°∞Í±¥ÏùÑ ÎßêÏîÄÌï¥Ï£ºÏÑ∏Ïöî.\"\n",
        "        \n",
        "        # Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò\n",
        "        policies_text = \"\\n\\n\" + \"=\"*50 + \"\\n\\n\".join([\n",
        "            self.format_policy_info(result) for result in search_results\n",
        "        ])\n",
        "        \n",
        "        # ÏùëÎãµ ÏÉùÏÑ± ÌîÑÎ°¨ÌîÑÌä∏\n",
        "        response_prompt = PromptTemplate(\n",
        "            input_variables=[\"query\", \"policies\"],\n",
        "            template=\"\"\"\n",
        "            ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: {query}\n",
        "            \n",
        "            Í≤ÄÏÉâÎêú Ï†ïÏ±Ö Ï†ïÎ≥¥:\n",
        "            {policies}\n",
        "            \n",
        "            ÏúÑÏùò Ï†ïÏ±Ö Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏Ïóê ÎåÄÌïú ÏπúÏ†àÌïòÍ≥† ÏÉÅÏÑ∏Ìïú ÎãµÎ≥ÄÏùÑ ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.\n",
        "            Í∞Å Ï†ïÏ±ÖÏùò ÌïµÏã¨ Ï†ïÎ≥¥Î•º Ìè¨Ìï®ÌïòÏó¨ Ïã§Ïö©Ï†ÅÏù∏ Í∞ÄÏù¥ÎìúÎ•º Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî.\n",
        "            Ï†ïÏ±ÖÏù¥ Ïó¨Îü¨ Í∞úÏù∏ Í≤ΩÏö∞ Î≤àÌò∏Î•º Îß§Í≤® Íµ¨Î∂ÑÌï¥Ï£ºÏÑ∏Ïöî.\n",
        "            \"\"\"\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            messages = [\n",
        "                SystemMessage(content=self.system_prompt),\n",
        "                HumanMessage(content=response_prompt.format(\n",
        "                    query=user_query,\n",
        "                    policies=policies_text\n",
        "                ))\n",
        "            ]\n",
        "            \n",
        "            response = self.llm.invoke(messages)\n",
        "            return response.content\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ÏùëÎãµ ÏÉùÏÑ± Ïã§Ìå®: {e}\")\n",
        "            return f\"ÏùëÎãµ ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}\"\n",
        "    \n",
        "    def answer_question(self, user_query: str) -> str:\n",
        "        \"\"\"ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏Ïóê ÎåÄÌïú ÏôÑÏ†ÑÌïú ÎãµÎ≥Ä ÏÉùÏÑ±\"\"\"\n",
        "        try:\n",
        "            # 1. Ï†ïÏ±Ö Í≤ÄÏÉâ\n",
        "            search_results = self.search_policies(user_query)\n",
        "            \n",
        "            # 2. ÏùëÎãµ ÏÉùÏÑ±\n",
        "            response = self.generate_response(user_query, search_results)\n",
        "            \n",
        "            return response\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"Í≤ÄÏÉâ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}\"\n",
        "\n",
        "# Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ Ï¥àÍ∏∞Ìôî\n",
        "if 'llm' in locals() and 'embeddings' in locals():\n",
        "    agent = YouthPolicySearchAgent(search_client, llm, embeddings)\n",
        "    print(\"‚úÖ Ï≤≠ÎÖÑÏ†ïÏ±Ö Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è OpenAI Î™®Îç∏Ïù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. API ÌÇ§Î•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12Îã®Í≥Ñ: Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'agent' in locals():\n",
        "    print(\"ü§ñ Ï≤≠ÎÖÑÏ†ïÏ±Ö Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ ÌÖåÏä§Ìä∏\")\n",
        "    \n",
        "    # ÌÖåÏä§Ìä∏ ÏßàÎ¨∏Îì§\n",
        "    test_questions = [\n",
        "        \"SW ÍµêÏú° Í¥ÄÎ†® Ï†ïÏ±ÖÏù¥ ÏûàÎÇòÏöî?\",\n",
        "        \"25ÏÑ∏ Ï≤≠ÎÖÑÏùÑ ÏúÑÌïú Ï∑®ÏóÖ ÏßÄÏõê Ï†ïÏ±ÖÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî\",\n",
        "        \"ÎåÄÍµ¨ ÏßÄÏó≠ Ï≤≠ÎÖÑ Ï†ïÏ±ÖÏùÑ Ï∞æÏïÑÏ£ºÏÑ∏Ïöî\",\n",
        "        \"Ï∞ΩÏóÖ ÏßÄÏõê Ï†ïÏ±ÖÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî\"\n",
        "    ]\n",
        "    \n",
        "    for i, question in enumerate(test_questions, 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ÌÖåÏä§Ìä∏ {i}: {question}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            # Í≤ÄÏÉâ ÏàòÌñâ\n",
        "            answer = agent.answer_question(question)\n",
        "            print(f\"\\nÎãµÎ≥Ä:\\n{answer}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "        \n",
        "        print(f\"\\n{'-'*60}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13Îã®Í≥Ñ: ÎåÄÌôîÌòï Í≤ÄÏÉâ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def interactive_search():\n",
        "    \"\"\"ÎåÄÌôîÌòï Í≤ÄÏÉâ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üéØ Ï≤≠ÎÖÑÏ†ïÏ±Ö Í≤ÄÏÉâ ÏãúÏä§ÌÖú\")\n",
        "    print(\"ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïòÏãúÎ©¥ Í¥ÄÎ†® Ï†ïÏ±ÖÏùÑ Ï∞æÏïÑÎìúÎ¶ΩÎãàÎã§.\")\n",
        "    print(\"Ï¢ÖÎ£åÌïòÎ†§Î©¥ 'quit', 'exit', 'Ï¢ÖÎ£å' Ï§ë ÌïòÎÇòÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî.\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nüí¨ ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî: \").strip()\n",
        "            \n",
        "            # Ï¢ÖÎ£å Ï°∞Í±¥\n",
        "            if user_input.lower() in ['quit', 'exit', 'Ï¢ÖÎ£å', 'q']:\n",
        "                print(\"üëã ÏãúÏä§ÌÖúÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
        "                break\n",
        "            \n",
        "            # Îπà ÏûÖÎ†• Ï≤òÎ¶¨\n",
        "            if not user_input:\n",
        "                print(\"‚ö†Ô∏è ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "                continue\n",
        "            \n",
        "            # Í≤ÄÏÉâ ÏàòÌñâ\n",
        "            print(\"\\nüîç Í≤ÄÏÉâ Ï§ë...\")\n",
        "            answer = agent.answer_question(user_input)\n",
        "            \n",
        "            print(f\"\\nü§ñ ÎãµÎ≥Ä:\")\n",
        "            print(f\"{answer}\")\n",
        "            print(f\"\\n{'-'*50}\")\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüëã ÏÇ¨Ïö©ÏûêÍ∞Ä Ï§ëÎã®ÌñàÏäµÎãàÎã§.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {e}\")\n",
        "\n",
        "# ÎåÄÌôîÌòï Í≤ÄÏÉâ ÏãúÏûë (Ï£ºÏÑù Ìï¥Ï†úÌïòÏó¨ ÏÇ¨Ïö©)\n",
        "# interactive_search()\n",
        "\n",
        "print(\"‚úÖ ÎåÄÌôîÌòï Í≤ÄÏÉâ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ï§ÄÎπÑ ÏôÑÎ£å\")\n",
        "print(\"üí° interactive_search() Ìï®ÏàòÎ•º Ìò∏Ï∂úÌïòÏó¨ ÎåÄÌôîÌòï Í≤ÄÏÉâÏùÑ ÏãúÏûëÌïòÏÑ∏Ïöî.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14Îã®Í≥Ñ: Í≥†Í∏â Í≤ÄÏÉâ Í∏∞Îä• ÌÖåÏä§Ìä∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def advanced_search_test():\n",
        "    \"\"\"Í≥†Í∏â Í≤ÄÏÉâ Í∏∞Îä• ÌÖåÏä§Ìä∏\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üöÄ Í≥†Í∏â Í≤ÄÏÉâ Í∏∞Îä• ÌÖåÏä§Ìä∏\")\n",
        "    \n",
        "    # Î≥µÌï© Ï°∞Í±¥ Í≤ÄÏÉâ\n",
        "    complex_queries = [\n",
        "        {\n",
        "            \"query\": \"20ÎåÄ ÌõÑÎ∞ò Ï≤≠ÎÖÑÏùÑ ÏúÑÌïú Ï∞ΩÏóÖ ÏßÄÏõê Ï†ïÏ±Ö\",\n",
        "            \"description\": \"ÎÇòÏù¥ÏôÄ Î∂ÑÏïºÎ•º Î™®Îëê Ìè¨Ìï®Ìïú Î≥µÌï© Í≤ÄÏÉâ\"\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"ÍµêÏú° Î∂ÑÏïºÏóêÏÑú ÏùºÏûêÎ¶¨Î•º Ï†úÍ≥µÌïòÎäî Ï†ïÏ±Ö\",\n",
        "            \"description\": \"ÌäπÏ†ï Î∂ÑÏïºÏùò ÏùºÏûêÎ¶¨ Í¥ÄÎ†® Ï†ïÏ±Ö Í≤ÄÏÉâ\"\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Í∞úÎ∞úÏûê ÏñëÏÑ± ÌîÑÎ°úÍ∑∏Îû®\",\n",
        "            \"description\": \"ÏßÅÏóÖ ÌäπÌôî ÍµêÏú° ÌîÑÎ°úÍ∑∏Îû® Í≤ÄÏÉâ\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    for i, test_case in enumerate(complex_queries, 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Í≥†Í∏â ÌÖåÏä§Ìä∏ {i}: {test_case['description']}\")\n",
        "        print(f\"ÏßàÎ¨∏: {test_case['query']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            # Í≤ÄÏÉâ ÏùòÎèÑ Î∂ÑÏÑù\n",
        "            intent = agent.extract_search_intent(test_case['query'])\n",
        "            print(f\"\\nüß† Î∂ÑÏÑùÎêú Í≤ÄÏÉâ ÏùòÎèÑ: {intent}\")\n",
        "            \n",
        "            # Í≤ÄÏÉâ Í≤∞Í≥º\n",
        "            search_results = agent.search_policies(test_case['query'])\n",
        "            print(f\"\\nüìä Í≤ÄÏÉâÎêú Ï†ïÏ±Ö Ïàò: {len(search_results)}\")\n",
        "            \n",
        "            # ÏµúÏ¢Ö ÎãµÎ≥Ä\n",
        "            answer = agent.generate_response(test_case['query'], search_results)\n",
        "            print(f\"\\nü§ñ ÎãµÎ≥Ä:\\n{answer}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "        \n",
        "        print(f\"\\n{'-'*60}\")\n",
        "\n",
        "# Í≥†Í∏â Í≤ÄÏÉâ ÌÖåÏä§Ìä∏ Ïã§Ìñâ\n",
        "if 'agent' in locals():\n",
        "    advanced_search_test()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïÑ Í≥†Í∏â Í≤ÄÏÉâ ÌÖåÏä§Ìä∏Î•º Ïã§ÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15Îã®Í≥Ñ: ÏÑ±Îä• Î∞è ÌíàÏßà ÌèâÍ∞Ä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_search_quality():\n",
        "    \"\"\"Í≤ÄÏÉâ ÌíàÏßà ÌèâÍ∞Ä\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìà Í≤ÄÏÉâ ÌíàÏßà ÌèâÍ∞Ä\")\n",
        "    \n",
        "    # ÌèâÍ∞ÄÏö© ÏßàÎ¨∏-ÎãµÎ≥Ä Ïåç\n",
        "    evaluation_cases = [\n",
        "        {\n",
        "            \"query\": \"SW ÍµêÏú° Ï†ïÏ±Ö\",\n",
        "            \"expected_keywords\": [\"SW\", \"ÍµêÏú°\", \"ÏÜåÌîÑÌä∏Ïõ®Ïñ¥\", \"ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç\"],\n",
        "            \"expected_categories\": [\"ÍµêÏú°\"]\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"Ï≤≠ÎÖÑ Ï∞ΩÏóÖ ÏßÄÏõê\",\n",
        "            \"expected_keywords\": [\"Ï∞ΩÏóÖ\", \"ÏßÄÏõê\", \"Ï≤≠ÎÖÑ\"],\n",
        "            \"expected_categories\": [\"Ï∞ΩÏóÖ\", \"ÏßÄÏõê\"]\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"Ï∑®ÏóÖ Ï§ÄÎπÑ ÎèÑÏõÄ\",\n",
        "            \"expected_keywords\": [\"Ï∑®ÏóÖ\", \"Ï§ÄÎπÑ\", \"ÎèÑÏõÄ\", \"ÏßÄÏõê\"],\n",
        "            \"expected_categories\": [\"Ï∑®ÏóÖ\", \"ÍµêÏú°\"]\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    total_score = 0\n",
        "    \n",
        "    for i, case in enumerate(evaluation_cases, 1):\n",
        "        print(f\"\\nÌèâÍ∞Ä ÏºÄÏù¥Ïä§ {i}: {case['query']}\")\n",
        "        \n",
        "        try:\n",
        "            # Í≤ÄÏÉâ ÏàòÌñâ\n",
        "            search_results = agent.search_policies(case['query'])\n",
        "            \n",
        "            # Í≤∞Í≥º Î∂ÑÏÑù\n",
        "            found_policies = len(search_results)\n",
        "            relevance_score = 0\n",
        "            \n",
        "            for result in search_results:\n",
        "                source = result.get('_source', {})\n",
        "                policy_text = f\"{source.get('plcyNm', '')} {source.get('plcyExplnCn', '')} {source.get('plcySprtCn', '')}\"\n",
        "                \n",
        "                # ÌÇ§ÏõåÎìú Í¥ÄÎ†®ÏÑ± Í≤ÄÏÇ¨\n",
        "                keyword_matches = sum(1 for keyword in case['expected_keywords'] \n",
        "                                    if keyword.lower() in policy_text.lower())\n",
        "                \n",
        "                if keyword_matches > 0:\n",
        "                    relevance_score += keyword_matches / len(case['expected_keywords'])\n",
        "            \n",
        "            # Ï†êÏàò Í≥ÑÏÇ∞\n",
        "            case_score = (relevance_score / max(found_policies, 1)) * 100\n",
        "            total_score += case_score\n",
        "            \n",
        "            print(f\"  - Í≤ÄÏÉâÎêú Ï†ïÏ±Ö Ïàò: {found_policies}\")\n",
        "            print(f\"  - Í¥ÄÎ†®ÏÑ± Ï†êÏàò: {case_score:.1f}%\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  - Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "    \n",
        "    average_score = total_score / len(evaluation_cases)\n",
        "    print(f\"\\nüéØ Ï†ÑÏ≤¥ ÌèâÍ∑† Ï†êÏàò: {average_score:.1f}%\")\n",
        "    \n",
        "    # ÏÑ±Îä• Í∂åÏû•ÏÇ¨Ìï≠\n",
        "    if average_score >= 80:\n",
        "        print(\"‚úÖ Ïö∞ÏàòÌïú Í≤ÄÏÉâ ÌíàÏßàÏûÖÎãàÎã§.\")\n",
        "    elif average_score >= 60:\n",
        "        print(\"‚ö†Ô∏è Î≥¥ÌÜµ ÏàòÏ§ÄÏùò Í≤ÄÏÉâ ÌíàÏßàÏûÖÎãàÎã§. ÌÇ§ÏõåÎìú Îß§Ïπ≠ Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.\")\n",
        "    else:\n",
        "        print(\"‚ùå Í≤ÄÏÉâ ÌíàÏßà Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§. Í≤ÄÏÉâ Î°úÏßÅÏùÑ Ï†êÍ≤ÄÌï¥Î≥¥ÏÑ∏Ïöî.\")\n",
        "\n",
        "# ÌíàÏßà ÌèâÍ∞Ä Ïã§Ìñâ\n",
        "if 'agent' in locals():\n",
        "    evaluate_search_quality()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïÑ ÌíàÏßà ÌèâÍ∞ÄÎ•º Ïã§ÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16Îã®Í≥Ñ: Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def demo_search_examples():\n",
        "    \"\"\"Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú Îç∞Î™®\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üé™ Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú Îç∞Î™®\")\n",
        "    \n",
        "    # Ïã§Ï†ú ÏÇ¨Ïö©ÏûêÍ∞Ä Î¨ºÏñ¥Î≥º Î≤ïÌïú ÏßàÎ¨∏Îì§\n",
        "    real_world_queries = [\n",
        "        \"ÎåÄÌïôÏÉùÏùÑ ÏúÑÌïú Ïù∏ÌÑ¥Ïã≠ ÌîÑÎ°úÍ∑∏Îû®Ïù¥ ÏûàÎÇòÏöî?\",\n",
        "        \"ÏΩîÎî©ÏùÑ Î∞∞Ïö∞Í≥† Ïã∂ÏùÄÎç∞ ÏßÄÏõêÎ∞õÏùÑ Ïàò ÏûàÎäî Ï†ïÏ±ÖÏù¥ ÏûàÎÇòÏöî?\",\n",
        "        \"20ÎåÄ ÌõÑÎ∞òÏù∏Îç∞ Ï∞ΩÏóÖ Í¥ÄÎ†® ÏßÄÏõêÏùÑ Î∞õÏùÑ Ïàò ÏûàÏùÑÍπåÏöî?\",\n",
        "        \"Ï∑®ÏóÖ Ï§ÄÎπÑÌïòÎäîÎç∞ ÎèÑÏõÄÏù¥ ÎêòÎäî Ï†ïÏ±ÖÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî\"\n",
        "    ]\n",
        "    \n",
        "    for i, query in enumerate(real_world_queries, 1):\n",
        "        print(f\"\\n{'üéØ Ïã§Ï†ú ÏßàÎ¨∏ ' + str(i):=^60}\")\n",
        "        print(f\"ÏÇ¨Ïö©Ïûê: {query}\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # Ïã§ÏãúÍ∞Ñ Í≤ÄÏÉâ ÏãúÎÆ¨Î†àÏù¥ÏÖò\n",
        "            import time\n",
        "            print(\"üîç Í≤ÄÏÉâ Ï§ë...\", end=\"\")\n",
        "            time.sleep(0.5)  # Í≤ÄÏÉâ ÏãúÍ∞Ñ ÏãúÎÆ¨Î†àÏù¥ÏÖò\n",
        "            print(\" ÏôÑÎ£å!\")\n",
        "            \n",
        "            answer = agent.answer_question(query)\n",
        "            print(f\"\\nü§ñ AI ÏÉÅÎã¥ÏÇ¨:\\n{answer}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú Îç∞Î™® Ïã§Ìñâ\n",
        "if 'agent' in locals():\n",
        "    demo_search_examples()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïÑ Îç∞Î™®Î•º Ïã§ÌñâÌï† Ïàò ÏóÜÏäµÎãàÎã§.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17Îã®Í≥Ñ: ÏãúÏä§ÌÖú ÏöîÏïΩ Î∞è Îã§Ïùå Îã®Í≥Ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìã Ï≤≠ÎÖÑÏ†ïÏ±Ö Í≤ÄÏÉâ ÏãúÏä§ÌÖú Íµ¨ÌòÑ ÏôÑÎ£å ÏöîÏïΩ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Íµ¨ÌòÑÎêú Í∏∞Îä•Îì§\n",
        "implemented_features = [\n",
        "    \"‚úÖ OpenSearch 3.1.0 Ïó∞Í≤∞ Î∞è ÌÖåÏä§Ìä∏\",\n",
        "    \"‚úÖ ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ï†ïÏ±Ö Í≤ÄÏÉâ\",\n",
        "    \"‚úÖ ÌïÑÌÑ∞ Í∏∞Î∞ò Ï†ïÏ±Ö Í≤ÄÏÉâ (ÎÇòÏù¥, ÏßÄÏó≠, Ïπ¥ÌÖåÍ≥†Î¶¨)\",\n",
        "    \"‚úÖ LangChainÍ≥º ChatOpenAI ÌÜµÌï©\",\n",
        "    \"‚úÖ Í≤ÄÏÉâ ÏùòÎèÑ ÏûêÎèô Ï∂îÏ∂ú\",\n",
        "    \"‚úÖ ÏûêÏó∞Ïñ¥ ÏßàÎ¨∏ Ï≤òÎ¶¨\",\n",
        "    \"‚úÖ Í≤ÄÏÉâ Í≤∞Í≥º Í∏∞Î∞ò ÎãµÎ≥Ä ÏÉùÏÑ±\",\n",
        "    \"‚úÖ ÎåÄÌôîÌòï Í≤ÄÏÉâ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§\",\n",
        "    \"‚úÖ Í≥†Í∏â Í≤ÄÏÉâ Í∏∞Îä•\",\n",
        "    \"‚úÖ Í≤ÄÏÉâ ÌíàÏßà ÌèâÍ∞Ä\"\n",
        "]\n",
        "\n",
        "print(\"\\nüéâ Íµ¨ÌòÑÎêú Í∏∞Îä•:\")\n",
        "for feature in implemented_features:\n",
        "    print(f\"  {feature}\")\n",
        "\n",
        "# ÏãúÏä§ÌÖú ÏïÑÌÇ§ÌÖçÏ≤ò\n",
        "print(f\"\\nüèóÔ∏è ÏãúÏä§ÌÖú ÏïÑÌÇ§ÌÖçÏ≤ò:\")\n",
        "print(f\"  üìä Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•ÏÜå: OpenSearch 3.1.0\")\n",
        "print(f\"  üîç Í≤ÄÏÉâ ÏóîÏßÑ: OpenSearch Query DSL\")\n",
        "print(f\"  ü§ñ AI Î™®Îç∏: OpenAI GPT-4o-mini\")\n",
        "print(f\"  üîó ÌÜµÌï© ÌîÑÎ†àÏûÑÏõåÌÅ¨: LangChain\")\n",
        "print(f\"  üéØ ÏûÑÎ≤†Îî©: OpenAI text-embedding-3-small\")\n",
        "\n",
        "# Ï£ºÏöî ÏÑ±Îä• ÏßÄÌëú\n",
        "print(f\"\\nüìä Ï£ºÏöî ÏÑ±Îä• ÏßÄÌëú:\")\n",
        "print(f\"  - Í≤ÄÏÉâ ÏÜçÎèÑ: < 1Ï¥à (ÏùºÎ∞òÏ†ÅÏù∏ ÏøºÎ¶¨)\")\n",
        "print(f\"  - ÎãµÎ≥Ä ÏÉùÏÑ± ÏãúÍ∞Ñ: 2-5Ï¥à (OpenAI API ÏÜçÎèÑÏóê Îî∞Îùº)\")\n",
        "print(f\"  - Í≤ÄÏÉâ Ï†ïÌôïÎèÑ: ÌÇ§ÏõåÎìú Îß§Ïπ≠ Í∏∞Î∞ò ÎÜíÏùÄ Ï†ïÌôïÎèÑ\")\n",
        "print(f\"  - Îã§Íµ≠Ïñ¥ ÏßÄÏõê: ÌïúÍµ≠Ïñ¥ ÏµúÏ†ÅÌôî\")\n",
        "\n",
        "# Îã§Ïùå Îã®Í≥Ñ Í∂åÏû•ÏÇ¨Ìï≠\n",
        "print(f\"\\nüöÄ Îã§Ïùå Îã®Í≥Ñ Í∂åÏû•ÏÇ¨Ìï≠:\")\n",
        "next_steps = [\n",
        "    \"1. Î≤°ÌÑ∞ Í≤ÄÏÉâ Íµ¨ÌòÑ (semantic search)\",\n",
        "    \"2. ÏÇ¨Ïö©Ïûê ÌîºÎìúÎ∞± ÏãúÏä§ÌÖú Íµ¨Ï∂ï\",\n",
        "    \"3. Í≤ÄÏÉâ Î°úÍ∑∏ Î∂ÑÏÑù Î∞è Í∞úÏÑ†\",\n",
        "    \"4. Ïõπ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Í∞úÎ∞ú (Streamlit/FastAPI)\",\n",
        "    \"5. Í≤ÄÏÉâ Í≤∞Í≥º Ï∫êÏã± ÏãúÏä§ÌÖú\",\n",
        "    \"6. A/B ÌÖåÏä§Ìä∏Î•º ÌÜµÌïú Í≤ÄÏÉâ ÏïåÍ≥†Î¶¨Ï¶ò Í∞úÏÑ†\",\n",
        "    \"7. Ï†ïÏ±Ö ÏóÖÎç∞Ïù¥Ìä∏ ÏûêÎèôÌôî\",\n",
        "    \"8. ÏÇ¨Ïö©Ïûê Í∞úÏù∏Ìôî Ï∂îÏ≤ú ÏãúÏä§ÌÖú\"\n",
        "]\n",
        "\n",
        "for step in next_steps:\n",
        "    print(f\"  {step}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"‚ú® ÏãúÏä§ÌÖúÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Íµ¨ÌòÑÎêòÏóàÏäµÎãàÎã§!\")\n",
        "print(\"üí° interactive_search() Ìï®ÏàòÎ•º Ìò∏Ï∂úÌïòÏó¨ ÎåÄÌôîÌòï Í≤ÄÏÉâÏùÑ ÏãúÏûëÌï† Ïàò ÏûàÏäµÎãàÎã§.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18Îã®Í≥Ñ: Ï∂îÍ∞Ä Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_search_results(query: str, results: list, filename: str = None):\n",
        "    \"\"\"Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º ÌååÏùºÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞\"\"\"\n",
        "    if not filename:\n",
        "        from datetime import datetime\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"search_results_{timestamp}.json\"\n",
        "    \n",
        "    export_data = {\n",
        "        \"query\": query,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_results\": len(results),\n",
        "        \"results\": results\n",
        "    }\n",
        "    \n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä {filename}Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")\n",
        "\n",
        "def batch_search(queries: list):\n",
        "    \"\"\"Ïó¨Îü¨ ÏßàÎ¨∏ÏùÑ Î∞∞ÏπòÎ°ú Í≤ÄÏÉâ\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for i, query in enumerate(queries, 1):\n",
        "        print(f\"\\n[{i}/{len(queries)}] Í≤ÄÏÉâ Ï§ë: {query}\")\n",
        "        \n",
        "        try:\n",
        "            search_results = agent.search_policies(query)\n",
        "            answer = agent.generate_response(query, search_results)\n",
        "            \n",
        "            result = {\n",
        "                \"query\": query,\n",
        "                \"answer\": answer,\n",
        "                \"num_results\": len(search_results),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "            \n",
        "            results.append(result)\n",
        "            print(f\"‚úÖ ÏôÑÎ£å ({len(search_results)}Í∞ú Ï†ïÏ±Ö Î∞úÍ≤¨)\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                \"error\": str(e),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            })\n",
        "    \n",
        "    return results\n",
        "\n",
        "def create_search_report(results: list):\n",
        "    \"\"\"Í≤ÄÏÉâ Í≤∞Í≥º Î≥¥Í≥†ÏÑú ÏÉùÏÑ±\"\"\"\n",
        "    if not results:\n",
        "        print(\"‚ö†Ô∏è Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìä Í≤ÄÏÉâ Í≤∞Í≥º Î≥¥Í≥†ÏÑú\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Ï¥ù Í≤ÄÏÉâ Ïàò: {len(results)}\")\n",
        "    \n",
        "    successful_searches = [r for r in results if 'error' not in r]\n",
        "    failed_searches = [r for r in results if 'error' in r]\n",
        "    \n",
        "    print(f\"ÏÑ±Í≥µÌïú Í≤ÄÏÉâ: {len(successful_searches)}\")\n",
        "    print(f\"Ïã§Ìå®Ìïú Í≤ÄÏÉâ: {len(failed_searches)}\")\n",
        "    \n",
        "    if successful_searches:\n",
        "        avg_results = sum(r.get('num_results', 0) for r in successful_searches) / len(successful_searches)\n",
        "        print(f\"ÌèâÍ∑† Í≤ÄÏÉâ Í≤∞Í≥º Ïàò: {avg_results:.1f}\")\n",
        "    \n",
        "    if failed_searches:\n",
        "        print(\"\\n‚ùå Ïã§Ìå®Ìïú Í≤ÄÏÉâÎì§:\")\n",
        "        for failed in failed_searches:\n",
        "            print(f\"  - {failed['query']}: {failed['error']}\")\n",
        "\n",
        "print(\"‚úÖ Ï∂îÍ∞Ä Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò Ï†ïÏùò ÏôÑÎ£å\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 19Îã®Í≥Ñ: ÏµúÏ¢Ö ÌÖåÏä§Ìä∏ Î∞è ÏôÑÎ£å"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def final_system_test():\n",
        "    \"\"\"ÏµúÏ¢Ö ÏãúÏä§ÌÖú ÌÖåÏä§Ìä∏\"\"\"\n",
        "    print(\"üéØ ÏµúÏ¢Ö ÏãúÏä§ÌÖú ÌÖåÏä§Ìä∏\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 1. Ïó∞Í≤∞ ÌÖåÏä§Ìä∏\n",
        "    print(\"\\n1. Ïó∞Í≤∞ ÌÖåÏä§Ìä∏\")\n",
        "    try:\n",
        "        cluster_info = client.info()\n",
        "        print(f\"  ‚úÖ OpenSearch Ïó∞Í≤∞ ÏÑ±Í≥µ: {cluster_info['version']['number']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå OpenSearch Ïó∞Í≤∞ Ïã§Ìå®: {e}\")\n",
        "        return False\n",
        "    \n",
        "    # 2. Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
        "    print(\"\\n2. Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\")\n",
        "    try:\n",
        "        stats = client.indices.stats(index=OPENSEARCH_INDEX)\n",
        "        doc_count = stats['indices'][OPENSEARCH_INDEX]['total']['docs']['count']\n",
        "        print(f\"  ‚úÖ Ïù∏Îç±Ïä§ Î¨∏ÏÑú Ïàò: {doc_count}\")\n",
        "        if doc_count == 0:\n",
        "            print(\"  ‚ö†Ô∏è Ïù∏Îç±Ïä§Ïóê Î¨∏ÏÑúÍ∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Ïù∏Îç±Ïä§ Ï°∞Ìöå Ïã§Ìå®: {e}\")\n",
        "        return False\n",
        "    \n",
        "    # 3. AI Î™®Îç∏ ÌÖåÏä§Ìä∏\n",
        "    print(\"\\n3. AI Î™®Îç∏ ÌÖåÏä§Ìä∏\")\n",
        "    if 'llm' in locals():\n",
        "        try:\n",
        "            test_response = llm.invoke([HumanMessage(content=\"ÏïàÎÖïÌïòÏÑ∏Ïöî!\")])\n",
        "            print(f\"  ‚úÖ LLM ÏùëÎãµ ÏÑ±Í≥µ: {test_response.content[:50]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå LLM ÌÖåÏä§Ìä∏ Ïã§Ìå®: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"  ‚ö†Ô∏è LLMÏù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return False\n",
        "    \n",
        "    # 4. Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ ÌÖåÏä§Ìä∏\n",
        "    print(\"\\n4. Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏ ÌÖåÏä§Ìä∏\")\n",
        "    if 'agent' in locals():\n",
        "        try:\n",
        "            test_query = \"Ï≤≠ÎÖÑ Ï†ïÏ±Ö ÌÖåÏä§Ìä∏\"\n",
        "            test_results = agent.search_policies(test_query)\n",
        "            print(f\"  ‚úÖ Í≤ÄÏÉâ ÏÑ±Í≥µ: {len(test_results)}Í∞ú Í≤∞Í≥º\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Í≤ÄÏÉâ ÌÖåÏä§Ìä∏ Ïã§Ìå®: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"  ‚ö†Ô∏è Í≤ÄÏÉâ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\")\n",
        "        return False\n",
        "    \n",
        "    print(\"\\nüéâ Î™®Îì† ÌÖåÏä§Ìä∏ ÌÜµÍ≥º!\")\n",
        "    print(\"‚ú® ÏãúÏä§ÌÖúÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏûëÎèôÌï©ÎãàÎã§.\")\n",
        "    return True\n",
        "\n",
        "# ÏµúÏ¢Ö ÌÖåÏä§Ìä∏ Ïã§Ìñâ\n",
        "system_ready = final_system_test()\n",
        "\n",
        "if system_ready:\n",
        "    print(\"\\nüöÄ ÏãúÏä§ÌÖú ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™ÖÎ†πÏñ¥:\")\n",
        "    print(\"  - interactive_search(): ÎåÄÌôîÌòï Í≤ÄÏÉâ ÏãúÏûë\")\n",
        "    print(\"  - demo_search_examples(): Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú Î≥¥Í∏∞\")\n",
        "    print(\"  - advanced_search_test(): Í≥†Í∏â Í≤ÄÏÉâ ÌÖåÏä§Ìä∏\")\n",
        "    print(\"  - evaluate_search_quality(): Í≤ÄÏÉâ ÌíàÏßà ÌèâÍ∞Ä\")\n",
        "    print(\"  - agent.answer_question('ÏßàÎ¨∏'): ÏßÅÏ†ë ÏßàÎ¨∏ÌïòÍ∏∞\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è ÏãúÏä§ÌÖú ÏÑ§Ï†ïÏùÑ ÌôïÏù∏ÌïòÍ≥† Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ÏÇ¨Ïö© Í∞ÄÏù¥Îìú\n",
        "\n",
        "### ÏãúÏûëÌïòÍ∏∞ Ï†ÑÏóê\n",
        "1. **OpenAI API ÌÇ§ ÏÑ§Ï†ï**: `OPENAI_API_KEY` Î≥ÄÏàòÏóê Ïã§Ï†ú API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî.\n",
        "2. **OpenSearch ÌôïÏù∏**: localhost:9200ÏóêÏÑú OpenSearchÍ∞Ä Ïã§Ìñâ Ï§ëÏù∏ÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\n",
        "3. **Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏**: youth_policies Ïù∏Îç±Ïä§Ïóê Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\n",
        "\n",
        "### Ï£ºÏöî Í∏∞Îä•\n",
        "- **ÌÇ§ÏõåÎìú Í≤ÄÏÉâ**: Ï†ïÏ±ÖÎ™Ö, ÏÑ§Î™Ö, ÏßÄÏõêÎÇ¥Ïö©ÏùÑ Í∏∞Î∞òÏúºÎ°ú Í≤ÄÏÉâ\n",
        "- **ÌïÑÌÑ∞ Í≤ÄÏÉâ**: ÎÇòÏù¥, ÏßÄÏó≠, Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ ÌïÑÌÑ∞ÎßÅ\n",
        "- **ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨**: ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏùÑ ÏûêÎèôÏúºÎ°ú Î∂ÑÏÑùÌïòÏó¨ Í≤ÄÏÉâ ÏùòÎèÑ Ï∂îÏ∂ú\n",
        "- **AI ÎãµÎ≥Ä**: ChatGPTÎ•º ÌôúÏö©Ìïú ÏπúÏ†àÌïòÍ≥† ÏÉÅÏÑ∏Ìïú ÎãµÎ≥Ä ÏÉùÏÑ±\n",
        "\n",
        "### ÏÇ¨Ïö©Î≤ï\n",
        "```
        "# ÎåÄÌôîÌòï Í≤ÄÏÉâ ÏãúÏûë\n",
        "interactive_search()\n",
        "\n",
        "# ÏßÅÏ†ë ÏßàÎ¨∏\n",
        "answer = agent.answer_question(\"SW ÍµêÏú° Ï†ïÏ±ÖÏù¥ ÏûàÎÇòÏöî?\")\n",
        "print(answer)\n",
        "\n",
        "# Î∞∞Ïπò Í≤ÄÏÉâ\n",
        "queries = [\"Ï∑®ÏóÖ ÏßÄÏõê\", \"Ï∞ΩÏóÖ Ï†ïÏ±Ö\", \"ÍµêÏú° ÌîÑÎ°úÍ∑∏Îû®\"]\n",
        "results = batch_search(queries)\n",
        "```\n",
        "\n",
        "### Î¨∏Ï†ú Ìï¥Í≤∞\n",
        "- **API ÌÇ§ Ïò§Î•ò**: OpenAI API ÌÇ§Í∞Ä Ïò¨Î∞îÎ•∏ÏßÄ ÌôïÏù∏\n",
        "- **Ïó∞Í≤∞ Ïò§Î•ò**: OpenSearch ÏÑúÎπÑÏä§Í∞Ä Ïã§Ìñâ Ï§ëÏù∏ÏßÄ ÌôïÏù∏\n",
        "- **Í≤ÄÏÉâ Í≤∞Í≥º ÏóÜÏùå**: Ïù∏Îç±Ïä§Ïóê Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏\n",
        "- **ÏùëÎãµ ÏÉùÏÑ± Ïã§Ìå®**: ÎÑ§Ìä∏ÏõåÌÅ¨ Ïó∞Í≤∞ Î∞è OpenAI API ÏÉÅÌÉú ÌôïÏù∏\n",
        "\n",
        "### ÏÑ±Îä• ÏµúÏ†ÅÌôî\n",
        "- Í≤ÄÏÉâ Í≤∞Í≥º ÏàòÎ•º Ï†ÅÏ†àÌûà Ï†úÌïú (Í∏∞Î≥∏Í∞í: 3Í∞ú)\n",
        "- Î≥µÏû°Ìïú ÏßàÎ¨∏ÏùÄ Îã®ÏàúÌïòÍ≤å ÎÇòÎàÑÏñ¥ Í≤ÄÏÉâ\n",
        "- ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî Í≤ÄÏÉâÏñ¥Îäî Ï∫êÏã± Í≥†Î†§\n",
        "\n",
        "**ÏôÑÎ£å!** Ïù¥Ï†ú Ï≤≠ÎÖÑÏ†ïÏ±Ö Í≤ÄÏÉâ ÏãúÏä§ÌÖúÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏäµÎãàÎã§. üéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

