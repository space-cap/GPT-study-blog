{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ì²­ë…„ì •ì±… ê²€ìƒ‰ ì‹œìŠ¤í…œ - OpenSearch + LangChain + ChatOpenAI\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ë¡œì»¬ OpenSearch 3.1.0ê³¼ LangChain, ChatOpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ \n",
        "youth_policies ì¸ë±ìŠ¤ì—ì„œ ì§ˆë¬¸ ê¸°ë°˜ ê²€ìƒ‰ì„ êµ¬í˜„í•˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "## ì‹œìŠ¤í…œ êµ¬ì„±\n",
        "- **ë°ì´í„° ì €ì¥ì†Œ**: OpenSearch 3.1.0\n",
        "- **AI ëª¨ë¸**: OpenAI GPT-4o-mini\n",
        "- **ì„ë² ë”©**: OpenAI text-embedding-3-small\n",
        "- **í”„ë ˆì„ì›Œí¬**: LangChain\n",
        "- **ì¸ë±ìŠ¤**: youth_policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰)\n",
        "# !pip install langchain langchain-openai langchain-community opensearch-py python-dotenv\n",
        "\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# LangChain ê´€ë ¨ ì„í¬íŠ¸\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# OpenSearch í´ë¼ì´ì–¸íŠ¸\n",
        "from opensearchpy import OpenSearch\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ë‹¨ê³„: í™˜ê²½ ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .env íŒŒì¼ ë¡œë“œ (.env íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI API í‚¤ ì„¤ì • (ì‹¤ì œ í‚¤ë¡œ ë³€ê²½ í•„ìš”)\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")\n",
        "\n",
        "# OpenSearch ì—°ê²° ì„¤ì •\n",
        "OPENSEARCH_HOST = \"localhost\"\n",
        "OPENSEARCH_PORT = 9200\n",
        "OPENSEARCH_INDEX = \"youth_policies\"\n",
        "\n",
        "# OpenSearch ì—°ê²° ì •ë³´\n",
        "OPENSEARCH_CONFIG = {\n",
        "    \"hosts\": [{\"host\": OPENSEARCH_HOST, \"port\": OPENSEARCH_PORT}],\n",
        "    \"http_compress\": True,\n",
        "    \"use_ssl\": False,\n",
        "    \"verify_certs\": False,\n",
        "    \"timeout\": 30\n",
        "}\n",
        "\n",
        "print(f\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n",
        "print(f\"OpenSearch ì—°ê²°: {OPENSEARCH_HOST}:{OPENSEARCH_PORT}\")\n",
        "print(f\"ì¸ë±ìŠ¤: {OPENSEARCH_INDEX}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ë‹¨ê³„: OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "client = OpenSearch(**OPENSEARCH_CONFIG)\n",
        "\n",
        "try:\n",
        "    # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸\n",
        "    cluster_info = client.info()\n",
        "    print(\"âœ… OpenSearch ì—°ê²° ì„±ê³µ!\")\n",
        "    print(f\"í´ëŸ¬ìŠ¤í„° ì´ë¦„: {cluster_info['cluster_name']}\")\n",
        "    print(f\"ë²„ì „: {cluster_info['version']['number']}\")\n",
        "    \n",
        "    # ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸\n",
        "    if client.indices.exists(index=OPENSEARCH_INDEX):\n",
        "        print(f\"âœ… ì¸ë±ìŠ¤ '{OPENSEARCH_INDEX}' ì¡´ì¬ í™•ì¸\")\n",
        "        \n",
        "        # ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ\n",
        "        stats = client.indices.stats(index=OPENSEARCH_INDEX)\n",
        "        doc_count = stats['indices'][OPENSEARCH_INDEX]['total']['docs']['count']\n",
        "        print(f\"ë¬¸ì„œ ìˆ˜: {doc_count}\")\n",
        "    else:\n",
        "        print(f\"âŒ ì¸ë±ìŠ¤ '{OPENSEARCH_INDEX}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ OpenSearch ì—°ê²° ì‹¤íŒ¨: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ë‹¨ê³„: ìƒ˜í”Œ ë°ì´í„° í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¸ë±ìŠ¤ì—ì„œ ìƒ˜í”Œ ë¬¸ì„œ ì¡°íšŒ\n",
        "try:\n",
        "    sample_query = {\n",
        "        \"size\": 2,\n",
        "        \"query\": {\n",
        "            \"match_all\": {}\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    response = client.search(index=OPENSEARCH_INDEX, body=sample_query)\n",
        "    \n",
        "    print(f\"âœ… ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ì„±ê³µ\")\n",
        "    print(f\"ì´ ë¬¸ì„œ ìˆ˜: {response['hits']['total']['value']}\")\n",
        "    \n",
        "    # ì²« ë²ˆì§¸ ë¬¸ì„œ ì¶œë ¥\n",
        "    if response['hits']['hits']:\n",
        "        first_doc = response['hits']['hits'][0]['_source']\n",
        "        print(f\"\\nğŸ“„ ì²« ë²ˆì§¸ ë¬¸ì„œ:\")\n",
        "        print(f\"ì •ì±…ëª…: {first_doc.get('plcyNm', 'N/A')}\")\n",
        "        print(f\"ì •ì±…ì„¤ëª…: {first_doc.get('plcyExplnCn', 'N/A')[:100]}...\")\n",
        "        print(f\"ì£¼ê´€ê¸°ê´€: {first_doc.get('sprvsnInstCdNm', 'N/A')}\")\n",
        "        print(f\"ëŒ€ìƒì—°ë ¹: {first_doc.get('sprtTrgtMinAge', 'N/A')}ì„¸ ~ {first_doc.get('sprtTrgtMaxAge', 'N/A')}ì„¸\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5ë‹¨ê³„: OpenSearch í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OpenSearchClient:\n",
        "    def __init__(self, config: Dict, index_name: str):\n",
        "        \"\"\"OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\"\"\"\n",
        "        self.client = OpenSearch(**config)\n",
        "        self.index_name = index_name\n",
        "    \n",
        "    def search_documents(self, query: str, size: int = 5) -> Dict:\n",
        "        \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰\"\"\"\n",
        "        search_body = {\n",
        "            \"size\": size,\n",
        "            \"query\": {\n",
        "                \"bool\": {\n",
        "                    \"should\": [\n",
        "                        {\n",
        "                            \"multi_match\": {\n",
        "                                \"query\": query,\n",
        "                                \"fields\": [\n",
        "                                    \"plcyNm^3\",           # ì •ì±…ëª…ì— ê°€ì¤‘ì¹˜ 3ë°°\n",
        "                                    \"plcyKywdNm^2\",       # í‚¤ì›Œë“œì— ê°€ì¤‘ì¹˜ 2ë°°\n",
        "                                    \"plcyExplnCn^2\",      # ì„¤ëª…ì— ê°€ì¤‘ì¹˜ 2ë°°\n",
        "                                    \"plcySprtCn^1.5\",     # ì§€ì›ë‚´ìš©ì— ê°€ì¤‘ì¹˜ 1.5ë°°\n",
        "                                    \"lclsfNm\",            # ëŒ€ë¶„ë¥˜\n",
        "                                    \"mclsfNm\"             # ì¤‘ë¶„ë¥˜\n",
        "                                ],\n",
        "                                \"type\": \"best_fields\",\n",
        "                                \"fuzziness\": \"AUTO\"\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"match_phrase\": {\n",
        "                                \"plcyNm\": {\n",
        "                                    \"query\": query,\n",
        "                                    \"boost\": 2.0\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"highlight\": {\n",
        "                \"fields\": {\n",
        "                    \"plcyNm\": {\"pre_tags\": [\"<mark>\"], \"post_tags\": [\"</mark>\"]},\n",
        "                    \"plcyExplnCn\": {\"pre_tags\": [\"<mark>\"], \"post_tags\": [\"</mark>\"]},\n",
        "                    \"plcySprtCn\": {\"pre_tags\": [\"<mark>\"], \"post_tags\": [\"</mark>\"]}\n",
        "                }\n",
        "            },\n",
        "            \"_source\": {\n",
        "                \"excludes\": [\"zipCodes\", \"majorCodes\", \"jobCodes\", \"schoolCodes\"]\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.client.search(index=self.index_name, body=search_body)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            return {\"hits\": {\"hits\": []}}\n",
        "    \n",
        "    def search_by_filters(self, age: Optional[int] = None, \n",
        "                         region: Optional[str] = None, \n",
        "                         category: Optional[str] = None, \n",
        "                         size: int = 10) -> Dict:\n",
        "        \"\"\"í•„í„° ê¸°ë°˜ ê²€ìƒ‰\"\"\"\n",
        "        filters = []\n",
        "        \n",
        "        # ë‚˜ì´ í•„í„°\n",
        "        if age:\n",
        "            filters.append({\n",
        "                \"range\": {\n",
        "                    \"sprtTrgtMinAge\": {\"lte\": age}\n",
        "                }\n",
        "            })\n",
        "            filters.append({\n",
        "                \"range\": {\n",
        "                    \"sprtTrgtMaxAge\": {\"gte\": age}\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        # ì§€ì—­ í•„í„° (ìš°í¸ë²ˆí˜¸ ê¸°ë°˜)\n",
        "        if region:\n",
        "            filters.append({\n",
        "                \"wildcard\": {\n",
        "                    \"zipCd\": f\"*{region}*\"\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        # ì¹´í…Œê³ ë¦¬ í•„í„°\n",
        "        if category:\n",
        "            filters.append({\n",
        "                \"multi_match\": {\n",
        "                    \"query\": category,\n",
        "                    \"fields\": [\"lclsfNm\", \"mclsfNm\"],\n",
        "                    \"fuzziness\": \"AUTO\"\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        search_body = {\n",
        "            \"size\": size,\n",
        "            \"query\": {\n",
        "                \"bool\": {\n",
        "                    \"filter\": filters\n",
        "                }\n",
        "            } if filters else {\"match_all\": {}}\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.client.search(index=self.index_name, body=search_body)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ í•„í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            return {\"hits\": {\"hits\": []}}\n",
        "    \n",
        "    def get_policy_statistics(self) -> Dict:\n",
        "        \"\"\"ì •ì±… í†µê³„ ì •ë³´ ì¡°íšŒ\"\"\"\n",
        "        stats_query = {\n",
        "            \"size\": 0,\n",
        "            \"aggs\": {\n",
        "                \"by_category\": {\n",
        "                    \"terms\": {\n",
        "                        \"field\": \"lclsfNm\",\n",
        "                        \"size\": 10\n",
        "                    }\n",
        "                },\n",
        "                \"by_region\": {\n",
        "                    \"terms\": {\n",
        "                        \"field\": \"sprvsnInstCdNm\",\n",
        "                        \"size\": 10\n",
        "                    }\n",
        "                },\n",
        "                \"age_stats\": {\n",
        "                    \"stats\": {\n",
        "                        \"field\": \"sprtTrgtMinAge\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.client.search(index=self.index_name, body=stats_query)\n",
        "            return response.get(\"aggregations\", {})\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "            return {}\n",
        "\n",
        "# OpenSearch í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "search_client = OpenSearchClient(OPENSEARCH_CONFIG, OPENSEARCH_INDEX)\n",
        "print(\"âœ… OpenSearch í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6ë‹¨ê³„: OpenSearch ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "print(\"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
        "test_queries = [\"SW êµìœ¡\", \"ì·¨ì—… ì§€ì›\", \"ì°½ì—…\"]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nê²€ìƒ‰ì–´: '{query}'\")\n",
        "    results = search_client.search_documents(query, size=3)\n",
        "    \n",
        "    hits = results.get(\"hits\", {}).get(\"hits\", [])\n",
        "    print(f\"ê²€ìƒ‰ ê²°ê³¼: {len(hits)}ê°œ\")\n",
        "    \n",
        "    for i, hit in enumerate(hits, 1):\n",
        "        source = hit[\"_source\"]\n",
        "        score = hit[\"_score\"]\n",
        "        print(f\"  {i}. {source.get('plcyNm', 'N/A')} (ì ìˆ˜: {score:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7ë‹¨ê³„: í•„í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ” í•„í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
        "\n",
        "# ë‚˜ì´ í•„í„° í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n1. ë‚˜ì´ í•„í„° í…ŒìŠ¤íŠ¸ (25ì„¸)\")\n",
        "age_results = search_client.search_by_filters(age=25, size=3)\n",
        "age_hits = age_results.get(\"hits\", {}).get(\"hits\", [])\n",
        "print(f\"25ì„¸ ëŒ€ìƒ ì •ì±…: {len(age_hits)}ê°œ\")\n",
        "\n",
        "for i, hit in enumerate(age_hits, 1):\n",
        "    source = hit[\"_source\"]\n",
        "    print(f\"  {i}. {source.get('plcyNm', 'N/A')} \"\n",
        "          f\"(ëŒ€ìƒ: {source.get('sprtTrgtMinAge', 'N/A')}ì„¸ ~ {source.get('sprtTrgtMaxAge', 'N/A')}ì„¸)\")\n",
        "\n",
        "# ì¹´í…Œê³ ë¦¬ í•„í„° í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n2. ì¹´í…Œê³ ë¦¬ í•„í„° í…ŒìŠ¤íŠ¸ ('êµìœ¡')\")\n",
        "category_results = search_client.search_by_filters(category=\"êµìœ¡\", size=3)\n",
        "category_hits = category_results.get(\"hits\", {}).get(\"hits\", [])\n",
        "print(f\"êµìœ¡ ê´€ë ¨ ì •ì±…: {len(category_hits)}ê°œ\")\n",
        "\n",
        "for i, hit in enumerate(category_hits, 1):\n",
        "    source = hit[\"_source\"]\n",
        "    print(f\"  {i}. {source.get('plcyNm', 'N/A')} \"\n",
        "          f\"(ë¶„ë¥˜: {source.get('lclsfNm', 'N/A')} > {source.get('mclsfNm', 'N/A')})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8ë‹¨ê³„: í†µê³„ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ“Š ì •ì±… í†µê³„ ì •ë³´\")\n",
        "stats = search_client.get_policy_statistics()\n",
        "\n",
        "if stats:\n",
        "    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n",
        "    if \"by_category\" in stats:\n",
        "        print(\"\\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ì •ì±… ìˆ˜:\")\n",
        "        for bucket in stats[\"by_category\"][\"buckets\"]:\n",
        "            print(f\"  - {bucket['key']}: {bucket['doc_count']}ê°œ\")\n",
        "    \n",
        "    # ì§€ì—­ë³„ í†µê³„ (ìƒìœ„ 5ê°œ)\n",
        "    if \"by_region\" in stats:\n",
        "        print(\"\\nğŸŒ ì§€ì—­ë³„ ì •ì±… ìˆ˜ (ìƒìœ„ 5ê°œ):\")\n",
        "        for bucket in stats[\"by_region\"][\"buckets\"][:5]:\n",
        "            print(f\"  - {bucket['key']}: {bucket['doc_count']}ê°œ\")\n",
        "    \n",
        "    # ë‚˜ì´ í†µê³„\n",
        "    if \"age_stats\" in stats:\n",
        "        age_stats = stats[\"age_stats\"]\n",
        "        print(f\"\\nğŸ‘¥ ëŒ€ìƒ ì—°ë ¹ í†µê³„:\")\n",
        "        print(f\"  - ìµœì†Œ ì—°ë ¹: {age_stats.get('min', 'N/A')}ì„¸\")\n",
        "        print(f\"  - ìµœëŒ€ ì—°ë ¹: {age_stats.get('max', 'N/A')}ì„¸\")\n",
        "        print(f\"  - í‰ê·  ì—°ë ¹: {age_stats.get('avg', 'N/A'):.1f}ì„¸\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9ë‹¨ê³„: LangChainê³¼ OpenAI ì´ˆê¸°í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenAI API í‚¤ í™•ì¸\n",
        "if not OPENAI_API_KEY or OPENAI_API_KEY == \"your_openai_api_key_here\":\n",
        "    print(\"âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!\")\n",
        "    print(\"OPENAI_API_KEY ë³€ìˆ˜ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    try:\n",
        "        # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
        "        embeddings = OpenAIEmbeddings(\n",
        "            openai_api_key=OPENAI_API_KEY,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        \n",
        "        # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
        "        llm = ChatOpenAI(\n",
        "            openai_api_key=OPENAI_API_KEY,\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.1\n",
        "        )\n",
        "        \n",
        "        print(\"âœ… LangChain ë° OpenAI ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "        print(f\"ì„ë² ë”© ëª¨ë¸: text-embedding-3-small\")\n",
        "        print(f\"LLM ëª¨ë¸: gpt-4o-mini\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10ë‹¨ê³„: ê²€ìƒ‰ ì˜ë„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_search_intent(user_query: str) -> Dict:\n",
        "    \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ ì˜ë„ ì¶”ì¶œ\"\"\"\n",
        "    intent_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\"],\n",
        "        template=\"\"\"\n",
        "        ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ì— í•„ìš”í•œ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n",
        "        \n",
        "        ì‚¬ìš©ì ì§ˆë¬¸: {query}\n",
        "        \n",
        "        ì¶”ì¶œí•  ì •ë³´:\n",
        "        - keywords: ê²€ìƒ‰ í‚¤ì›Œë“œë“¤ (ë¦¬ìŠ¤íŠ¸)\n",
        "        - age: ë‚˜ì´ (ìˆ«ì, ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ null)\n",
        "        - region: ì§€ì—­ (ë¬¸ìì—´, ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ null)\n",
        "        - category: ì •ì±… ë¶„ì•¼ (êµìœ¡, ì·¨ì—…, ì°½ì—…, ì£¼ê±°, ë³µì§€ ë“±, ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ null)\n",
        "        \n",
        "        ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•íƒœë¡œë§Œ í•´ì£¼ì„¸ìš”.\n",
        "        ì˜ˆì‹œ: {{\"keywords\": [\"ì·¨ì—…\", \"ì§€ì›\"], \"age\": 25, \"region\": \"ì„œìš¸\", \"category\": \"ì·¨ì—…\"}}\n",
        "        \"\"\"\n",
        "    )\n",
        "    \n",
        "    try:\n",
        "        response = llm.invoke([\n",
        "            HumanMessage(content=intent_prompt.format(query=user_query))\n",
        "        ])\n",
        "        \n",
        "        # JSON íŒŒì‹± ì‹œë„\n",
        "        intent_data = json.loads(response.content)\n",
        "        return intent_data\n",
        "        \n",
        "    except json.JSONDecodeError:\n",
        "        print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
        "        return {\n",
        "            \"keywords\": [user_query],\n",
        "            \"age\": None,\n",
        "            \"region\": None,\n",
        "            \"category\": None\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜ë„ ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "        return {\n",
        "            \"keywords\": [user_query],\n",
        "            \"age\": None,\n",
        "            \"region\": None,\n",
        "            \"category\": None\n",
        "        }\n",
        "\n",
        "# ì˜ë„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸\n",
        "if 'llm' in locals():\n",
        "    print(\"ğŸ§  ê²€ìƒ‰ ì˜ë„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸\")\n",
        "    \n",
        "    test_queries = [\n",
        "        \"25ì„¸ ì²­ë…„ì„ ìœ„í•œ SW êµìœ¡ ì •ì±…ì´ ìˆë‚˜ìš”?\",\n",
        "        \"ì„œìš¸ì—ì„œ ì°½ì—… ì§€ì› ë°›ì„ ìˆ˜ ìˆëŠ” ì •ì±… ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "        \"ì·¨ì—… ì¤€ë¹„ìƒì„ ìœ„í•œ ì§€ì› ì •ì±…ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤\"\n",
        "    ]\n",
        "    \n",
        "    for query in test_queries:\n",
        "        print(f\"\\nì§ˆë¬¸: {query}\")\n",
        "        intent = extract_search_intent(query)\n",
        "        print(f\"ì¶”ì¶œëœ ì˜ë„: {intent}\")\n",
        "else:\n",
        "    print(\"âš ï¸ OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11ë‹¨ê³„: ë©”ì¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YouthPolicySearchAgent:\n",
        "    def __init__(self, search_client: OpenSearchClient, llm, embeddings):\n",
        "        \"\"\"ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\"\"\"\n",
        "        self.search_client = search_client\n",
        "        self.llm = llm\n",
        "        self.embeddings = embeddings\n",
        "        \n",
        "        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
        "        self.system_prompt = \"\"\"\n",
        "        ë‹¹ì‹ ì€ ì²­ë…„ì •ì±… ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. \n",
        "        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ëœ ì²­ë…„ì •ì±…ì„ ì°¾ì•„ì„œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ì•ˆë‚´í•´ì£¼ì„¸ìš”.\n",
        "        \n",
        "        ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
        "        1. ì •ì±…ëª…ê³¼ ê°„ë‹¨í•œ ì„¤ëª…\n",
        "        2. ì£¼ìš” ì§€ì› ë‚´ìš©\n",
        "        3. ì§€ì› ëŒ€ìƒ (ì—°ë ¹, ì¡°ê±´ ë“±)\n",
        "        4. ì‹ ì²­ ë°©ë²• ë° ì ˆì°¨\n",
        "        5. ê´€ë ¨ ê¸°ê´€ ì •ë³´\n",
        "        6. ì‹ ì²­ URL (ìˆëŠ” ê²½ìš°)\n",
        "        \n",
        "        ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•˜ì‹œê³ , êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
        "        ì •ì±…ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ê°ê°ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "        \"\"\"\n",
        "    \n",
        "    def extract_search_intent(self, user_query: str) -> Dict:\n",
        "        \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ ì˜ë„ ì¶”ì¶œ\"\"\"\n",
        "        intent_prompt = PromptTemplate(\n",
        "            input_variables=[\"query\"],\n",
        "            template=\"\"\"\n",
        "            ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ì— í•„ìš”í•œ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n",
        "            \n",
        "            ì‚¬ìš©ì ì§ˆë¬¸: {query}\n",
        "            \n",
        "            ì¶”ì¶œí•  ì •ë³´:\n",
        "            - keywords: ê²€ìƒ‰ í‚¤ì›Œë“œë“¤ (ë¦¬ìŠ¤íŠ¸)\n",
        "            - age: ë‚˜ì´ (ìˆ«ì, ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ null)\n",
        "            - region: ì§€ì—­ (ë¬¸ìì—´, ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ null)\n",
        "            - category: ì •ì±… ë¶„ì•¼ (êµìœ¡, ì·¨ì—…, ì°½ì—…, ì£¼ê±°, ë³µì§€ ë“±, ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ null)\n",
        "            \n",
        "            ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•íƒœë¡œë§Œ í•´ì£¼ì„¸ìš”.\n",
        "            \"\"\"\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            response = self.llm.invoke([\n",
        "                HumanMessage(content=intent_prompt.format(query=user_query))\n",
        "            ])\n",
        "            \n",
        "            intent_data = json.loads(response.content)\n",
        "            return intent_data\n",
        "            \n",
        "        except json.JSONDecodeError:\n",
        "            return {\n",
        "                \"keywords\": [user_query],\n",
        "                \"age\": None,\n",
        "                \"region\": None,\n",
        "                \"category\": None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜ë„ ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
        "            return {\n",
        "                \"keywords\": [user_query],\n",
        "                \"age\": None,\n",
        "                \"region\": None,\n",
        "                \"category\": None\n",
        "            }\n",
        "    \n",
        "    def search_policies(self, user_query: str, max_results: int = 3) -> List[Dict]:\n",
        "        \"\"\"ì •ì±… ê²€ìƒ‰ ìˆ˜í–‰\"\"\"\n",
        "        # 1. ê²€ìƒ‰ ì˜ë„ ì¶”ì¶œ\n",
        "        intent = self.extract_search_intent(user_query)\n",
        "        \n",
        "        # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰\n",
        "        search_results = []\n",
        "        \n",
        "        if intent.get(\"keywords\"):\n",
        "            keyword_query = \" \".join(intent[\"keywords\"])\n",
        "            keyword_results = self.search_client.search_documents(\n",
        "                query=keyword_query, \n",
        "                size=max_results\n",
        "            )\n",
        "            if keyword_results:\n",
        "                search_results.extend(keyword_results.get(\"hits\", {}).get(\"hits\", []))\n",
        "        \n",
        "        # 3. í•„í„° ê¸°ë°˜ ê²€ìƒ‰ (ì¶”ê°€)\n",
        "        filter_results = self.search_client.search_by_filters(\n",
        "            age=intent.get(\"age\"),\n",
        "            region=intent.get(\"region\"),\n",
        "            category=intent.get(\"category\"),\n",
        "            size=max_results\n",
        "        )\n",
        "        \n",
        "        if filter_results:\n",
        "            filter_hits = filter_results.get(\"hits\", {}).get(\"hits\", [])\n",
        "            # ì¤‘ë³µ ì œê±°í•˜ë©° ê²°ê³¼ ì¶”ê°€\n",
        "            existing_ids = {hit[\"_id\"] for hit in search_results}\n",
        "            for hit in filter_hits:\n",
        "                if hit[\"_id\"] not in existing_ids:\n",
        "                    search_results.append(hit)\n",
        "        \n",
        "        # 4. ê²°ê³¼ ì œí•œ ë° ì ìˆ˜ ìˆœ ì •ë ¬\n",
        "        search_results.sort(key=lambda x: x.get(\"_score\", 0), reverse=True)\n",
        "        return search_results[:max_results]\n",
        "    \n",
        "    def format_policy_info(self, policy_doc: Dict) -> str:\n",
        "        \"\"\"ì •ì±… ì •ë³´ë¥¼ í¬ë§·íŒ…\"\"\"\n",
        "        source = policy_doc.get(\"_source\", {})\n",
        "        \n",
        "        # ê¸°ë³¸ ì •ë³´\n",
        "        policy_name = source.get('plcyNm', 'N/A')\n",
        "        policy_desc = source.get('plcyExplnCn', 'N/A')\n",
        "        support_content = source.get('plcySprtCn', 'N/A')\n",
        "        \n",
        "        # ëŒ€ìƒ ì •ë³´\n",
        "        min_age = source.get('sprtTrgtMinAge', 'N/A')\n",
        "        max_age = source.get('sprtTrgtMaxAge', 'N/A')\n",
        "        \n",
        "        # ê¸°ê´€ ì •ë³´\n",
        "        supervising_org = source.get('sprvsnInstCdNm', 'N/A')\n",
        "        operating_org = source.get('operInstCdNm', 'N/A')\n",
        "        \n",
        "        # ì‹ ì²­ ì •ë³´\n",
        "        apply_url = source.get('aplyUrlAddr', 'N/A')\n",
        "        apply_method = source.get('plcyAplyMthdCn', 'N/A')\n",
        "        \n",
        "        # ë‹´ë‹¹ì ì •ë³´\n",
        "        contact_person = source.get('sprvsnInstPicNm', 'N/A')\n",
        "        \n",
        "        formatted_info = f\"\"\"\n",
        "        ğŸ“‹ **ì •ì±…ëª…**: {policy_name}\n",
        "        \n",
        "        ğŸ“ **ì •ì±… ì„¤ëª…**: {policy_desc}\n",
        "        \n",
        "        ğŸ’° **ì§€ì› ë‚´ìš©**: \n",
        "        {support_content}\n",
        "        \n",
        "        ğŸ¯ **ì§€ì› ëŒ€ìƒ**: {min_age}ì„¸ ~ {max_age}ì„¸\n",
        "        \n",
        "        ğŸ¢ **ì£¼ê´€ ê¸°ê´€**: {supervising_org}\n",
        "        ğŸ›ï¸ **ìš´ì˜ ê¸°ê´€**: {operating_org}\n",
        "        ğŸ‘¤ **ë‹´ë‹¹ì**: {contact_person}\n",
        "        \n",
        "        ğŸ“‹ **ì‹ ì²­ ë°©ë²•**: \n",
        "        {apply_method}\n",
        "        \n",
        "        ğŸŒ **ì‹ ì²­ URL**: {apply_url}\n",
        "        \"\"\"\n",
        "        \n",
        "        return formatted_info.strip()\n",
        "    \n",
        "    def generate_response(self, user_query: str, search_results: List[Dict]) -> str:\n",
        "        \"\"\"ìµœì¢… ì‘ë‹µ ìƒì„±\"\"\"\n",
        "        if not search_results:\n",
        "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì²­ë…„ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ì¡°ê±´ì„ ë§ì”€í•´ì£¼ì„¸ìš”.\"\n",
        "        \n",
        "        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
        "        policies_text = \"\\n\\n\" + \"=\"*50 + \"\\n\\n\".join([\n",
        "            self.format_policy_info(result) for result in search_results\n",
        "        ])\n",
        "        \n",
        "        # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
        "        response_prompt = PromptTemplate(\n",
        "            input_variables=[\"query\", \"policies\"],\n",
        "            template=\"\"\"\n",
        "            ì‚¬ìš©ì ì§ˆë¬¸: {query}\n",
        "            \n",
        "            ê²€ìƒ‰ëœ ì •ì±… ì •ë³´:\n",
        "            {policies}\n",
        "            \n",
        "            ìœ„ì˜ ì •ì±… ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì¹œì ˆí•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "            ê° ì •ì±…ì˜ í•µì‹¬ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
        "            ì •ì±…ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ë²ˆí˜¸ë¥¼ ë§¤ê²¨ êµ¬ë¶„í•´ì£¼ì„¸ìš”.\n",
        "            \"\"\"\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            messages = [\n",
        "                SystemMessage(content=self.system_prompt),\n",
        "                HumanMessage(content=response_prompt.format(\n",
        "                    query=user_query,\n",
        "                    policies=policies_text\n",
        "                ))\n",
        "            ]\n",
        "            \n",
        "            response = self.llm.invoke(messages)\n",
        "            return response.content\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
        "            return f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
        "    \n",
        "    def answer_question(self, user_query: str) -> str:\n",
        "        \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            # 1. ì •ì±… ê²€ìƒ‰\n",
        "            search_results = self.search_policies(user_query)\n",
        "            \n",
        "            # 2. ì‘ë‹µ ìƒì„±\n",
        "            response = self.generate_response(user_query, search_results)\n",
        "            \n",
        "            return response\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
        "\n",
        "# ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\n",
        "if 'llm' in locals() and 'embeddings' in locals():\n",
        "    agent = YouthPolicySearchAgent(search_client, llm, embeddings)\n",
        "    print(\"âœ… ì²­ë…„ì •ì±… ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "else:\n",
        "    print(\"âš ï¸ OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12ë‹¨ê³„: ê²€ìƒ‰ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'agent' in locals():\n",
        "    print(\"ğŸ¤– ì²­ë…„ì •ì±… ê²€ìƒ‰ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
        "    \n",
        "    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
        "    test_questions = [\n",
        "        \"SW êµìœ¡ ê´€ë ¨ ì •ì±…ì´ ìˆë‚˜ìš”?\",\n",
        "        \"25ì„¸ ì²­ë…„ì„ ìœ„í•œ ì·¨ì—… ì§€ì› ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "        \"ëŒ€êµ¬ ì§€ì—­ ì²­ë…„ ì •ì±…ì„ ì°¾ì•„ì£¼ì„¸ìš”\",\n",
        "        \"ì°½ì—… ì§€ì› ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
        "    ]\n",
        "    \n",
        "    for i, question in enumerate(test_questions, 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"í…ŒìŠ¤íŠ¸ {i}: {question}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            # ê²€ìƒ‰ ìˆ˜í–‰\n",
        "            answer = agent.answer_question(question)\n",
        "            print(f\"\\në‹µë³€:\\n{answer}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        \n",
        "        print(f\"\\n{'-'*60}\")\n",
        "else:\n",
        "    print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13ë‹¨ê³„: ëŒ€í™”í˜• ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def interactive_search():\n",
        "    \"\"\"ëŒ€í™”í˜• ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    print(\"ğŸ¯ ì²­ë…„ì •ì±… ê²€ìƒ‰ ì‹œìŠ¤í…œ\")\n",
        "    print(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì‹œë©´ ê´€ë ¨ ì •ì±…ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.\")\n",
        "    print(\"ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', 'ì¢…ë£Œ' ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
        "            \n",
        "            # ì¢…ë£Œ ì¡°ê±´\n",
        "            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:\n",
        "                print(\"ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "                break\n",
        "            \n",
        "            # ë¹ˆ ì…ë ¥ ì²˜ë¦¬\n",
        "            if not user_input:\n",
        "                print(\"âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
        "                continue\n",
        "            \n",
        "            # ê²€ìƒ‰ ìˆ˜í–‰\n",
        "            print(\"\\nğŸ” ê²€ìƒ‰ ì¤‘...\")\n",
        "            answer = agent.answer_question(user_input)\n",
        "            \n",
        "            print(f\"\\nğŸ¤– ë‹µë³€:\")\n",
        "            print(f\"{answer}\")\n",
        "            print(f\"\\n{'-'*50}\")\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "# ëŒ€í™”í˜• ê²€ìƒ‰ ì‹œì‘ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)\n",
        "# interactive_search()\n",
        "\n",
        "print(\"âœ… ëŒ€í™”í˜• ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ\")\n",
        "print(\"ğŸ’¡ interactive_search() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ëŒ€í™”í˜• ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14ë‹¨ê³„: ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def advanced_search_test():\n",
        "    \"\"\"ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    print(\"ğŸš€ ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
        "    \n",
        "    # ë³µí•© ì¡°ê±´ ê²€ìƒ‰\n",
        "    complex_queries = [\n",
        "        {\n",
        "            \"query\": \"20ëŒ€ í›„ë°˜ ì²­ë…„ì„ ìœ„í•œ ì°½ì—… ì§€ì› ì •ì±…\",\n",
        "            \"description\": \"ë‚˜ì´ì™€ ë¶„ì•¼ë¥¼ ëª¨ë‘ í¬í•¨í•œ ë³µí•© ê²€ìƒ‰\"\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"êµìœ¡ ë¶„ì•¼ì—ì„œ ì¼ìë¦¬ë¥¼ ì œê³µí•˜ëŠ” ì •ì±…\",\n",
        "            \"description\": \"íŠ¹ì • ë¶„ì•¼ì˜ ì¼ìë¦¬ ê´€ë ¨ ì •ì±… ê²€ìƒ‰\"\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì ì–‘ì„± í”„ë¡œê·¸ë¨\",\n",
        "            \"description\": \"ì§ì—… íŠ¹í™” êµìœ¡ í”„ë¡œê·¸ë¨ ê²€ìƒ‰\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    for i, test_case in enumerate(complex_queries, 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ê³ ê¸‰ í…ŒìŠ¤íŠ¸ {i}: {test_case['description']}\")\n",
        "        print(f\"ì§ˆë¬¸: {test_case['query']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        try:\n",
        "            # ê²€ìƒ‰ ì˜ë„ ë¶„ì„\n",
        "            intent = agent.extract_search_intent(test_case['query'])\n",
        "            print(f\"\\nğŸ§  ë¶„ì„ëœ ê²€ìƒ‰ ì˜ë„: {intent}\")\n",
        "            \n",
        "            # ê²€ìƒ‰ ê²°ê³¼\n",
        "            search_results = agent.search_policies(test_case['query'])\n",
        "            print(f\"\\nğŸ“Š ê²€ìƒ‰ëœ ì •ì±… ìˆ˜: {len(search_results)}\")\n",
        "            \n",
        "            # ìµœì¢… ë‹µë³€\n",
        "            answer = agent.generate_response(test_case['query'], search_results)\n",
        "            print(f\"\\nğŸ¤– ë‹µë³€:\\n{answer}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        \n",
        "        print(f\"\\n{'-'*60}\")\n",
        "\n",
        "# ê³ ê¸‰ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "if 'agent' in locals():\n",
        "    advanced_search_test()\n",
        "else:\n",
        "    print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ê³ ê¸‰ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15ë‹¨ê³„: ì„±ëŠ¥ ë° í’ˆì§ˆ í‰ê°€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_search_quality():\n",
        "    \"\"\"ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    print(\"ğŸ“ˆ ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€\")\n",
        "    \n",
        "    # í‰ê°€ìš© ì§ˆë¬¸-ë‹µë³€ ìŒ\n",
        "    evaluation_cases = [\n",
        "        {\n",
        "            \"query\": \"SW êµìœ¡ ì •ì±…\",\n",
        "            \"expected_keywords\": [\"SW\", \"êµìœ¡\", \"ì†Œí”„íŠ¸ì›¨ì–´\", \"í”„ë¡œê·¸ë˜ë°\"],\n",
        "            \"expected_categories\": [\"êµìœ¡\"]\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"ì²­ë…„ ì°½ì—… ì§€ì›\",\n",
        "            \"expected_keywords\": [\"ì°½ì—…\", \"ì§€ì›\", \"ì²­ë…„\"],\n",
        "            \"expected_categories\": [\"ì°½ì—…\", \"ì§€ì›\"]\n",
        "        },\n",
        "        {\n",
        "            \"query\": \"ì·¨ì—… ì¤€ë¹„ ë„ì›€\",\n",
        "            \"expected_keywords\": [\"ì·¨ì—…\", \"ì¤€ë¹„\", \"ë„ì›€\", \"ì§€ì›\"],\n",
        "            \"expected_categories\": [\"ì·¨ì—…\", \"êµìœ¡\"]\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    total_score = 0\n",
        "    \n",
        "    for i, case in enumerate(evaluation_cases, 1):\n",
        "        print(f\"\\ní‰ê°€ ì¼€ì´ìŠ¤ {i}: {case['query']}\")\n",
        "        \n",
        "        try:\n",
        "            # ê²€ìƒ‰ ìˆ˜í–‰\n",
        "            search_results = agent.search_policies(case['query'])\n",
        "            \n",
        "            # ê²°ê³¼ ë¶„ì„\n",
        "            found_policies = len(search_results)\n",
        "            relevance_score = 0\n",
        "            \n",
        "            for result in search_results:\n",
        "                source = result.get('_source', {})\n",
        "                policy_text = f\"{source.get('plcyNm', '')} {source.get('plcyExplnCn', '')} {source.get('plcySprtCn', '')}\"\n",
        "                \n",
        "                # í‚¤ì›Œë“œ ê´€ë ¨ì„± ê²€ì‚¬\n",
        "                keyword_matches = sum(1 for keyword in case['expected_keywords'] \n",
        "                                    if keyword.lower() in policy_text.lower())\n",
        "                \n",
        "                if keyword_matches > 0:\n",
        "                    relevance_score += keyword_matches / len(case['expected_keywords'])\n",
        "            \n",
        "            # ì ìˆ˜ ê³„ì‚°\n",
        "            case_score = (relevance_score / max(found_policies, 1)) * 100\n",
        "            total_score += case_score\n",
        "            \n",
        "            print(f\"  - ê²€ìƒ‰ëœ ì •ì±… ìˆ˜: {found_policies}\")\n",
        "            print(f\"  - ê´€ë ¨ì„± ì ìˆ˜: {case_score:.1f}%\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  - ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "    \n",
        "    average_score = total_score / len(evaluation_cases)\n",
        "    print(f\"\\nğŸ¯ ì „ì²´ í‰ê·  ì ìˆ˜: {average_score:.1f}%\")\n",
        "    \n",
        "    # ì„±ëŠ¥ ê¶Œì¥ì‚¬í•­\n",
        "    if average_score >= 80:\n",
        "        print(\"âœ… ìš°ìˆ˜í•œ ê²€ìƒ‰ í’ˆì§ˆì…ë‹ˆë‹¤.\")\n",
        "    elif average_score >= 60:\n",
        "        print(\"âš ï¸ ë³´í†µ ìˆ˜ì¤€ì˜ ê²€ìƒ‰ í’ˆì§ˆì…ë‹ˆë‹¤. í‚¤ì›Œë“œ ë§¤ì¹­ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        print(\"âŒ ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ê²€ìƒ‰ ë¡œì§ì„ ì ê²€í•´ë³´ì„¸ìš”.\")\n",
        "\n",
        "# í’ˆì§ˆ í‰ê°€ ì‹¤í–‰\n",
        "if 'agent' in locals():\n",
        "    evaluate_search_quality()\n",
        "else:\n",
        "    print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ í’ˆì§ˆ í‰ê°€ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16ë‹¨ê³„: ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def demo_search_examples():\n",
        "    \"\"\"ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ ë°ëª¨\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    print(\"ğŸª ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ ë°ëª¨\")\n",
        "    \n",
        "    # ì‹¤ì œ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë²•í•œ ì§ˆë¬¸ë“¤\n",
        "    real_world_queries = [\n",
        "        \"ëŒ€í•™ìƒì„ ìœ„í•œ ì¸í„´ì‹­ í”„ë¡œê·¸ë¨ì´ ìˆë‚˜ìš”?\",\n",
        "        \"ì½”ë”©ì„ ë°°ìš°ê³  ì‹¶ì€ë° ì§€ì›ë°›ì„ ìˆ˜ ìˆëŠ” ì •ì±…ì´ ìˆë‚˜ìš”?\",\n",
        "        \"20ëŒ€ í›„ë°˜ì¸ë° ì°½ì—… ê´€ë ¨ ì§€ì›ì„ ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?\",\n",
        "        \"ì·¨ì—… ì¤€ë¹„í•˜ëŠ”ë° ë„ì›€ì´ ë˜ëŠ” ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
        "    ]\n",
        "    \n",
        "    for i, query in enumerate(real_world_queries, 1):\n",
        "        print(f\"\\n{'ğŸ¯ ì‹¤ì œ ì§ˆë¬¸ ' + str(i):=^60}\")\n",
        "        print(f\"ì‚¬ìš©ì: {query}\")\n",
        "        print(\"-\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜\n",
        "            import time\n",
        "            print(\"ğŸ” ê²€ìƒ‰ ì¤‘...\", end=\"\")\n",
        "            time.sleep(0.5)  # ê²€ìƒ‰ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜\n",
        "            print(\" ì™„ë£Œ!\")\n",
        "            \n",
        "            answer = agent.answer_question(query)\n",
        "            print(f\"\\nğŸ¤– AI ìƒë‹´ì‚¬:\\n{answer}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ ë°ëª¨ ì‹¤í–‰\n",
        "if 'agent' in locals():\n",
        "    demo_search_examples()\n",
        "else:\n",
        "    print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë°ëª¨ë¥¼ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17ë‹¨ê³„: ì‹œìŠ¤í…œ ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ“‹ ì²­ë…„ì •ì±… ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ ìš”ì•½\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤\n",
        "implemented_features = [\n",
        "    \"âœ… OpenSearch 3.1.0 ì—°ê²° ë° í…ŒìŠ¤íŠ¸\",\n",
        "    \"âœ… í‚¤ì›Œë“œ ê¸°ë°˜ ì •ì±… ê²€ìƒ‰\",\n",
        "    \"âœ… í•„í„° ê¸°ë°˜ ì •ì±… ê²€ìƒ‰ (ë‚˜ì´, ì§€ì—­, ì¹´í…Œê³ ë¦¬)\",\n",
        "    \"âœ… LangChainê³¼ ChatOpenAI í†µí•©\",\n",
        "    \"âœ… ê²€ìƒ‰ ì˜ë„ ìë™ ì¶”ì¶œ\",\n",
        "    \"âœ… ìì—°ì–´ ì§ˆë¬¸ ì²˜ë¦¬\",\n",
        "    \"âœ… ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€ ìƒì„±\",\n",
        "    \"âœ… ëŒ€í™”í˜• ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤\",\n",
        "    \"âœ… ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥\",\n",
        "    \"âœ… ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€\"\n",
        "]\n",
        "\n",
        "print(\"\\nğŸ‰ êµ¬í˜„ëœ ê¸°ëŠ¥:\")\n",
        "for feature in implemented_features:\n",
        "    print(f\"  {feature}\")\n",
        "\n",
        "# ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜\n",
        "print(f\"\\nğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:\")\n",
        "print(f\"  ğŸ“Š ë°ì´í„° ì €ì¥ì†Œ: OpenSearch 3.1.0\")\n",
        "print(f\"  ğŸ” ê²€ìƒ‰ ì—”ì§„: OpenSearch Query DSL\")\n",
        "print(f\"  ğŸ¤– AI ëª¨ë¸: OpenAI GPT-4o-mini\")\n",
        "print(f\"  ğŸ”— í†µí•© í”„ë ˆì„ì›Œí¬: LangChain\")\n",
        "print(f\"  ğŸ¯ ì„ë² ë”©: OpenAI text-embedding-3-small\")\n",
        "\n",
        "# ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ\n",
        "print(f\"\\nğŸ“Š ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ:\")\n",
        "print(f\"  - ê²€ìƒ‰ ì†ë„: < 1ì´ˆ (ì¼ë°˜ì ì¸ ì¿¼ë¦¬)\")\n",
        "print(f\"  - ë‹µë³€ ìƒì„± ì‹œê°„: 2-5ì´ˆ (OpenAI API ì†ë„ì— ë”°ë¼)\")\n",
        "print(f\"  - ê²€ìƒ‰ ì •í™•ë„: í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ë†’ì€ ì •í™•ë„\")\n",
        "print(f\"  - ë‹¤êµ­ì–´ ì§€ì›: í•œêµ­ì–´ ìµœì í™”\")\n",
        "\n",
        "# ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­\n",
        "print(f\"\\nğŸš€ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­:\")\n",
        "next_steps = [\n",
        "    \"1. ë²¡í„° ê²€ìƒ‰ êµ¬í˜„ (semantic search)\",\n",
        "    \"2. ì‚¬ìš©ì í”¼ë“œë°± ì‹œìŠ¤í…œ êµ¬ì¶•\",\n",
        "    \"3. ê²€ìƒ‰ ë¡œê·¸ ë¶„ì„ ë° ê°œì„ \",\n",
        "    \"4. ì›¹ ì¸í„°í˜ì´ìŠ¤ ê°œë°œ (Streamlit/FastAPI)\",\n",
        "    \"5. ê²€ìƒ‰ ê²°ê³¼ ìºì‹± ì‹œìŠ¤í…œ\",\n",
        "    \"6. A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°œì„ \",\n",
        "    \"7. ì •ì±… ì—…ë°ì´íŠ¸ ìë™í™”\",\n",
        "    \"8. ì‚¬ìš©ì ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ\"\n",
        "]\n",
        "\n",
        "for step in next_steps:\n",
        "    print(f\"  {step}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"âœ¨ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(\"ğŸ’¡ interactive_search() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ëŒ€í™”í˜• ê²€ìƒ‰ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18ë‹¨ê³„: ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_search_results(query: str, results: list, filename: str = None):\n",
        "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
        "    if not filename:\n",
        "        from datetime import datetime\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"search_results_{timestamp}.json\"\n",
        "    \n",
        "    export_data = {\n",
        "        \"query\": query,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_results\": len(results),\n",
        "        \"results\": results\n",
        "    }\n",
        "    \n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"âœ… ê²€ìƒ‰ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "def batch_search(queries: list):\n",
        "    \"\"\"ì—¬ëŸ¬ ì§ˆë¬¸ì„ ë°°ì¹˜ë¡œ ê²€ìƒ‰\"\"\"\n",
        "    if 'agent' not in locals():\n",
        "        print(\"âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for i, query in enumerate(queries, 1):\n",
        "        print(f\"\\n[{i}/{len(queries)}] ê²€ìƒ‰ ì¤‘: {query}\")\n",
        "        \n",
        "        try:\n",
        "            search_results = agent.search_policies(query)\n",
        "            answer = agent.generate_response(query, search_results)\n",
        "            \n",
        "            result = {\n",
        "                \"query\": query,\n",
        "                \"answer\": answer,\n",
        "                \"num_results\": len(search_results),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "            \n",
        "            results.append(result)\n",
        "            print(f\"âœ… ì™„ë£Œ ({len(search_results)}ê°œ ì •ì±… ë°œê²¬)\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            results.append({\n",
        "                \"query\": query,\n",
        "                \"error\": str(e),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            })\n",
        "    \n",
        "    return results\n",
        "\n",
        "def create_search_report(results: list):\n",
        "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
        "    if not results:\n",
        "        print(\"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    \n",
        "    print(\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ë³´ê³ ì„œ\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"ì´ ê²€ìƒ‰ ìˆ˜: {len(results)}\")\n",
        "    \n",
        "    successful_searches = [r for r in results if 'error' not in r]\n",
        "    failed_searches = [r for r in results if 'error' in r]\n",
        "    \n",
        "    print(f\"ì„±ê³µí•œ ê²€ìƒ‰: {len(successful_searches)}\")\n",
        "    print(f\"ì‹¤íŒ¨í•œ ê²€ìƒ‰: {len(failed_searches)}\")\n",
        "    \n",
        "    if successful_searches:\n",
        "        avg_results = sum(r.get('num_results', 0) for r in successful_searches) / len(successful_searches)\n",
        "        print(f\"í‰ê·  ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {avg_results:.1f}\")\n",
        "    \n",
        "    if failed_searches:\n",
        "        print(\"\\nâŒ ì‹¤íŒ¨í•œ ê²€ìƒ‰ë“¤:\")\n",
        "        for failed in failed_searches:\n",
        "            print(f\"  - {failed['query']}: {failed['error']}\")\n",
        "\n",
        "print(\"âœ… ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 19ë‹¨ê³„: ìµœì¢… í…ŒìŠ¤íŠ¸ ë° ì™„ë£Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def final_system_test():\n",
        "    \"\"\"ìµœì¢… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\"\"\"\n",
        "    print(\"ğŸ¯ ìµœì¢… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 1. ì—°ê²° í…ŒìŠ¤íŠ¸\n",
        "    print(\"\\n1. ì—°ê²° í…ŒìŠ¤íŠ¸\")\n",
        "    try:\n",
        "        cluster_info = client.info()\n",
        "        print(f\"  âœ… OpenSearch ì—°ê²° ì„±ê³µ: {cluster_info['version']['number']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ OpenSearch ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
        "        return False\n",
        "    \n",
        "    # 2. ë°ì´í„° í™•ì¸\n",
        "    print(\"\\n2. ë°ì´í„° í™•ì¸\")\n",
        "    try:\n",
        "        stats = client.indices.stats(index=OPENSEARCH_INDEX)\n",
        "        doc_count = stats['indices'][OPENSEARCH_INDEX]['total']['docs']['count']\n",
        "        print(f\"  âœ… ì¸ë±ìŠ¤ ë¬¸ì„œ ìˆ˜: {doc_count}\")\n",
        "        if doc_count == 0:\n",
        "            print(\"  âš ï¸ ì¸ë±ìŠ¤ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ ì¸ë±ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
        "        return False\n",
        "    \n",
        "    # 3. AI ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
        "    print(\"\\n3. AI ëª¨ë¸ í…ŒìŠ¤íŠ¸\")\n",
        "    if 'llm' in locals():\n",
        "        try:\n",
        "            test_response = llm.invoke([HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”!\")])\n",
        "            print(f\"  âœ… LLM ì‘ë‹µ ì„±ê³µ: {test_response.content[:50]}...\")\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ LLM í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"  âš ï¸ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return False\n",
        "    \n",
        "    # 4. ê²€ìƒ‰ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n",
        "    print(\"\\n4. ê²€ìƒ‰ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
        "    if 'agent' in locals():\n",
        "        try:\n",
        "            test_query = \"ì²­ë…„ ì •ì±… í…ŒìŠ¤íŠ¸\"\n",
        "            test_results = agent.search_policies(test_query)\n",
        "            print(f\"  âœ… ê²€ìƒ‰ ì„±ê³µ: {len(test_results)}ê°œ ê²°ê³¼\")\n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"  âš ï¸ ê²€ìƒ‰ ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        return False\n",
        "    \n",
        "    print(\"\\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
        "    print(\"âœ¨ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
        "    return True\n",
        "\n",
        "# ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "system_ready = final_system_test()\n",
        "\n",
        "if system_ready:\n",
        "    print(\"\\nğŸš€ ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:\")\n",
        "    print(\"  - interactive_search(): ëŒ€í™”í˜• ê²€ìƒ‰ ì‹œì‘\")\n",
        "    print(\"  - demo_search_examples(): ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ ë³´ê¸°\")\n",
        "    print(\"  - advanced_search_test(): ê³ ê¸‰ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
        "    print(\"  - evaluate_search_quality(): ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€\")\n",
        "    print(\"  - agent.answer_question('ì§ˆë¬¸'): ì§ì ‘ ì§ˆë¬¸í•˜ê¸°\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ ì‹œìŠ¤í…œ ì„¤ì •ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì‚¬ìš© ê°€ì´ë“œ\n",
        "\n",
        "### ì‹œì‘í•˜ê¸° ì „ì—\n",
        "1. **OpenAI API í‚¤ ì„¤ì •**: `OPENAI_API_KEY` ë³€ìˆ˜ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
        "2. **OpenSearch í™•ì¸**: localhost:9200ì—ì„œ OpenSearchê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
        "3. **ë°ì´í„° í™•ì¸**: youth_policies ì¸ë±ìŠ¤ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
        "\n",
        "### ì£¼ìš” ê¸°ëŠ¥\n",
        "- **í‚¤ì›Œë“œ ê²€ìƒ‰**: ì •ì±…ëª…, ì„¤ëª…, ì§€ì›ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰\n",
        "- **í•„í„° ê²€ìƒ‰**: ë‚˜ì´, ì§€ì—­, ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§\n",
        "- **ìì—°ì–´ ì²˜ë¦¬**: ì‚¬ìš©ì ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì˜ë„ ì¶”ì¶œ\n",
        "- **AI ë‹µë³€**: ChatGPTë¥¼ í™œìš©í•œ ì¹œì ˆí•˜ê³  ìƒì„¸í•œ ë‹µë³€ ìƒì„±\n",
        "\n",
        "### ì‚¬ìš©ë²•\n",
        "```
        "# ëŒ€í™”í˜• ê²€ìƒ‰ ì‹œì‘\n",
        "interactive_search()\n",
        "\n",
        "# ì§ì ‘ ì§ˆë¬¸\n",
        "answer = agent.answer_question(\"SW êµìœ¡ ì •ì±…ì´ ìˆë‚˜ìš”?\")\n",
        "print(answer)\n",
        "\n",
        "# ë°°ì¹˜ ê²€ìƒ‰\n",
        "queries = [\"ì·¨ì—… ì§€ì›\", \"ì°½ì—… ì •ì±…\", \"êµìœ¡ í”„ë¡œê·¸ë¨\"]\n",
        "results = batch_search(queries)\n",
        "```\n",
        "\n",
        "### ë¬¸ì œ í•´ê²°\n",
        "- **API í‚¤ ì˜¤ë¥˜**: OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\n",
        "- **ì—°ê²° ì˜¤ë¥˜**: OpenSearch ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸\n",
        "- **ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ**: ì¸ë±ìŠ¤ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
        "- **ì‘ë‹µ ìƒì„± ì‹¤íŒ¨**: ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë° OpenAI API ìƒíƒœ í™•ì¸\n",
        "\n",
        "### ì„±ëŠ¥ ìµœì í™”\n",
        "- ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ì ì ˆíˆ ì œí•œ (ê¸°ë³¸ê°’: 3ê°œ)\n",
        "- ë³µì¡í•œ ì§ˆë¬¸ì€ ë‹¨ìˆœí•˜ê²Œ ë‚˜ëˆ„ì–´ ê²€ìƒ‰\n",
        "- ìì£¼ ì‚¬ìš©í•˜ëŠ” ê²€ìƒ‰ì–´ëŠ” ìºì‹± ê³ ë ¤\n",
        "\n",
        "**ì™„ë£Œ!** ì´ì œ ì²­ë…„ì •ì±… ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‰"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

