{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cae8901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7992a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 스토어가 성공적으로 생성되었습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# OpenAI API 키 설정 (환경변수 또는 직접 입력)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 1. 임베딩 모델 초기화\n",
    "# OpenAI의 text-embedding-ada-002 모델 사용\n",
    "# 기본 1536차원 : 1536 × 4바이트 = 6.1KB per 문서\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 1024차원으로 축소: 512 × 4바이트 = 2.0KB per 문서 (약 67% 절약)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)\n",
    "\n",
    "\n",
    "# 2. 샘플 텍스트 데이터 준비\n",
    "sample_texts = [\n",
    "    \"LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\",\n",
    "    \"벡터 데이터베이스는 텍스트를 수치형 벡터로 변환하여 저장합니다.\",\n",
    "    \"RAG는 검색 증강 생성으로, 외부 지식을 활용해 답변을 생성합니다.\",\n",
    "    \"임베딩은 텍스트의 의미를 고차원 벡터 공간에 표현하는 기술입니다.\",\n",
    "]\n",
    "\n",
    "# 3. 벡터 스토어 생성 및 문서 추가\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=sample_texts,  # 저장할 텍스트 리스트\n",
    "    embedding=embeddings,  # 사용할 임베딩 모델\n",
    "    persist_directory=\"./chroma_db\",  # 데이터베이스 저장 경로\n",
    ")\n",
    "\n",
    "print(\"벡터 스토어가 성공적으로 생성되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7eb4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# 1. 문서 로더 설정 (PDF 파일 예시)\n",
    "def load_and_process_document(file_path):\n",
    "    \"\"\"\n",
    "    문서를 로드하고 청크로 분할하는 함수\n",
    "    \"\"\"\n",
    "    # 파일 확장자에 따라 적절한 로더 선택\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(\"지원하지 않는 파일 형식입니다.\")\n",
    "\n",
    "    # 문서 로드\n",
    "    documents = loader.load()\n",
    "\n",
    "    # 2. 텍스트 분할기 설정\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,  # 각 청크의 최대 크기\n",
    "        chunk_overlap=200,  # 청크 간 겹치는 부분\n",
    "        length_function=len,  # 길이 계산 함수\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # 분할 기준\n",
    "    )\n",
    "\n",
    "    # 문서를 청크로 분할\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# 사용 예시 (실제 파일이 있을 때)\n",
    "# chunks = load_and_process_document(\"sample_document.pdf\")\n",
    "# vectorstore = Chroma.from_documents(\n",
    "#     documents=chunks,\n",
    "#     embedding=embeddings,\n",
    "#     persist_directory=\"./chroma_db\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36a119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.vectorstores.chroma.Chroma"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = load_and_process_document(\"sample_document.pdf\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "type(vectorstore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f99965",
   "metadata": {},
   "source": [
    "3-3. 유사도 검색 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc45e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 쿼리: LangChain이 무엇인가요?\n",
      "==================================================\n",
      "1. LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\n",
      "------------------------------\n",
      "2. 임베딩은 텍스트의 의미를 고차원 벡터 공간에 표현하는 기술입니다.\n",
      "------------------------------\n",
      "3. LS 전선/LS 마린솔루션 \n",
      "📌미/중 맞설 AI 허브 노리는 사우디, 빈 살만 펀드, 韓 스타트업 쇼핑 \n",
      " *HOT 예상 \n",
      "NAVER/컴퍼니케이/딥노이드/스톤브릿지벤처/폴라리스오피스/플리토/\n",
      "더존비즈온/솔트룩스 \n",
      "📌트럼프 휴전 깨졌나. 후티, 홍해 지나던 상선 이틀 연속 공격 \n",
      " *HOT 예상 \n",
      "HMM/흥아해운/KCTC/동방 \n",
      " \n",
      "📈TODAY 종목 Pick \n",
      "1️⃣ 삼성물산(초보투자자형) \n",
      "✅가격권 150,000 원 ~ 200,000 원 \n",
      " \n",
      " 현재 원전과 주택 양축에서 모두 구조적 전환을 시도. 원전 \n",
      "부문에서는 기존의 시공 중심 역할에서 벗어나, \n",
      "SMR(소형모듈원자로)을 중심으로 한 비즈니스로 확대 \n",
      " 루마니아 뉴스케일 SMR 프로젝트(24 년 11 월 수주) 시작으로, \n",
      "스웨덴 등 북유럽 국가들에서 초기 사업자로서의 입지를 \n",
      "확보하고자 시도 \n",
      " 주택 부문에서 넥스트 홈이라는 기술 기반 주거상품을 앞세워 \n",
      "구조 혁신과 고급화 전략을 동시에 추진하고 있으며 이 시스템이 \n",
      "핵심 경쟁력으로 작용할 것으로 판단 \n",
      " \n",
      "2️⃣ LS ELECTRIC(안정투자자형) \n",
      "✅가격권 246,000 원 ~ 326,000 원\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. 기본 유사도 검색\n",
    "def search_similar_documents(query, k=3):\n",
    "    \"\"\"\n",
    "    쿼리와 유사한 문서를 검색하는 함수\n",
    "\n",
    "    Args:\n",
    "        query (str): 검색할 쿼리\n",
    "        k (int): 반환할 문서 수\n",
    "\n",
    "    Returns:\n",
    "        list: 유사한 문서 리스트\n",
    "    \"\"\"\n",
    "    # 유사도 검색 수행\n",
    "    similar_docs = vectorstore.similarity_search(query=query, k=k)  # 상위 k개 문서 반환\n",
    "\n",
    "    return similar_docs\n",
    "\n",
    "\n",
    "# 검색 실행\n",
    "query = \"LangChain이 무엇인가요?\"\n",
    "results = search_similar_documents(query)\n",
    "\n",
    "print(f\"검색 쿼리: {query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7eb12",
   "metadata": {},
   "source": [
    "3-4. 점수 기반 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3680e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 쿼리: 벡터 데이터베이스의 특징\n",
      "==================================================\n",
      "1. 유사도 점수: 0.4371\n",
      "   내용: 벡터 데이터베이스는 텍스트를 수치형 벡터로 변환하여 저장합니다.\n",
      "------------------------------\n",
      "2. 유사도 점수: 1.1749\n",
      "   내용: 임베딩은 텍스트의 의미를 고차원 벡터 공간에 표현하는 기술입니다.\n",
      "------------------------------\n",
      "3. 유사도 점수: 1.4976\n",
      "   내용:  미국 시장을 중심으로 AI(인공지능) 데이터센터향 전력기기 \n",
      "수주가 본격화되고 있는 가운데, 이미 높은 시장점유율을 \n",
      "확보하고 있는 국내 시장에서도 정부의 AI 인프라 확대 계획에 \n",
      "힘입어 수혜 기대 \n",
      " 지난해 말 미국 X 사와 데이터센터용 전력기기 수주 계약을 \n",
      "체결했고, 최근에는 전력 및 액체냉각 시스템을 구축하는 \n",
      "버티브(Vertiv)와 파트너십을 체결 \n",
      " 데이터센터용 전력기기는 기존 양산형 전력기기와 달리 고객의 \n",
      "요구에 맞춰 개발되는데, LS ELECTRIC 은 빠른 개발 및 인증과 \n",
      "납기가 큰 경쟁우위로 작용할 것으로 판단 \n",
      " \n",
      "3️⃣ SK 오션플랜트(안정투자자형) \n",
      "✅가격권 19,000 원 ~ 25,000 원 \n",
      " \n",
      " 1 분기 실적은 시장 기대치를 상회. 해상풍력 매출 규모 성장에 \n",
      "비례하여 마진이 정상화되는 과정에 있음 \n",
      " 연간 매출액 가이던스의 변화가 제한적이기 때문에 수주잔고를 \n",
      "감안하면 분기 매출액 편차는 크지 않을 것으로 예상 \n",
      " 다만 올해 연간 매출 대부분을 특수선 부문이 차지할 전망이며 \n",
      "기존 잔고 소진 이후 국내외 해상풍력 수주 물량 증가에 따른 \n",
      "매출 Mix 개선이 예상. 국내 재생에너지 정책 제고 기대감으로 \n",
      "멀티플이 확장되는 국면 \n",
      " 2030 년까지 서해안 에너지고속도로, 2040 년까지 한반도 \n",
      "에너지고속도로 건설로 송전 인프라 적기 구축 및 전력망 혁신 \n",
      "추진 수혜\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 유사도 점수와 함께 검색\n",
    "def search_with_scores(query, k=3):\n",
    "    \"\"\"\n",
    "    유사도 점수와 함께 문서를 검색하는 함수\n",
    "    \"\"\"\n",
    "    # 점수와 함께 검색\n",
    "    results_with_scores = vectorstore.similarity_search_with_score(query=query, k=k)\n",
    "\n",
    "    return results_with_scores\n",
    "\n",
    "\n",
    "# 점수 기반 검색 실행\n",
    "query = \"벡터 데이터베이스의 특징\"\n",
    "scored_results = search_with_scores(query)\n",
    "\n",
    "print(f\"검색 쿼리: {query}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, (doc, score) in enumerate(scored_results, 1):\n",
    "    print(f\"{i}. 유사도 점수: {score:.4f}\")\n",
    "    print(f\"   내용: {doc.page_content}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a9b9d",
   "metadata": {},
   "source": [
    "3-5. 필터링 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4905fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초급 난이도 문서 검색 결과:\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\n",
      "  메타데이터: {'category': 'framework', 'difficulty': 'beginner'}\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터를 활용한 필터링 검색\n",
    "def create_vectorstore_with_metadata():\n",
    "    \"\"\"\n",
    "    메타데이터가 포함된 벡터 스토어 생성\n",
    "    \"\"\"\n",
    "    # 메타데이터가 포함된 문서 데이터\n",
    "    documents_with_metadata = [\n",
    "        {\n",
    "            \"text\": \"LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발 프레임워크입니다.\",\n",
    "            \"metadata\": {\"category\": \"framework\", \"difficulty\": \"beginner\"},\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"벡터 데이터베이스는 텍스트를 수치형 벡터로 변환하여 저장합니다.\",\n",
    "            \"metadata\": {\"category\": \"database\", \"difficulty\": \"intermediate\"},\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"RAG는 검색 증강 생성으로, 외부 지식을 활용해 답변을 생성합니다.\",\n",
    "            \"metadata\": {\"category\": \"technique\", \"difficulty\": \"advanced\"},\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 텍스트와 메타데이터 분리\n",
    "    texts = [doc[\"text\"] for doc in documents_with_metadata]\n",
    "    metadatas = [doc[\"metadata\"] for doc in documents_with_metadata]\n",
    "\n",
    "    # 메타데이터가 포함된 벡터 스토어 생성\n",
    "    vectorstore_with_meta = Chroma.from_texts(\n",
    "        texts=texts,\n",
    "        metadatas=metadatas,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db_with_meta\",\n",
    "    )\n",
    "\n",
    "    return vectorstore_with_meta\n",
    "\n",
    "\n",
    "# 필터링 검색 함수\n",
    "def filtered_search(vectorstore, query, filter_dict, k=3):\n",
    "    \"\"\"\n",
    "    메타데이터 필터를 적용한 검색\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(\n",
    "        query=query, k=k, filter=filter_dict  # 필터 조건\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 필터링 검색 실행 예시\n",
    "vectorstore_meta = create_vectorstore_with_metadata()\n",
    "\n",
    "# 초급 난이도 문서만 검색\n",
    "beginner_results = filtered_search(\n",
    "    vectorstore_meta, \"프레임워크에 대해 알려주세요\", {\"difficulty\": \"beginner\"}\n",
    ")\n",
    "\n",
    "print(\"초급 난이도 문서 검색 결과:\")\n",
    "for doc in beginner_results:\n",
    "    print(f\"- {doc.page_content}\")\n",
    "    print(f\"  메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7e3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
