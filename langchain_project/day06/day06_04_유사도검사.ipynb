{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e19a6634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b135a7",
   "metadata": {},
   "source": [
    "1. 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907a15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트1 vs 텍스트2 유사도: 0.3452\n",
      "텍스트1 vs 텍스트3 유사도: 0.1175\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)\n",
    "\n",
    "# 비교할 텍스트들\n",
    "text1 = \"오늘 날씨가 정말 좋습니다.\"\n",
    "text2 = \"햇살이 따뜻하고 기분이 좋네요.\"\n",
    "text3 = \"컴퓨터 프로그래밍을 배우고 있습니다.\"\n",
    "\n",
    "# 임베딩 생성\n",
    "embedding1 = embeddings.embed_query(text1)\n",
    "embedding2 = embeddings.embed_query(text2)\n",
    "embedding3 = embeddings.embed_query(text3)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "similarity_1_2 = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "similarity_1_3 = cosine_similarity([embedding1], [embedding3])[0][0]\n",
    "\n",
    "print(f\"텍스트1 vs 텍스트2 유사도: {similarity_1_2:.4f}\")\n",
    "print(f\"텍스트1 vs 텍스트3 유사도: {similarity_1_3:.4f}\")\n",
    "\n",
    "\n",
    "#텍스트1 vs 텍스트2 유사도: 0.3452\n",
    "#텍스트1 vs 텍스트3 유사도: 0.1175\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea32ee7",
   "metadata": {},
   "source": [
    "2. 벡터 간 거리 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193eb83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유클리드 거리: 1.1443\n",
      "맨하탄 거리: 28.8679\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "\n",
    "# 유클리드 거리 (낮을수록 유사)\n",
    "euclidean_dist = euclidean(embedding1, embedding2)\n",
    "print(f\"유클리드 거리: {euclidean_dist:.4f}\")\n",
    "\n",
    "# 맨하탄 거리 (낮을수록 유사)\n",
    "# 맨하탄 거리 (cityblock 사용)\n",
    "manhattan_dist = cityblock(embedding1, embedding2)\n",
    "print(f\"맨하탄 거리: {manhattan_dist:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9c21b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맨하탄 거리: 28.8679\n",
      "맨하탄 거리: 28.8679\n",
      "맨하탄 거리: 28.8679\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "embedding1_array = np.array(embedding1)\n",
    "embedding2_array = np.array(embedding2)\n",
    "\n",
    "# 맨하탄 거리 계산\n",
    "manhattan_dist = np.sum(np.abs(embedding1_array - embedding2_array))\n",
    "print(f\"맨하탄 거리: {manhattan_dist:.4f}\")\n",
    "\n",
    "# 직접 변환하면서 계산\n",
    "manhattan_dist = np.sum(np.abs(np.array(embedding1) - np.array(embedding2)))\n",
    "print(f\"맨하탄 거리: {manhattan_dist:.4f}\")\n",
    "\n",
    "# 리스트 컴프리헨션 사용\n",
    "manhattan_dist = sum(abs(a - b) for a, b in zip(embedding1, embedding2))\n",
    "print(f\"맨하탄 거리: {manhattan_dist:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497ac05",
   "metadata": {},
   "source": [
    "다중 텍스트 유사도 매트릭스\n",
    "여러 텍스트 동시 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589032ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 매트릭스:\n",
      "        텍스트1    텍스트2    텍스트3    텍스트4    텍스트5\n",
      "텍스트1  1.0000  0.3452  0.3293  0.0828  0.2092\n",
      "텍스트2  0.3452  1.0000  0.2684  0.1146  0.2278\n",
      "텍스트3  0.3293  0.2684  1.0000  0.2536  0.1734\n",
      "텍스트4  0.0828  0.1146  0.2536  1.0000  0.2478\n",
      "텍스트5  0.2092  0.2278  0.1734  0.2478  1.0000\n"
     ]
    }
   ],
   "source": [
    "#from langchain_openai import OpenAIEmbeddings\n",
    "#import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 비교할 텍스트 리스트\n",
    "texts = [\n",
    "    \"오늘 날씨가 정말 좋습니다.\",\n",
    "    \"햇살이 따뜻하고 기분이 좋네요.\",\n",
    "    \"비가 오고 있어서 우울합니다.\",\n",
    "    \"파이썬 프로그래밍을 배우고 있습니다.\",\n",
    "    \"머신러닝 공부가 재미있어요.\",\n",
    "]\n",
    "\n",
    "# 모든 텍스트의 임베딩 생성\n",
    "text_embeddings = embeddings.embed_documents(texts)\n",
    "\n",
    "# 유사도 매트릭스 계산\n",
    "similarity_matrix = cosine_similarity(text_embeddings)\n",
    "\n",
    "# 결과를 DataFrame으로 시각화\n",
    "df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=[f\"텍스트{i+1}\" for i in range(len(texts))],\n",
    "    columns=[f\"텍스트{i+1}\" for i in range(len(texts))],\n",
    ")\n",
    "\n",
    "print(\"유사도 매트릭스:\")\n",
    "print(df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd34c8",
   "metadata": {},
   "source": [
    "실용적인 유사도 검사 함수\n",
    "1. 유사도 검사 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d33758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사 여부: False, 유사도: 0.5388\n",
      "가장 유사한 텍스트: AI 학습 방법론에 대해 알아보자\n",
      "유사도 점수: 0.4301\n"
     ]
    }
   ],
   "source": [
    "class SimilarityChecker:\n",
    "    def __init__(self, model_name=\"text-embedding-3-small\", threshold=0.8):\n",
    "        self.embeddings = OpenAIEmbeddings(model=model_name, dimensions=1024)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def calculate_similarity(self, text1, text2):\n",
    "        \"\"\"두 텍스트 간의 코사인 유사도 계산\"\"\"\n",
    "        embedding1 = self.embeddings.embed_query(text1)\n",
    "        embedding2 = self.embeddings.embed_query(text2)\n",
    "\n",
    "        similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "        return similarity\n",
    "\n",
    "    def is_similar(self, text1, text2):\n",
    "        \"\"\"임계값 기준으로 유사 여부 판단\"\"\"\n",
    "        similarity = self.calculate_similarity(text1, text2)\n",
    "        return similarity >= self.threshold, similarity\n",
    "\n",
    "    def find_most_similar(self, query_text, candidate_texts):\n",
    "        \"\"\"후보 텍스트 중 가장 유사한 것 찾기\"\"\"\n",
    "        query_embedding = self.embeddings.embed_query(query_text)\n",
    "        candidate_embeddings = self.embeddings.embed_documents(candidate_texts)\n",
    "\n",
    "        similarities = cosine_similarity([query_embedding], candidate_embeddings)[0]\n",
    "\n",
    "        # 가장 유사한 텍스트의 인덱스와 유사도\n",
    "        best_idx = np.argmax(similarities)\n",
    "        best_similarity = similarities[best_idx]\n",
    "\n",
    "        return {\n",
    "            \"most_similar_text\": candidate_texts[best_idx],\n",
    "            \"similarity_score\": best_similarity,\n",
    "            \"index\": best_idx,\n",
    "            \"all_similarities\": similarities,\n",
    "        }\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "checker = SimilarityChecker(threshold=0.7)\n",
    "\n",
    "# 두 텍스트 유사도 검사\n",
    "text_a = \"파이썬으로 웹 개발을 하고 있습니다.\"\n",
    "text_b = \"Python을 사용해서 웹사이트를 만들고 있어요.\"\n",
    "\n",
    "is_similar, score = checker.is_similar(text_a, text_b)\n",
    "print(f\"유사 여부: {is_similar}, 유사도: {score:.4f}\")\n",
    "\n",
    "# 가장 유사한 텍스트 찾기\n",
    "query = \"머신러닝 공부하는 방법\"\n",
    "candidates = [\n",
    "    \"AI 학습 방법론에 대해 알아보자\",\n",
    "    \"요리 레시피를 찾고 있습니다\",\n",
    "    \"딥러닝 튜토리얼 추천해주세요\",\n",
    "    \"오늘 날씨가 좋네요\",\n",
    "]\n",
    "\n",
    "result = checker.find_most_similar(query, candidates)\n",
    "print(f\"가장 유사한 텍스트: {result['most_similar_text']}\")\n",
    "print(f\"유사도 점수: {result['similarity_score']:.4f}\")\n",
    "\n",
    "# 유사 여부: False, 유사도: 0.5388\n",
    "# 가장 유사한 텍스트: AI 학습 방법론에 대해 알아보자\n",
    "# 유사도 점수: 0.4301\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d74152",
   "metadata": {},
   "source": [
    "고급 유사도 검사 기법\n",
    "1. 의미적 검색 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782b144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "순위 1: 머신러닝은 인공지능의 한 분야입니다.\n",
      "유사도: 0.3628\n",
      "\n",
      "순위 2: 자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\n",
      "유사도: 0.3310\n",
      "\n",
      "순위 3: 파이썬은 프로그래밍 언어입니다.\n",
      "유사도: 0.2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SemanticSearch:\n",
    "    def __init__(self, documents, model_name=\"text-embedding-3-small\"):\n",
    "        self.documents = documents\n",
    "        self.embeddings = OpenAIEmbeddings(model=model_name, dimensions=1024)\n",
    "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "\n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"쿼리와 가장 유사한 문서들 반환\"\"\"\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "\n",
    "        # 모든 문서와의 유사도 계산\n",
    "        similarities = cosine_similarity([query_embedding], self.doc_embeddings)[0]\n",
    "\n",
    "        # 상위 k개 결과 선택\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"document\": self.documents[idx],\n",
    "                    \"similarity\": similarities[idx],\n",
    "                    \"rank\": len(results) + 1,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "documents = [\n",
    "    \"파이썬은 프로그래밍 언어입니다.\",\n",
    "    \"머신러닝은 인공지능의 한 분야입니다.\",\n",
    "    \"오늘 날씨가 맑고 따뜻합니다.\",\n",
    "    \"딥러닝은 신경망을 사용하는 기술입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\",\n",
    "]\n",
    "\n",
    "search_engine = SemanticSearch(documents)\n",
    "results = search_engine.search(\"AI와 관련된 기술\", top_k=3)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"순위 {result['rank']}: {result['document']}\")\n",
    "    print(f\"유사도: {result['similarity']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e04b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_similarity_check(texts, batch_size=100):\n",
    "    \"\"\"대량의 텍스트에 대한 효율적인 유사도 검사\"\"\"\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    # 배치 단위로 임베딩 생성\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        batch_embeddings = embeddings.embed_documents(batch)\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "    # 유사도 매트릭스 계산\n",
    "    similarity_matrix = cosine_similarity(all_embeddings)\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee93b6",
   "metadata": {},
   "source": [
    "유사도 임계값 설정 가이드\n",
    "임계값별 의미\n",
    "0.9 이상: 거의 동일한 의미\n",
    "\n",
    "0.8 - 0.9: 매우 유사한 의미\n",
    "\n",
    "0.7 - 0.8: 관련성이 높음\n",
    "\n",
    "0.6 - 0.7: 어느 정도 관련성 있음\n",
    "\n",
    "0.5 이하: 관련성이 낮음\n",
    "\n",
    "도메인별 권장 임계값\n",
    "중복 검사: 0.85 이상\n",
    "\n",
    "의미적 검색: 0.7 이상\n",
    "\n",
    "문서 분류: 0.6 이상\n",
    "\n",
    "추천 시스템: 0.5 이상\n",
    "\n",
    "이러한 방법들을 조합하여 사용하면 다양한 상황에서 효과적인 유사도 검사를 수행할 수 있습니다. 특히 차원 조정을 통해 성능과 비용의 균형을 맞추는 것도 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab50f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
