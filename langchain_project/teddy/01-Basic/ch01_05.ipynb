{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588660d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7dbe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bada3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f021318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f38f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5822a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442ce209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # 모델명\n",
    "    max_tokens=100,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c5f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd82aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0bde1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 일종의 수학 공식을 사용하여 데이터를 분석하고 패턴을 학습하는 과정입니다. \\n\\n먼저, 모델은 입력 데이터를 받아들이고 이를 처리하여 출력을 생성합니다. 이때, 모델은 입력 데이터와 출력 데이터 간의 관계를 숨겨진 패턴으로 학습하려고 노력합니다. \\n\\n모델은 입력된 데이터와 실제 출력값 간의 차이를 계산하고, 이 차이를 최소화하는 방향으로 모델의 내부 매개변수를 조정합니다. 이 과정을 반복하여 모델이 입력 데이터를 올바르게 처리하고 원하는 출력을 생성할 수 있도록 학습합니다.\\n\\n이러한 방식으로, 인공지능 모델은 주어진 데이터를 학습하고 새로운 데이터에 대한 예측을 수행하는 데 사용됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 268, 'prompt_tokens': 33, 'total_tokens': 301, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BqHVDqVYUZiPSUQPUX3cS24Yyk4Kg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--118ee508-4b26-473a-80ea-dd97e0fe4eeb-0', usage_metadata={'input_tokens': 33, 'output_tokens': 268, 'total_tokens': 301, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3053f6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력하여 모델이 데이터 간의 패턴이나 관계를 학습하는 과정입니다. \n",
      "\n",
      "일반적으로 인공지능 모델은 입력층, 은닉층, 출력층으로 구성되어 있습니다. 입력층에는 학습할 데이터가 입력되고, 은닉층은 입력된 데이터를 처리하여 중요한 특성을 추출하는 역할을 합니다. 최종적으로 출력층에서는 모델이 학습한 결과를 출력합니다.\n",
      "\n",
      "모델은 입력 데이터를 받아들이고, 이를 어떻게 처리할지를 결정하는 가중치(weight)와 편향(bias)를 업데이트하면서 학습을 진행합니다. 이러한 과정을 반복하면서 모델은 데이터 간의 패턴을 학습하고 성능을 개선해 나갑니다.\n",
      "\n",
      "이렇게 학습된 모델은 새로운 데이터가 입력되었을 때, 학습한 지식을 바탕으로 적절한 결과를 도출할 수 있습니다. 인공지능 모델의 성능은 모델의 구조, 학습 알고리즘, 데이터의 양과 질 등 다양한 요소에 의해 영향을 받습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "136fc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3859dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27eccd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델은 데이터를 입력으로 받아들이고, 그 데이터를 가지고 패턴을 학습하여 원하는 작업을 수행하는데 사용됩니다. \\n\\n인공지능 모델의 학습 과정은 크게 입력층, 은닉층, 출력층으로 구성된 신경망이라는 구조를 사용합니다. 이 신경망은 입력 데이터를 받아들이고 각 층을 통과하면서 가중치를 조절하며 학습을 진행합니다. \\n\\n모델은 학습 데이터를 사용하여 예측을 만들고, 이 예측 값과 정답 사이의 오차를 계산하여 이 오차를 최소화하는 방향으로 가중치를 조정하면서 학습을 진행합니다. 이렇게 반복적으로 가중치를 최적화하면서 모델이 패턴을 학습하게 됩니다.\\n\\n즉, 인공지능 모델의 학습 원리는 입력 데이터를 받아들이고 예측을 만들며, 이를 토대로 오차를 최소화하도록 가중치를 조정하는 과정을 반복하는 것입니다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e2bccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 그 데이터의 패턴이나 규칙을 학습하여 문제를 해결하는 과정입니다. \n",
      "\n",
      "모델은 초기에는 데이터를 입력받아 일련의 패턴을 인식하는데 어려움을 겪습니다. 하지만 반복적으로 학습을 거듭함으로써 데이터의 패턴을 더욱 정확하게 학습하고 문제를 효과적으로 해결할 수 있게 됩니다. 이러한 과정은 모델이 가중치(weight)를 조절하거나 최적화 알고리즘을 사용하여 학습을 진행합니다.\n",
      "\n",
      "이렇게 모델은 입력된 데이터와 원하는 출력 간의 관계를 학습하며, 새로운 데이터가 주어졌을 때 정확한 결과를 예측할 수 있도록 학습됩니다. 이러한 원리를 통해 인공지능 모델은 문제를 해결하거나 패턴을 인식하는데 활용됩니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16072fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", max_tokens=100, temperature=0.1)\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e08ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4a9772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  - Waiter: Good evening! Welcome to our restaurant. How many people are in your party?\n",
      "  - You: Good evening! Just one, please.\n",
      "  - Waiter: Great! Here’s the menu. Can I get you something to drink while you look?\n",
      "  - You: Yes, I’d like a glass of water, please.\n",
      "  - Waiter: Sure! Are you ready to order, or do you need a few more minutes?\n",
      " "
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b0849c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  - Customer: Hi there! I’d like to order a pizza, please.\n",
      "  - Pizza Shop: Sure! What size would you like?\n",
      "  - Customer: I’ll have a large pizza, please.\n",
      "  - Pizza Shop: Great! What toppings do you want?\n",
      "  - Customer: I’d like pepperoni and mushrooms.\n",
      "  - Pizza Shop: Would you like any extra cheese?\n",
      "  - Customer: Yes, please! How long will it take?\n",
      " "
     ]
    }
   ],
   "source": [
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc590b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
