import os
from typing import Optional

from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (OPENAI_API_KEY)
load_dotenv()


# --- 1. ì •ë³´ 'ì¶”ì¶œê¸°'ê°€ ì‚¬ìš©í•  ë°ì´í„° êµ¬ì¡° ---
# ì´ë¦„, ì „í™”ë²ˆí˜¸ ë“± ë¶€ë¶„ì ì¸ ì •ë³´ë§Œ ë‹´ì„ ìˆ˜ ìˆë„ë¡ ëª¨ë“  í•„ë“œë¥¼ Optionalë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
class PartialCustomerInfo(BaseModel):
    """ê³ ê°ì˜ ì´ë¦„ ë˜ëŠ” ì „í™”ë²ˆí˜¸ ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° êµ¬ì¡°ì…ë‹ˆë‹¤."""

    name: Optional[str] = Field(None, description="ëŒ€í™”ì—ì„œ ì¶”ì¶œí•œ ê³ ê°ì˜ ì´ë¦„")
    phone_number: Optional[str] = Field(
        None, description="ëŒ€í™”ì—ì„œ ì¶”ì¶œí•œ ê³ ê°ì˜ ì „í™”ë²ˆí˜¸"
    )


def run_chatbot():
    """
    ëŒ€í™”ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ë©° ê³ ê°ì˜ ì´ë¦„ê³¼ ì—°ë½ì²˜ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì±—ë´‡ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(
        "ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”! ìŠ¤ë§ˆì¼ ì¹˜ê³¼ ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (ì¢…ë£Œí•˜ì‹œë ¤ë©´ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”)"
    )

    # --- 2. ì±—ë´‡ ëª¨ë¸ ë° ì„¤ì • ì´ˆê¸°í™” ---
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    extraction_llm = llm.with_structured_output(PartialCustomerInfo)

    # --- 3. 'ìƒíƒœ ê´€ë¦¬ì'ê°€ ì‚¬ìš©í•  ì €ì¥ ê³µê°„ ---
    # ìˆ˜ì§‘ëœ ê³ ê° ì •ë³´ë¥¼ ê¸°ì–µí•˜ëŠ” ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
    collected_info = {
        "name": None,
        "phone_number": None,
        "reason": None,
    }

    # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    chat_history = []

    while True:
        # --- ìµœì¢… ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸ ---
        if collected_info["name"] and collected_info["phone_number"]:
            print("\nâœ… [ìƒë‹´ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ]")
            print(f"  - ê³ ê°ëª…: {collected_info['name']}")
            print(f"  - ì—°ë½ì²˜: {collected_info['phone_number']}")
            print(f"  - ë¬¸ì˜ ì‚¬ìœ : {collected_info['reason'] or 'N/A'}")
            print("\nğŸ¤– ê°ì‚¬í•©ë‹ˆë‹¤! ì „ë¬¸ ìƒë‹´ì›ì´ ê³§ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
            break

        user_input = input("ğŸ™‚: ")
        if user_input.lower() == "exit":
            print("ğŸ¤– ìƒë‹´ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.")
            break

        # ì²« ì§ˆë¬¸ì„ 'ë¬¸ì˜ ì‚¬ìœ 'ë¡œ ì €ì¥
        if not collected_info["reason"]:
            collected_info["reason"] = user_input

        chat_history.append(HumanMessage(content=user_input))

        # --- 4. 'ì •ë³´ ì¶”ì¶œê¸°' ì‹¤í–‰ ---
        # ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë‹µë³€ì—ì„œ ì´ë¦„ì´ë‚˜ ì—°ë½ì²˜ë¥¼ ì¶”ì¶œ ì‹œë„í•©ë‹ˆë‹¤.
        try:
            extracted_data = extraction_llm.invoke([HumanMessage(content=user_input)])
            if extracted_data.name and not collected_info["name"]:
                collected_info["name"] = extracted_data.name
                print(f"ğŸ¤– [ì´ë¦„: {extracted_data.name} í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.]")
            if extracted_data.phone_number and not collected_info["phone_number"]:
                collected_info["phone_number"] = extracted_data.phone_number
                print(f"ğŸ¤– [ì—°ë½ì²˜: {extracted_data.phone_number} í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.]")
        except Exception:
            # ì¶”ì¶œí•  ì •ë³´ê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë„˜ì–´ê°‘ë‹ˆë‹¤.
            pass

        # ëª©í‘œë¥¼ ë‹¬ì„±í–ˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
        if collected_info["name"] and collected_info["phone_number"]:
            continue

        # --- 5. 'ì‘ë‹µ ìƒì„±ê¸°' ì‹¤í–‰ ---
        # í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´(ìƒíƒœ)ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒì— ë¬´ì—‡ì„ ë¬¼ì–´ë³¼ì§€ ê²°ì •í•©ë‹ˆë‹¤.
        system_prompt_for_response = f"""
        ë‹¹ì‹ ì€ 'ìŠ¤ë§ˆì¼ ì¹˜ê³¼'ì˜ ì¹œì ˆí•œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ê³ ê°ì˜ ì´ë¦„ê³¼ ì „í™”ë²ˆí˜¸ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

        [í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´]
        - ì´ë¦„: {collected_info['name'] or 'ì•„ì§ ëª¨ë¦„'}
        - ì „í™”ë²ˆí˜¸: {collected_info['phone_number'] or 'ì•„ì§ ëª¨ë¦„'}

        [ë‹¹ì‹ ì˜ ì„ë¬´]
        - ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì€ ì •ë³´ë¥¼ ê³ ê°ì—ê²Œ ì •ì¤‘í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.
        - ë§Œì•½ ì´ë¦„ì´ ì—†ë‹¤ë©´, ì´ë¦„ì„ ë¬¼ì–´ë³´ì„¸ìš”.
        - ë§Œì•½ ì „í™”ë²ˆí˜¸ê°€ ì—†ë‹¤ë©´, ì „í™”ë²ˆí˜¸ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.
        - ê³ ê°ì´ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ë©´, "ë„¤, ê·¸ ë¶€ë¶„ì€ ì „ë¬¸ ìƒë‹´ì›ì´ ìì„¸íˆ ì•ˆë‚´í•´ ë“œë¦´ ê±°ì˜ˆìš”. ìš°ì„  ì—°ë½ì²˜ë¥¼ ë‚¨ê²¨ì£¼ì‹œê² ì–´ìš”?" ì™€ ê°™ì´ ë¶€ë“œëŸ½ê²Œ ì‘ëŒ€í•˜ë©° ì›ë˜ ëª©í‘œë¡œ ëŒì•„ì˜¤ì„¸ìš”.
        - ì ˆëŒ€ë¡œ ì˜í•™ì  ì¡°ì–¸ì„ í•˜ì§€ ë§ˆì„¸ìš”.
        """

        messages_for_response = [
            SystemMessage(content=system_prompt_for_response),
        ]
        # ëŒ€í™”ì˜ íë¦„ì„ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìµœê·¼ ëŒ€í™” ë‚´ìš©ì„ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.
        messages_for_response.extend(chat_history[-4:])

        ai_response = llm.invoke(messages_for_response)
        chat_history.append(ai_response)
        print(f"ğŸ¤–: {ai_response.content}")


if __name__ == "__main__":
    run_chatbot()
